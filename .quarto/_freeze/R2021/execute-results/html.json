{
  "hash": "94ed08821f0da33299afbff083d6bf6e",
  "result": {
    "markdown": "# Non-econometric methods for econometricians\n\n## Selected ML and Dataviz techniques using R\n\nEconometricians are used to handling data, performing analysis and reporting results. But somewhere along the line data became big and unstructured, analysis was now machines learning about something and outputs became visualisations.\n\nThis online seminar takes some big(ish) datasets, sets the machines on them and draws some great graphs. If you ever wondered what use a tree was for forecasting or why everything is a network (including neural ones), or wanted to draw a map with your house in it, or to understand a document without the bother of reading it (or a few other things besides) then you might find something to interest you. All done in R.\n\nSpecifically, this seminar is designed to introduce some of the key methods used outside of econometrics that econometricians will find very useful in their work in a central bank. This includes some important machine learning techniques as a gateway to others, particularly tree-based methods and neural networks, as well as text processing and map making. All the way through there is an emphasis on the network properties of many of these techniques. We make extensive use of the `tidyverse`, including `ggplot2` and `tidytext`, and a number of statistics, machine learning, geographical data and other packages.\n\nThe framework for each day is the following:\n\n-   Each day is divided into two two-hour sessions starting at 10.30 am and 2.00 pm GMT.\n-   The first hour of each will be an online presentation covering a particular topic (or topics) with a look at both techniques and code.\n-   After a quick break the second hour will be largely devoted to the code itself or resources to understand how to code the material.\n\nWe may run polls during the event to prioritize the topics covered in the webinars as it is not expected that everyone will be able to try out everything.\n\n### The code\n\nAll code and some of the data will be made available through the Juno portal. For each presentation the .Rmd (R markdown) file is supplied that creates the presentation, an HTML file of the presentation for you to step through which can be re-created from the .Rmd file, and a further .R file of the code that we use. Some additional code and data is included, including links to a number of videos that cover some additional aspects both in this file and in the presentations.\n\nSome data will need to be downloaded from original other sites if all the examples are to be followed. All code is additionally available at <https://github.com/andrewpeterblake/R2020> or <https://github.com/andrewpeterblake/R2021> or through the QR codes below.\n\n\n::: {.cell layout-align=\"center\"}\n::: {.cell-output-display}\n![GitHub: 2020 (grey, left), 2021 (pink, right)](R2021_files/figure-html/unnamed-chunk-1-1.png){fig-align='center' width=25%}\n:::\n\n::: {.cell-output-display}\n![GitHub: 2020 (grey, left), 2021 (pink, right)](R2021_files/figure-html/unnamed-chunk-1-2.png){fig-align='center' width=25%}\n:::\n:::\n\n\n#### HOW TO ENSURE RSTUDIO FINDS THE CODE\n\nTo use the code, in particular so that R Studio finds the data files etc, create a directory for each topic, (e.g. Trees, ANN etc) and copy the contents from the zip file or GitHub. Then create a new project in R Studio that uses that directory as its home directory, using \"File/New Project\" in the drop down menu. Opening files within a project sets the home directory to that directory, so everything (including the sub-directories) can be found.\n\n------------------------------------------------------------------------\n\n## Day 1: Trees and maps\n\n### 10.30 am -- 12.30 pm\n\nTrees\n\n-   Classification and regression trees\n-   Econometrics strikes back: Bootstrap/bagging and Boosting/Model selection\n-   Random forests\n-   Visualising decision trees\n-   Use example: House prices\n\nThe presentations for this are `Trees.html` and `LondonHP.html`; The two programs `TreeCancer.R` and `TreeNW.R` are the use examples.\n\n### 2.00 pm -- 4.00 pm\n\nMaps in R\n\n-   How to draw a map in R\n-   A guide to some resources\n-   Choropleths\n-   Use examples: Climate change, regional data, postcode wrangling\n\nThe presentation for this is `MapAER.html` (see also `Weatherpretty.html`); The program `MapAERcode.R` is the main map drawing code, I've included `ZAF.R` as as short simple way and source for two countries, and the directory `Trendz` contains the program (`app.R`) and data for the weather example.\n\n\n::: {.cell layout-align=\"right\"}\n::: {.cell-output-display}\n![](R2021_files/figure-html/unnamed-chunk-2-1.png){fig-align='right' width=25% style=\"float:right\"}\n:::\n:::\n\n\nI've included an additional video (red QR code) for more about Shiny. This uses unemployment data from the [Survey of Professional Forecasters](https://www.philadelphiafed.org/surveys-and-data/real-time-data-research/survey-of-professional-forecasters). The code we look at is for climate change data [World Bank data](https://climateknowledgeportal.worldbank.org/).\n\nA comprehensive treatment of maps is @Geocomputation *Geocomputation in R*, but it is quite a lot to assimilate all at once.\n\n<br>\n\n------------------------------------------------------------------------\n\n## Day 2: Networks\n\n### 10.30 am -- 12.30 pm\n\nNeural networks\n\n-   What is an ANN? Deep learning?\n-   Function approximation via a network\n-   Data: fit, validate, test\n-   Network architecture\n-   Use examples: House prices revisited\n\nThe presentation for this is `IntroANN.html`; The program `ANN.R` replicates the ANN estimation. The data used is the same as for Day 1.\n\n### 2.00 pm -- 4.00 pm\n\nNetworks in R\n\n-   DAGs and ANNs as network graphs\n-   Incidence matrices\n-   Measuring connectivity: Degree and betweenness\n-   Plotting with `igraph`\n-   Use examples: Industry inter-relationships\n\n\n::: {.cell layout-align=\"right\"}\n::: {.cell-output-display}\n![](R2021_files/figure-html/unnamed-chunk-3-1.png){fig-align='right' width=25% style=\"float:right\"}\n:::\n\n::: {.cell-output-display}\n![](R2021_files/figure-html/unnamed-chunk-3-2.png){fig-align='right' width=25% style=\"float:right\"}\n:::\n:::\n\n\nThe presentation used for the first part of this is `DAG.html` and the program `Draw_DAG_ANN.R` draws the ANN examples from Day 2 Session 1 as well as some of the DAG examples. The example is modified from @Mixtape *Causal Inference: The Mixtape*, which is a great read with R code. The pdf `HandShake3.pdf` is the source of the director network graphs, and `Graph101a.R` is a subset of the analytical work on the corruption data set as described in the post [*Graph Theory 101*](https://www.r-bloggers.com/2020/01/graph-theory-101-with-corruption-cases-in-spain/) (purple QR code), which is the work of [Marina Medina](https://codingclubuc3m.rbind.io/talk/2020-01-21/) (blue QR code link to presentation site).\n\n------------------------------------------------------------------------\n\n## Day 3: Text\n\n### 10.30 am -- 12.30 pm\n\nText modelling, a 'tidytext' approach (Session 1)\n\n-   Data cleaning\n-   Sentiment\n-   Topic modelling\n\n#### 2.00 pm -- 4.00 pm\n\nText modelling, a 'tidytext' approach (Session 2)\n\n-   Parts-of-speech tagging\n-   Text regression\n-   Use examples: Central bank minutes, reports\n\n------------------------------------------------------------------------\n\n## Finally...\n\nFor me, the best (although slightly dated) text is @ESL [The Elements of Statistical Learning](https://web.stanford.edu/~hastie/ElemStatLearn/) and the best source for the mathematics, with an easy-reading version by some of the same authors @ITSL [Introduction to Statistical Learning](https://www.statlearning.com/).\n\nI also rather like @HOMLR [Hands-On Machine Learning with R](https://bradleyboehmke.github.io/HOML/) which is something of a cookbook rather than a technical manual but with wide scope. @Taddy is more elementary.\n\nOn text, just read @Silge [Text Mining with R: A Tidy Approach](https://www.tidytextmining.com/) and then @SuperText [Supervised Machine Learning for Text Analysis in R](https://smltar.com/). That's it.\n\nTwo books I would solidly recommend to make us all into better statisticians and not just econometricians are @GHV [Regression and Other Stories](http://www.stat.columbia.edu/~gelman/regression), and @McElreath [Statistical Rethinking](https://github.com/rmcelreath/rethinking).\n",
    "supporting": [
      "R2021_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}