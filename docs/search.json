[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Quantiles",
    "section": "",
    "text": "Preface\nThis book is the result of an initiative that the Bank of England began in the early 1990s. This was a different world with a burgeoning new world order, as the Iron Curtain crumbled and the European experiment gathered momentum.\nPlaceholders abound.\nDisclaimer: The Bank of England does not accept any liability for misleading or inaccurate information or omissions in the information provided. The subject matter reflects the views of the individual presenter and not the wider Bank of England or its Policy Committees."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "This is a book created from markdown and executable code.\nSee Blake and Mumtaz (2017).\n\n\n\n\nBlake, Andrew P, and Haroon Mumtaz. 2017. Applied Bayesian Econometrics for Central Bankers. Revised. Technical Books. Centre for Central Banking Studies, Bank of England."
  },
  {
    "objectID": "R2021.html#selected-ml-and-dataviz-techniques-using-r",
    "href": "R2021.html#selected-ml-and-dataviz-techniques-using-r",
    "title": "2  Non-econometric methods for econometricians",
    "section": "2.1 Selected ML and Dataviz techniques using R",
    "text": "2.1 Selected ML and Dataviz techniques using R\nEconometricians are used to handling data, performing analysis and reporting results. But somewhere along the line data became big and unstructured, analysis was now machines learning about something and outputs became visualisations.\nThis online seminar takes some big(ish) datasets, sets the machines on them and draws some great graphs. If you ever wondered what use a tree was for forecasting or why everything is a network (including neural ones), or wanted to draw a map with your house in it, or to understand a document without the bother of reading it (or a few other things besides) then you might find something to interest you. All done in R.\nSpecifically, this seminar is designed to introduce some of the key methods used outside of econometrics that econometricians will find very useful in their work in a central bank. This includes some important machine learning techniques as a gateway to others, particularly tree-based methods and neural networks, as well as text processing and map making. All the way through there is an emphasis on the network properties of many of these techniques. We make extensive use of the tidyverse, including ggplot2 and tidytext, and a number of statistics, machine learning, geographical data and other packages.\nThe framework for each day is the following:\n\nEach day is divided into two two-hour sessions starting at 10.30 am and 2.00 pm GMT.\nThe first hour of each will be an online presentation covering a particular topic (or topics) with a look at both techniques and code.\nAfter a quick break the second hour will be largely devoted to the code itself or resources to understand how to code the material.\n\nWe may run polls during the event to prioritize the topics covered in the webinars as it is not expected that everyone will be able to try out everything.\n\n2.1.1 The code\nAll code and some of the data will be made available through the Juno portal. For each presentation the .Rmd (R markdown) file is supplied that creates the presentation, an HTML file of the presentation for you to step through which can be re-created from the .Rmd file, and a further .R file of the code that we use. Some additional code and data is included, including links to a number of videos that cover some additional aspects both in this file and in the presentations.\nSome data will need to be downloaded from original other sites if all the examples are to be followed. All code is additionally available at https://github.com/andrewpeterblake/R2020 or https://github.com/andrewpeterblake/R2021 or through the QR codes below.\n\n\n\n\n\nGitHub: 2020 (grey, left), 2021 (pink, right)\n\n\n\n\n\n\n\nGitHub: 2020 (grey, left), 2021 (pink, right)"
  },
  {
    "objectID": "R2021.html#day-1-trees-and-maps",
    "href": "R2021.html#day-1-trees-and-maps",
    "title": "2  Non-econometric methods for econometricians",
    "section": "3.1 Day 1: Trees and maps",
    "text": "3.1 Day 1: Trees and maps\n\n3.1.1 10.30 am – 12.30 pm\nTrees\n\nClassification and regression trees\nEconometrics strikes back: Bootstrap/bagging and Boosting/Model selection\nRandom forests\nVisualising decision trees\nUse example: House prices\n\nThe presentations for this are Trees.html and LondonHP.html; The two programs TreeCancer.R and TreeNW.R are the use examples.\n\n\n3.1.2 2.00 pm – 4.00 pm\nMaps in R\n\nHow to draw a map in R\nA guide to some resources\nChoropleths\nUse examples: Climate change, regional data, postcode wrangling\n\nThe presentation for this is MapAER.html (see also Weatherpretty.html); The program MapAERcode.R is the main map drawing code, I’ve included ZAF.R as as short simple way and source for two countries, and the directory Trendz contains the program (app.R) and data for the weather example.\n\n\n\n\n\n\n\n\n\nI’ve included an additional video (red QR code) for more about Shiny. This uses unemployment data from the Survey of Professional Forecasters. The code we look at is for climate change data World Bank data.\nA comprehensive treatment of maps is Lovelace, Nowosad, and Muenchow (2019) Geocomputation in R, but it is quite a lot to assimilate all at once."
  },
  {
    "objectID": "R2021.html#day-2-networks",
    "href": "R2021.html#day-2-networks",
    "title": "2  Non-econometric methods for econometricians",
    "section": "3.2 Day 2: Networks",
    "text": "3.2 Day 2: Networks\n\n3.2.1 10.30 am – 12.30 pm\nNeural networks\n\nWhat is an ANN? Deep learning?\nFunction approximation via a network\nData: fit, validate, test\nNetwork architecture\nUse examples: House prices revisited\n\nThe presentation for this is IntroANN.html; The program ANN.R replicates the ANN estimation. The data used is the same as for Day 1.\n\n\n3.2.2 2.00 pm – 4.00 pm\nNetworks in R\n\nDAGs and ANNs as network graphs\nIncidence matrices\nMeasuring connectivity: Degree and betweenness\nPlotting with igraph\nUse examples: Industry inter-relationships\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe presentation used for the first part of this is DAG.html and the program Draw_DAG_ANN.R draws the ANN examples from Day 2 Session 1 as well as some of the DAG examples. The example is modified from Cunningham (2021) Causal Inference: The Mixtape, which is a great read with R code. The pdf HandShake3.pdf is the source of the director network graphs, and Graph101a.R is a subset of the analytical work on the corruption data set as described in the post Graph Theory 101 (purple QR code), which is the work of Marina Medina (blue QR code link to presentation site)."
  },
  {
    "objectID": "R2021.html#day-3-text",
    "href": "R2021.html#day-3-text",
    "title": "2  Non-econometric methods for econometricians",
    "section": "3.3 Day 3: Text",
    "text": "3.3 Day 3: Text\n\n3.3.1 10.30 am – 12.30 pm\nText modelling, a ‘tidytext’ approach (Session 1)\n\nData cleaning\nSentiment\nTopic modelling\n\n\n\n3.3.2 2.00 pm – 4.00 pm\nText modelling, a ‘tidytext’ approach (Session 2)\n\nParts-of-speech tagging\nText regression\nUse examples: Central bank minutes, reports\n\n\n\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. New Haven & London: Yale University Press. https://mixtape.scunning.com/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. The R Series. Boca Raton: Chapman & Hall/CRC. https://geocompr.robinlovelace.net/."
  },
  {
    "objectID": "R2021.html#finally",
    "href": "R2021.html#finally",
    "title": "2  Non-econometric methods for econometricians",
    "section": "2.5 Finally…",
    "text": "2.5 Finally…\nFor me, the best (although slightly dated) text is Hastie, Tibshirani, and Friedman (2009) The Elements of Statistical Learning and the best source for the mathematics, with an easy-reading version by some of the same authors James et al. (2021) Introduction to Statistical Learning.\nI also rather like Boehmke and Greenwell (2019) Hands-On Machine Learning with R which is something of a cookbook rather than a technical manual but with wide scope. Taddy (2019) is more elementary.\nOn text, just read Silge and Robinson (2017) Text Mining with R: A Tidy Approach and then Hvitfeldt and Silge (2021) Supervised Machine Learning for Text Analysis in R. That’s it.\nTwo books I would solidly recommend to make us all into better statisticians and not just econometricians are Gelman, Hill, and Vehtari (2019) Regression and Other Stories, and McElreath (2020) Statistical Rethinking.\n\n\n\n\nBoehmke, Brad, and Brandon M. Greenwell. 2019. Hands-on Machine Learning with R. The R Series. Boca Raton: Chapman & Hall/CRC. https://bradleyboehmke.github.io/HOML/.\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. New Haven & London: Yale University Press. https://mixtape.scunning.com/.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2019. Regression and Other Stories. Cambridge: Cambridge University Press. http://www.stat.columbia.edu/~gelman/regression.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. 2nd ed. New York, NY: Springer. https://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine Learning for Text Analysis in R. Chapman & Hall: CRC Press. https://smltar.com/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. 2nd ed. Springer Texts in Statistics. New York, NY: Springer. https://www.statlearning.com/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. The R Series. Boca Raton: Chapman & Hall/CRC. https://geocompr.robinlovelace.net/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd ed. Abingdon, Oxfordshire: CRC Press. https://github.com/rmcelreath/rethinking.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. O’Reilly. https://www.tidytextmining.com/.\n\n\nTaddy, Matt. 2019. Business Data Science: Combining Machine Learning and Economics to Optimize, Automate, and Accelerate Business Decisions. New York, NY: McGraw-Hill Education. https://github.com/TaddyLab/BDS."
  },
  {
    "objectID": "QR.html#getting-the-data",
    "href": "QR.html#getting-the-data",
    "title": "3  Quantile regression in R",
    "section": "3.1 Getting the data",
    "text": "3.1 Getting the data\nWe download the data and save it locally.\n\nh <- \"https://www.philadelphiafed.org/-/media/frbp/assets/surveys-and-data/survey-of-professional-forecasters/historical-data/\"\nf <- \"meanlevel.xlsx\"\n\ndownload.file(paste0(h, f), destfile=f, mode=\"wb\")\n\nRetrieve the unemployment data for the average unemployment forecast.\n\nUNEMP <- f %>%\n  read_excel(na=\"#N/A\", sheet=\"UNEMP\") %>% \n  mutate(Date=as.Date(as.yearqtr(paste(YEAR, QUARTER), format=\"%Y %q\"))) \n\nUsel <- UNEMP %>% \n  select(Date, UNEMP1, UNEMP3, UNEMP4, UNEMP5, UNEMP6) %>%\n  mutate(UNRATE = lead(UNEMP1,1)) %>%\n  select(Date, UNRATE, \n         UNEMP1=UNEMP3, UNEMP2=UNEMP4, UNEMP3=UNEMP5, UNEMP4=UNEMP6) %>%\n  mutate(UNEMP1 = lag(UNEMP1,1), \n         UNEMP2 = lag(UNEMP2,2), \n         UNEMP3 = lag(UNEMP3,3), \n         UNEMP4 = lag(UNEMP4,4)) %>%\n  pivot_longer(cols = -c(Date, UNRATE), names_to=\"Which\", values_to=\"Val\") %>%\n  filter(year(Date) > 2000)"
  },
  {
    "objectID": "Stemp.html#study-question-1.3.2",
    "href": "Stemp.html#study-question-1.3.2",
    "title": "4  Causal Inference in Statistics: Pearl, Glymour, Jewell",
    "section": "4.1 Study question 1.3.2",
    "text": "4.1 Study question 1.3.2\nData:\n\nlibrary(tidyverse)\ned <- tibble(Gender = c(\"M\",\"M\",\"M\",\"M\",\"F\",\"F\",\"F\",\"F\"),\n             eLevel = c(\"U\",\"H\",\"C\",\"G\",\"U\",\"H\",\"C\",\"G\"),\n             num    = c(112,231,595,242,136,189,763,172)) %>%\n  mutate(total = sum(num))\n\nwhich we tabulate as\n\ned %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\n\n\n\n\nM\nU\n112\n2440\n\n\nM\nH\n231\n2440\n\n\nM\nC\n595\n2440\n\n\nM\nG\n242\n2440\n\n\nF\nU\n136\n2440\n\n\nF\nH\n189\n2440\n\n\nF\nC\n763\n2440\n\n\nF\nG\n172\n2440"
  },
  {
    "objectID": "Stemp.html#answers",
    "href": "Stemp.html#answers",
    "title": "4  Causal Inference in Statistics: Pearl, Glymour, Jewell",
    "section": "4.2 Answers",
    "text": "4.2 Answers\n\n4.2.1 Wnat is \\(P(eLevel = H)\\)?\n\ned %>%\n  filter(eLevel == \"H\") %>%\n  mutate(p_H = n()/total) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\np_H\n\n\n\n\nM\nH\n231\n2440\n0.0008197\n\n\nF\nH\n189\n2440\n0.0008197\n\n\n\n\n\n\\[\nP(eLevel = H\\ \\vee \\ Gender = F)\n\\]\n\ned %>%\n  filter(Gender == \"F\" | eLevel == \"H\") %>%\n  mutate(p_HorF = sum(num)/total) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\np_HorF\n\n\n\n\nM\nH\n231\n2440\n0.6110656\n\n\nF\nU\n136\n2440\n0.6110656\n\n\nF\nH\n189\n2440\n0.6110656\n\n\nF\nC\n763\n2440\n0.6110656\n\n\nF\nG\n172\n2440\n0.6110656\n\n\n\n\n\n\\[\nP(eLevel = H\\ |\\ Gender = F)\n\\]\n\ned %>%\n  filter(Gender == \"F\") %>%\n  mutate(tcond = sum(num)) %>% \n  filter(eLevel == \"H\") %>%\n  mutate(p_HgivenF = sum(num)/tcond) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\ntcond\np_HgivenF\n\n\n\n\nF\nH\n189\n2440\n1260\n0.15\n\n\n\n\n\n\\[\nP(Gender = F\\ | \\ eLevel = H)\n\\]\n\ned %>%\n  filter(eLevel == \"H\") %>%\n  mutate(tcond = sum(num)) %>% \n  filter(Gender == \"F\") %>%\n  mutate(p_FgivenH = sum(num)/tcond) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\ntcond\np_FgivenH\n\n\n\n\nF\nH\n189\n2440\n420\n0.45\n\n\n\n\n\n\n\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester: John Wiley & Sons. http://bayes.cs.ucla.edu/PRIMER/."
  },
  {
    "objectID": "summary.html",
    "href": "summary.html",
    "title": "5  Summary",
    "section": "",
    "text": "In summary, this book has no content whatsoever…"
  },
  {
    "objectID": "references.html",
    "href": "references.html",
    "title": "References",
    "section": "",
    "text": "Blake, Andrew P, and Haroon Mumtaz. 2017. Applied Bayesian\nEconometrics for Central Bankers. Revised. Technical Books. Centre\nfor Central Banking Studies, Bank of England.\n\n\nBoehmke, Brad, and Brandon M. Greenwell. 2019. Hands-on Machine\nLearning with R. The R Series. Boca\nRaton: Chapman & Hall/CRC. https://bradleyboehmke.github.io/HOML/.\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. New\nHaven & London: Yale University Press. https://mixtape.scunning.com/.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2019. Regression and\nOther Stories. Cambridge: Cambridge University Press. http://www.stat.columbia.edu/~gelman/regression.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The\nElements of Statistical Learning: Data Mining, Inference, and\nPrediction. 2nd ed. New York, NY: Springer. https://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine Learning\nfor Text Analysis in R. Chapman & Hall: CRC Press.\nhttps://smltar.com/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.\n2021. An Introduction to Statistical Learning: With Applications in\nR. 2nd ed. Springer Texts in Statistics. New York, NY:\nSpringer. https://www.statlearning.com/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019.\nGeocomputation with R. 1st ed. The R\nSeries. Boca Raton: Chapman & Hall/CRC. https://geocompr.robinlovelace.net/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course\nwith Examples in R and Stan. 2nd ed. Abingdon,\nOxfordshire: CRC Press. https://github.com/rmcelreath/rethinking.\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal\nInference in Statistics: A Primer. Chichester: John Wiley &\nSons. http://bayes.cs.ucla.edu/PRIMER/.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with\nR: A Tidy Approach. O’Reilly. https://www.tidytextmining.com/.\n\n\nTaddy, Matt. 2019. Business Data Science: Combining Machine Learning\nand Economics to Optimize, Automate, and Accelerate Business\nDecisions. New York, NY: McGraw-Hill Education. https://github.com/TaddyLab/BDS."
  },
  {
    "objectID": "intro.html#reading-is-good-for-you",
    "href": "intro.html#reading-is-good-for-you",
    "title": "1  Introduction",
    "section": "1.1 Reading is good for you",
    "text": "1.1 Reading is good for you\nFor me, the best (although slightly dated) text is Hastie, Tibshirani, and Friedman (2009) The Elements of Statistical Learning and the best source for the mathematics, with an easy-reading version by some of the same authors James et al. (2021) Introduction to Statistical Learning.\nI also rather like Boehmke and Greenwell (2019) Hands-On Machine Learning with R which is something of a cookbook rather than a technical manual but with wide scope. Taddy (2019) is more elementary.\nOn text, just read Silge and Robinson (2017) Text Mining with R: A Tidy Approach and then Hvitfeldt and Silge (2021) Supervised Machine Learning for Text Analysis in R. That’s it.\nTwo books I would solidly recommend to make us all into better statisticians and not just econometricians are Gelman, Hill, and Vehtari (2019) Regression and Other Stories, and McElreath (2020) Statistical Rethinking.\n\n\n\n\nBlake, Andrew P, and Haroon Mumtaz. 2017. Applied Bayesian Econometrics for Central Bankers. Revised. Technical Books. Centre for Central Banking Studies, Bank of England.\n\n\nBoehmke, Brad, and Brandon M. Greenwell. 2019. Hands-on Machine Learning with R. The R Series. Boca Raton: Chapman & Hall/CRC. https://bradleyboehmke.github.io/HOML/.\n\n\nGelman, Andrew, Jennifer Hill, and Aki Vehtari. 2019. Regression and Other Stories. Cambridge: Cambridge University Press. http://www.stat.columbia.edu/~gelman/regression.\n\n\nHastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. The Elements of Statistical Learning: Data Mining, Inference, and Prediction. 2nd ed. New York, NY: Springer. https://web.stanford.edu/~hastie/ElemStatLearn/.\n\n\nHvitfeldt, Emil, and Julia Silge. 2021. Supervised Machine Learning for Text Analysis in R. Chapman & Hall: CRC Press. https://smltar.com/.\n\n\nJames, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani. 2021. An Introduction to Statistical Learning: With Applications in R. 2nd ed. Springer Texts in Statistics. New York, NY: Springer. https://www.statlearning.com/.\n\n\nMcElreath, Richard. 2020. Statistical Rethinking: A Bayesian Course with Examples in R and Stan. 2nd ed. Abingdon, Oxfordshire: CRC Press. https://github.com/rmcelreath/rethinking.\n\n\nSilge, Julia, and David Robinson. 2017. Text Mining with R: A Tidy Approach. O’Reilly. https://www.tidytextmining.com/.\n\n\nTaddy, Matt. 2019. Business Data Science: Combining Machine Learning and Economics to Optimize, Automate, and Accelerate Business Decisions. New York, NY: McGraw-Hill Education. https://github.com/TaddyLab/BDS."
  },
  {
    "objectID": "R2021.html#how-to-ensure-rstudio-finds-the-code",
    "href": "R2021.html#how-to-ensure-rstudio-finds-the-code",
    "title": "2  Non-econometric methods for econometricians",
    "section": "2.2 HOW TO ENSURE RSTUDIO FINDS THE CODE",
    "text": "2.2 HOW TO ENSURE RSTUDIO FINDS THE CODE\nTo use the code, in particular so that R Studio finds the data files etc, create a directory for each topic, (e.g. Trees, ANN etc) and copy the contents from the zip file or GitHub. Then create a new project in R Studio that uses that directory as its home directory, using “File/New Project” in the drop down menu. Opening files within a project sets the home directory to that directory, so everything (including the sub-directories) can be found."
  },
  {
    "objectID": "R2021.html",
    "href": "R2021.html",
    "title": "2  Non-econometric methods for econometricians",
    "section": "",
    "text": "3 Typical program structure"
  },
  {
    "objectID": "R2021.html#typical-program-structure",
    "href": "R2021.html#typical-program-structure",
    "title": "2  Non-econometric methods for econometricians",
    "section": "2.3 Typical program structure",
    "text": "2.3 Typical program structure\n\n2.3.1 Day 1: Trees and maps\n\n2.3.1.1 Trees\n\nClassification and regression trees\nEconometrics strikes back: Bootstrap/bagging and Boosting/Model selection\nRandom forests\nVisualising decision trees\nUse example: House prices\n\nThe presentations for this are Trees.html and LondonHP.html; The two programs TreeCancer.R and TreeNW.R are the use examples.\n\n\n2.3.1.2 Maps\n\nHow to draw a map in R\nA guide to some resources\nChoropleths\nUse examples: Climate change, regional data, postcode wrangling\n\nThe presentation for this is MapAER.html (see also Weatherpretty.html); The program MapAERcode.R is the main map drawing code, I’ve included ZAF.R as as short simple way and source for two countries, and the directory Trendz contains the program (app.R) and data for the weather example.\n\n\n\n\n\n\n\n\n\nI’ve included an additional video (red QR code) for more about Shiny. This uses unemployment data from the Survey of Professional Forecasters. The code we look at is for climate change data World Bank data.\nA comprehensive treatment of maps is Lovelace, Nowosad, and Muenchow (2019) Geocomputation in R, but it is quite a lot to assimilate all at once.\n\n\n\n\n\n2.3.2 Day 2: Networks\n\n2.3.2.1 Neural networks\n\nWhat is an ANN? Deep learning?\nFunction approximation via a network\nData: fit, validate, test\nNetwork architecture\nUse examples: House prices revisited\n\nThe presentation for this is IntroANN.html; The program ANN.R replicates the ANN estimation. The data used is the same as for Day 1.\n\n\n2.3.2.2 Networks (real ones)\n\nDAGs and ANNs as network graphs\nIncidence matrices\nMeasuring connectivity: Degree and betweenness\nPlotting with igraph\nUse examples: Industry inter-relationships\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\nThe presentation used for the first part of this is DAG.html and the program Draw_DAG_ANN.R draws the ANN examples from Day 2 Session 1 as well as some of the DAG examples. The example is modified from Cunningham (2021) Causal Inference: The Mixtape, which is a great read with R code. The pdf HandShake3.pdf is the source of the director network graphs, and Graph101a.R is a subset of the analytical work on the corruption data set as described in the post Graph Theory 101 (purple QR code), which is the work of Marina Medina (blue QR code link to presentation site).\n\n\n\n\n2.3.3 Day 3: Text\n\n2.3.3.1 Text modelling, a ‘tidytext’ approach (Session 1)\n\nData cleaning\nSentiment\nTopic modelling\n\n\n\n2.3.3.2 Text modelling, a ‘tidytext’ approach (Session 2)\n\nParts-of-speech tagging\nText regression\nUse examples: Central bank minutes, reports\n\n\n\n\n\nCunningham, Scott. 2021. Causal Inference: The Mixtape. New Haven & London: Yale University Press. https://mixtape.scunning.com/.\n\n\nLovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019. Geocomputation with R. 1st ed. The R Series. Boca Raton: Chapman & Hall/CRC. https://geocompr.robinlovelace.net/."
  },
  {
    "objectID": "QR.html#plots",
    "href": "QR.html#plots",
    "title": "3  Quantile regression in R",
    "section": "3.2 Plots",
    "text": "3.2 Plots\n\nUsel %>% \n  ggplot(aes(x=Date)) + \n  geom_line(aes(y=UNRATE), colour=\"red\") + \n  geom_point(aes(y=Val, colour=Which, shape=Which)) +\n  theme_light() + \n  labs(title=\"Mean unemployment forecasts\", x=\"\",y=\"\", caption = \"Source: SPF\")"
  },
  {
    "objectID": "Stemp.html#exercises-and-answers",
    "href": "Stemp.html#exercises-and-answers",
    "title": "4  Causal Inference in Statistics: Pearl, Glymour, Jewell",
    "section": "4.2 Exercises and answers",
    "text": "4.2 Exercises and answers\n\n4.2.1 Find \\(P(eLevel = H)\\)\n\ned %>%\n  filter(eLevel == \"H\") %>%\n  mutate(p_H = n()/total) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\np_H\n\n\n\n\nM\nH\n231\n2440\n0.0008197\n\n\nF\nH\n189\n2440\n0.0008197\n\n\n\n\n\n\n\n4.2.2 Find \\(P(eLevel = H\\ \\vee \\ Gender = F)\\)\n\ned %>%\n  filter(Gender == \"F\" | eLevel == \"H\") %>%\n  mutate(p_HorF = sum(num)/total) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\np_HorF\n\n\n\n\nM\nH\n231\n2440\n0.6110656\n\n\nF\nU\n136\n2440\n0.6110656\n\n\nF\nH\n189\n2440\n0.6110656\n\n\nF\nC\n763\n2440\n0.6110656\n\n\nF\nG\n172\n2440\n0.6110656\n\n\n\n\n\n\n\n4.2.3 Find \\(P(eLevel = H\\ |\\ Gender = F)\\)\n\ned %>%\n  filter(Gender == \"F\") %>%\n  mutate(tcond = sum(num)) %>% \n  filter(eLevel == \"H\") %>%\n  mutate(p_HgivenF = sum(num)/tcond) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\ntcond\np_HgivenF\n\n\n\n\nF\nH\n189\n2440\n1260\n0.15\n\n\n\n\n\n\n\n4.2.4 Find \\(P(Gender = F\\ | \\ eLevel = H)\\)\n\ned %>%\n  filter(eLevel == \"H\") %>%\n  mutate(tcond = sum(num)) %>% \n  filter(Gender == \"F\") %>%\n  mutate(p_FgivenH = sum(num)/tcond) %>%\n  kable()\n\n\n\n\nGender\neLevel\nnum\ntotal\ntcond\np_FgivenH\n\n\n\n\nF\nH\n189\n2440\n420\n0.45\n\n\n\n\n\n\n\n\n\nPearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016. Causal Inference in Statistics: A Primer. Chichester: John Wiley & Sons. http://bayes.cs.ucla.edu/PRIMER/."
  }
]