% Options for packages loaded elsewhere
\PassOptionsToPackage{unicode}{hyperref}
\PassOptionsToPackage{hyphens}{url}
%
\documentclass[
  letterpaper,
]{book}

\usepackage{amsmath,amssymb}
\usepackage{iftex}
\ifPDFTeX
  \usepackage[T1]{fontenc}
  \usepackage[utf8]{inputenc}
  \usepackage{textcomp} % provide euro and other symbols
\else % if luatex or xetex
  \usepackage{unicode-math}
  \defaultfontfeatures{Scale=MatchLowercase}
  \defaultfontfeatures[\rmfamily]{Ligatures=TeX,Scale=1}
\fi
\usepackage{lmodern}
\ifPDFTeX\else  
    % xetex/luatex font selection
\fi
% Use upquote if available, for straight quotes in verbatim environments
\IfFileExists{upquote.sty}{\usepackage{upquote}}{}
\IfFileExists{microtype.sty}{% use microtype if available
  \usepackage[]{microtype}
  \UseMicrotypeSet[protrusion]{basicmath} % disable protrusion for tt fonts
}{}
\makeatletter
\@ifundefined{KOMAClassName}{% if non-KOMA class
  \IfFileExists{parskip.sty}{%
    \usepackage{parskip}
  }{% else
    \setlength{\parindent}{0pt}
    \setlength{\parskip}{6pt plus 2pt minus 1pt}}
}{% if KOMA class
  \KOMAoptions{parskip=half}}
\makeatother
\usepackage{xcolor}
\setlength{\emergencystretch}{3em} % prevent overfull lines
\setcounter{secnumdepth}{5}
% Make \paragraph and \subparagraph free-standing
\ifx\paragraph\undefined\else
  \let\oldparagraph\paragraph
  \renewcommand{\paragraph}[1]{\oldparagraph{#1}\mbox{}}
\fi
\ifx\subparagraph\undefined\else
  \let\oldsubparagraph\subparagraph
  \renewcommand{\subparagraph}[1]{\oldsubparagraph{#1}\mbox{}}
\fi

\usepackage{color}
\usepackage{fancyvrb}
\newcommand{\VerbBar}{|}
\newcommand{\VERB}{\Verb[commandchars=\\\{\}]}
\DefineVerbatimEnvironment{Highlighting}{Verbatim}{commandchars=\\\{\}}
% Add ',fontsize=\small' for more characters per line
\usepackage{framed}
\definecolor{shadecolor}{RGB}{241,243,245}
\newenvironment{Shaded}{\begin{snugshade}}{\end{snugshade}}
\newcommand{\AlertTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\AnnotationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\AttributeTok}[1]{\textcolor[rgb]{0.40,0.45,0.13}{#1}}
\newcommand{\BaseNTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\BuiltInTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\CharTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\CommentTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\CommentVarTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ConstantTok}[1]{\textcolor[rgb]{0.56,0.35,0.01}{#1}}
\newcommand{\ControlFlowTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\DataTypeTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DecValTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\DocumentationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}
\newcommand{\ErrorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\ExtensionTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\FloatTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\FunctionTok}[1]{\textcolor[rgb]{0.28,0.35,0.67}{#1}}
\newcommand{\ImportTok}[1]{\textcolor[rgb]{0.00,0.46,0.62}{#1}}
\newcommand{\InformationTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\KeywordTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\NormalTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\OperatorTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\OtherTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\PreprocessorTok}[1]{\textcolor[rgb]{0.68,0.00,0.00}{#1}}
\newcommand{\RegionMarkerTok}[1]{\textcolor[rgb]{0.00,0.23,0.31}{#1}}
\newcommand{\SpecialCharTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{#1}}
\newcommand{\SpecialStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\StringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\VariableTok}[1]{\textcolor[rgb]{0.07,0.07,0.07}{#1}}
\newcommand{\VerbatimStringTok}[1]{\textcolor[rgb]{0.13,0.47,0.30}{#1}}
\newcommand{\WarningTok}[1]{\textcolor[rgb]{0.37,0.37,0.37}{\textit{#1}}}

\providecommand{\tightlist}{%
  \setlength{\itemsep}{0pt}\setlength{\parskip}{0pt}}\usepackage{longtable,booktabs,array}
\usepackage{calc} % for calculating minipage widths
% Correct order of tables after \paragraph or \subparagraph
\usepackage{etoolbox}
\makeatletter
\patchcmd\longtable{\par}{\if@noskipsec\mbox{}\fi\par}{}{}
\makeatother
% Allow footnotes in longtable head/foot
\IfFileExists{footnotehyper.sty}{\usepackage{footnotehyper}}{\usepackage{footnote}}
\makesavenoteenv{longtable}
\usepackage{graphicx}
\makeatletter
\def\maxwidth{\ifdim\Gin@nat@width>\linewidth\linewidth\else\Gin@nat@width\fi}
\def\maxheight{\ifdim\Gin@nat@height>\textheight\textheight\else\Gin@nat@height\fi}
\makeatother
% Scale images if necessary, so that they will not overflow the page
% margins by default, and it is still possible to overwrite the defaults
% using explicit options in \includegraphics[width, height, ...]{}
\setkeys{Gin}{width=\maxwidth,height=\maxheight,keepaspectratio}
% Set default figure placement to htbp
\makeatletter
\def\fps@figure{htbp}
\makeatother
\newlength{\cslhangindent}
\setlength{\cslhangindent}{1.5em}
\newlength{\csllabelwidth}
\setlength{\csllabelwidth}{3em}
\newlength{\cslentryspacingunit} % times entry-spacing
\setlength{\cslentryspacingunit}{\parskip}
\newenvironment{CSLReferences}[2] % #1 hanging-ident, #2 entry spacing
 {% don't indent paragraphs
  \setlength{\parindent}{0pt}
  % turn on hanging indent if param 1 is 1
  \ifodd #1
  \let\oldpar\par
  \def\par{\hangindent=\cslhangindent\oldpar}
  \fi
  % set entry spacing
  \setlength{\parskip}{#2\cslentryspacingunit}
 }%
 {}
\usepackage{calc}
\newcommand{\CSLBlock}[1]{#1\hfill\break}
\newcommand{\CSLLeftMargin}[1]{\parbox[t]{\csllabelwidth}{#1}}
\newcommand{\CSLRightInline}[1]{\parbox[t]{\linewidth - \csllabelwidth}{#1}\break}
\newcommand{\CSLIndent}[1]{\hspace{\cslhangindent}#1}

\usepackage{makeidx}
\makeindex
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\@ifpackageloaded{fontawesome5}{}{\usepackage{fontawesome5}}
\definecolor{quarto-callout-color}{HTML}{909090}
\definecolor{quarto-callout-note-color}{HTML}{0758E5}
\definecolor{quarto-callout-important-color}{HTML}{CC1914}
\definecolor{quarto-callout-warning-color}{HTML}{EB9113}
\definecolor{quarto-callout-tip-color}{HTML}{00A047}
\definecolor{quarto-callout-caution-color}{HTML}{FC5300}
\definecolor{quarto-callout-color-frame}{HTML}{acacac}
\definecolor{quarto-callout-note-color-frame}{HTML}{4582ec}
\definecolor{quarto-callout-important-color-frame}{HTML}{d9534f}
\definecolor{quarto-callout-warning-color-frame}{HTML}{f0ad4e}
\definecolor{quarto-callout-tip-color-frame}{HTML}{02b875}
\definecolor{quarto-callout-caution-color-frame}{HTML}{fd7e14}
\makeatother
\makeatletter
\makeatother
\makeatletter
\@ifpackageloaded{bookmark}{}{\usepackage{bookmark}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\AtBeginDocument{%
\ifdefined\contentsname
  \renewcommand*\contentsname{Table of contents}
\else
  \newcommand\contentsname{Table of contents}
\fi
\ifdefined\listfigurename
  \renewcommand*\listfigurename{List of Figures}
\else
  \newcommand\listfigurename{List of Figures}
\fi
\ifdefined\listtablename
  \renewcommand*\listtablename{List of Tables}
\else
  \newcommand\listtablename{List of Tables}
\fi
\ifdefined\figurename
  \renewcommand*\figurename{Figure}
\else
  \newcommand\figurename{Figure}
\fi
\ifdefined\tablename
  \renewcommand*\tablename{Table}
\else
  \newcommand\tablename{Table}
\fi
}
\@ifpackageloaded{float}{}{\usepackage{float}}
\floatstyle{ruled}
\@ifundefined{c@chapter}{\newfloat{codelisting}{h}{lop}}{\newfloat{codelisting}{h}{lop}[chapter]}
\floatname{codelisting}{Listing}
\newcommand*\listoflistings{\listof{codelisting}{List of Listings}}
\makeatother
\makeatletter
\@ifpackageloaded{caption}{}{\usepackage{caption}}
\@ifpackageloaded{subcaption}{}{\usepackage{subcaption}}
\makeatother
\makeatletter
\@ifpackageloaded{tcolorbox}{}{\usepackage[skins,breakable]{tcolorbox}}
\makeatother
\makeatletter
\@ifundefined{shadecolor}{\definecolor{shadecolor}{rgb}{.97, .97, .97}}
\makeatother
\makeatletter
\makeatother
\makeatletter
\makeatother
\ifLuaTeX
  \usepackage{selnolig}  % disable illegal ligatures
\fi
\IfFileExists{bookmark.sty}{\usepackage{bookmark}}{\usepackage{hyperref}}
\IfFileExists{xurl.sty}{\usepackage{xurl}}{} % add URL line breaks if available
\urlstyle{same} % disable monospaced font for URLs
\hypersetup{
  pdftitle={Quantiles, Networks, Time},
  pdfauthor={andrew p blake},
  hidelinks,
  pdfcreator={LaTeX via pandoc}}

\title{Quantiles, Networks, Time}
\author{andrew p blake}
\date{2024-01-01}

\begin{document}
\frontmatter
\maketitle
\ifdefined\Shaded\renewenvironment{Shaded}{\begin{tcolorbox}[borderline west={3pt}{0pt}{shadecolor}, sharp corners, interior hidden, breakable, boxrule=0pt, enhanced, frame hidden]}{\end{tcolorbox}}\fi

\renewcommand*\contentsname{Table of contents}
{
\setcounter{tocdepth}{2}
\tableofcontents
}
\listoffigures
\listoftables
\mainmatter
\bookmarksetup{startatroot}

\hypertarget{sec-genesis}{%
\chapter*{Genesis}\label{sec-genesis}}
\addcontentsline{toc}{chapter}{Genesis}

\markboth{Genesis}{Genesis}

Central banks have been around quite a while. They began as a useful
institution that mostly benefited banks, and were not universally seen
as something that particularly benefited society. Central banking was
long associated with grey men in grey suits, pondering deeply the
impenetrable machinations of high finance, fuelled by cigar smoke and
mystique. In truth, this -- at best -- Capraesque view of central
bankers is substantially out of date, and has been for decades. They are
no longer monochrome, or exclusively male, and need skills their
forebears could have barely imagined -- and they have most decidedly
different priorities.

In particular, they exist in an environment where the substantial
expertise embodied in their staff members for the very particular -- and
evolving -- challenges of central banking could usefully be shared.
Global challenges need often need global solutions, and local challenges
are faced everywhere and someone, somewhere has probably faced the same
one as you. Recognising this led to a particular initiative taken by the
Bank of England in the early 1990s. It was decided that the Bank should
create a forum where the central bankers of the world could gather to
commune, discuss, and above all, learn together.

The timing, of course, was not incidental, and the initiative turned out
to be a prescient one. This was at a major historical turning point, one
that signalled a burgeoning new world order, as the Iron Curtain
crumbled, the European experiment gathered momentum, and industrial
might continued an inexorable shift eastwards. Economic policy had
shifted too. Monetary policy was beginning a new and -- as it turned out
-- lasting phase. There was indeed much to learn, and new monetary
policy needed new approaches better suited to those policies.
(Post-Great Financial Crisis, the necessary tool kit would expand
again.)

And so the Centre for Central Banking Studies was founded.
\href{https://www.bankofengland.co.uk/-/media/boe/files/quarterly-bulletin/2006/the-centre-for-central-banking-studies.pdf}{Hammond
(2006)} provides a history of the early years of the CCBS, charting an
ambitious project that had an immediate impact on international central
banking practices. More than thirty years later it remains a key forum
for learning, discussion and networking, just as intended. Literally
thousands of central bankers have taken part in CCBS events, and many
alumni now occupy senior policymaking positions around the world.
Activities have evolved to include many more of the disparate areas of
responsibility that now involve the central banking community, and with
a truly global reach.

This book is about a small part of that output. It is (mostly) about
applied economics and central banking. It is born of the experience of
the many who have participated in events over the years, with literally
thousands of suggestions that have improved and expanded the content
delivered to properly reflect the daily concerns of the central bank
economist.

Mostly, but not entirely. Mostly, because the tool kit continues to
expand and the techniques of data analysis evolve. We are all data
scientists of some sort now, with a domain specialisation of central
banking. And that domain is somewhat different to economists in academia
or industry, with more of a focus on what we might dub causal
forecasting. Underlying much of central bank analysis are a number of
useful statistical methods and machine learning models that complement
the default econometric approach. Taken together these constitute a
language that central bankers need to understand. Some of this book is
about how to build, interpret, and use models that used to be anathema
to the econometrician but are increasingly part of the predictive
landscape.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{Yogyakarta.jpg}

}

\caption{Puppet, Yogyakarta}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{AbuDhabi.jpg}

}

\caption{Abu Dhabi, United Arab Emirates}

}

\end{minipage}%
\newline
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{Specs.gif}

}

\caption{Villa Sterne, Pretoria}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{Korea.jpg}

}

\caption{Insadong, Seoul}

}

\end{minipage}%

\end{figure}

\begin{figure}

{\centering \includegraphics{Montevideo.jpg}

}

\caption{Old Town, Montevideo}

\end{figure}

Placeholders abound.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, arc=.35mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Disclaimer}, colbacktitle=quarto-callout-note-color!10!white, bottomtitle=1mm, opacityback=0, colframe=quarto-callout-note-color-frame, toprule=.15mm, titlerule=0mm, left=2mm, bottomrule=.15mm, colback=white, leftrule=.75mm, coltitle=black]

The Bank of England does not accept any liability for misleading or
inaccurate information or omissions in the information provided. The
subject matter reflects the views of the author and not the wider Bank
of England or its Policy Committees.

\end{tcolorbox}

\part{Methods matter}

\hypertarget{introduction}{%
\chapter{Introduction}\label{introduction}}

This is a book created using \href{quarto.org}{Quarto} and includes all
examples as executable code.

See Andrew P. Blake and Mumtaz (2017).

\hypertarget{reading-is-good-for-you}{%
\section{Reading is good for you}\label{reading-is-good-for-you}}

For me, the best (although slightly dated) text is Hastie, Tibshirani,
and Friedman (2009)
\href{https://web.stanford.edu/~hastie/ElemStatLearn/}{The Elements of
Statistical Learning} and the best source for the mathematics, with an
easy-reading version by some of the same authors James et al. (2021)
\href{https://www.statlearning.com/}{Introduction to Statistical
Learning}.

I also rather like Boehmke and Greenwell (2019)
\href{https://bradleyboehmke.github.io/HOML/}{Hands-On Machine Learning
with R} which is something of a cookbook rather than a technical manual
but with wide scope. Taddy (2019) is more elementary.

On text, just read Silge and Robinson (2017)
\href{https://www.tidytextmining.com/}{Text Mining with R: A Tidy
Approach} and then Hvitfeldt and Silge (2021)
\href{https://smltar.com/}{Supervised Machine Learning for Text Analysis
in R}. That's it.

Two books I would solidly recommend to make us all into better
statisticians and not just econometricians are Gelman, Hill, and Vehtari
(2019) \href{http://www.stat.columbia.edu/~gelman/regression}{Regression
and Other Stories}, and McElreath (2020)
\href{https://github.com/rmcelreath/rethinking}{Statistical Rethinking}.

\hypertarget{non-econometric-methods-for-econometricians}{%
\chapter{Non-econometric methods for
econometricians}\label{non-econometric-methods-for-econometricians}}

\hypertarget{selected-ml-and-dataviz-techniques-in-r}{%
\section{Selected ML and Dataviz techniques in
R}\label{selected-ml-and-dataviz-techniques-in-r}}

Econometricians are used to handling data, performing analysis and
reporting results. But somewhere along the line data became big and
unstructured, analysis was now machines learning about something and
outputs became visualisations.

This online seminar takes some big(ish) datasets, sets the machines on
them and draws some great graphs. If you ever wondered what use a tree
was for forecasting or why everything is a network (including neural
ones), or wanted to draw a map with your house in it, or to understand a
document without the bother of reading it (or a few other things
besides) then you might find something to interest you. All done in R.

Specifically, this seminar is designed to introduce some of the key
methods used outside of econometrics that econometricians will find very
useful in their work in a central bank. This includes some important
machine learning techniques as a gateway to others, particularly
tree-based methods and neural networks, as well as text processing and
map making. All the way through there is an emphasis on the network
properties of many of these techniques. We make extensive use of the
\texttt{tidyverse}, including \texttt{ggplot2} and \texttt{tidytext},
and a number of statistics, machine learning, geographical data and
other packages.

The framework for each day is the following:

\begin{itemize}
\tightlist
\item
  Each day is divided into two two-hour sessions starting at 10.30 am
  and 2.00 pm GMT.
\item
  The first hour of each will be an online presentation covering a
  particular topic (or topics) with a look at both techniques and code.
\item
  After a quick break the second hour will be largely devoted to the
  code itself or resources to understand how to code the material.
\end{itemize}

We may run polls during the event to prioritize the topics covered in
the webinars as it is not expected that everyone will be able to try out
everything.

\hypertarget{the-code}{%
\subsection{The code}\label{the-code}}

All code and some of the data will be made available through the Juno
portal. For each presentation the .Rmd (R markdown) file is supplied
that creates the presentation, an HTML file of the presentation for you
to step through which can be re-created from the .Rmd file, and a
further .R file of the code that we use. Some additional code and data
is included, including links to a number of videos that cover some
additional aspects both in this file and in the presentations.

Some data will need to be downloaded from original other sites if all
the examples are to be followed. All code is additionally available at
\url{https://github.com/andrewpeterblake/R2020} or
\url{https://github.com/andrewpeterblake/R2021} or through the QR codes
below.

\begin{figure}

\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.40\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{R2021_files/figure-pdf/unnamed-chunk-1-1.pdf}

}

\caption{2020}

}

\end{minipage}%
%
\begin{minipage}[t]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.40\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{R2021_files/figure-pdf/unnamed-chunk-1-2.pdf}

}

\caption{2021}

}

\end{minipage}%
%
\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%
\newline
\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.40\linewidth}

{\centering 

GitHub repositories for historic CCBS courses

}

\end{minipage}%
%
\begin{minipage}[t]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%

\end{figure}

\hypertarget{how-to-ensure-rstudio-finds-the-code}{%
\section{HOW TO ENSURE RSTUDIO FINDS THE
CODE}\label{how-to-ensure-rstudio-finds-the-code}}

To use the code, in particular so that R Studio finds the data files
etc, create a directory for each topic, (e.g.~Trees, ANN etc) and copy
the contents from the zip file or GitHub. Then create a new project in R
Studio that uses that directory as its home directory, using ``File/New
Project'' in the drop down menu. Opening files within a project sets the
home directory to that directory, so everything (including the
sub-directories) can be found.

\hypertarget{typical-program-structure}{%
\section{Typical program structure}\label{typical-program-structure}}

\hypertarget{day-1-trees-and-maps}{%
\subsection{Day 1: Trees and maps}\label{day-1-trees-and-maps}}

\hypertarget{trees}{%
\subsubsection{Trees}\label{trees}}

\begin{itemize}
\tightlist
\item
  Classification and regression trees
\item
  Econometrics strikes back: Bootstrap/bagging and Boosting/Model
  selection
\item
  Random forests
\item
  Visualising decision trees
\item
  Use example: House prices
\end{itemize}

The presentations for this are \texttt{Trees.html} and
\texttt{LondonHP.html}; The two programs \texttt{TreeCancer.R} and
\texttt{TreeNW.R} are the use examples.

\hypertarget{maps}{%
\subsubsection{Maps}\label{maps}}

\begin{itemize}
\tightlist
\item
  How to draw a map in R
\item
  A guide to some resources
\item
  Choropleths
\item
  Use examples: Climate change, regional data, postcode wrangling
\end{itemize}

The presentation for this is \texttt{MapAER.html} (see also
\texttt{Weatherpretty.html}); The program \texttt{MapAERcode.R} is the
main map drawing code, I've included \texttt{ZAF.R} as as short simple
way and source for two countries, and the directory \texttt{Trendz}
contains the program (\texttt{app.R}) and data for the weather example.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\includegraphics{R2021_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

I've included an additional video (red QR code) for more about Shiny.
This uses unemployment data from the
\href{https://www.philadelphiafed.org/surveys-and-data/real-time-data-research/survey-of-professional-forecasters}{Survey
of Professional Forecasters}. The code we look at is for climate change
data \href{https://climateknowledgeportal.worldbank.org/}{World Bank
data}.

}

\end{minipage}%

\end{figure}

A comprehensive treatment of maps is Lovelace, Nowosad, and Muenchow
(2019) \emph{Geocomputation in R}, but it is quite a lot to assimilate
all at once.

\hypertarget{day-2-networks}{%
\subsection{Day 2: Networks}\label{day-2-networks}}

\hypertarget{neural-networks}{%
\subsubsection{Neural networks}\label{neural-networks}}

\begin{itemize}
\tightlist
\item
  What is an ANN? Deep learning?
\item
  Function approximation via a network
\item
  Data: fit, validate, test
\item
  Network architecture
\item
  Use examples: House prices revisited
\end{itemize}

The presentation for this is \texttt{IntroANN.html}; The program
\texttt{ANN.R} replicates the ANN estimation. The data used is the same
as for Day 1.

\hypertarget{networks-real-ones}{%
\subsubsection{Networks (real ones)}\label{networks-real-ones}}

\begin{itemize}
\tightlist
\item
  DAGs and ANNs as network graphs
\item
  Incidence matrices
\item
  Measuring connectivity: Degree and betweenness
\item
  Plotting with \texttt{igraph}
\item
  Use examples: Industry inter-relationships
\end{itemize}

\begin{figure}

\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.40\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{R2021_files/figure-pdf/unnamed-chunk-3-1.pdf}

}

\caption{Coding club}

}

\end{minipage}%
%
\begin{minipage}[t]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.40\linewidth}

{\centering 

\raisebox{-\height}{

\includegraphics{R2021_files/figure-pdf/unnamed-chunk-3-2.pdf}

}

\caption{R-Bloggers article}

}

\end{minipage}%
%
\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%
\newline
\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.40\linewidth}

{\centering 

Network examples

}

\end{minipage}%
%
\begin{minipage}[t]{0.10\linewidth}

{\centering 

~

}

\end{minipage}%
%
\begin{minipage}[t]{0.05\linewidth}

{\centering 

~

}

\end{minipage}%

\end{figure}

The presentation used for the first part of this is \texttt{DAG.html}
and the program \texttt{Draw\_DAG\_ANN.R} draws the ANN examples from
Day 2 Session 1 as well as some of the DAG examples. The example is
modified from Cunningham (2021) \emph{Causal Inference: The Mixtape},
which is a great read with R code. The pdf \texttt{HandShake3.pdf} is
the source of the director network graphs, and \texttt{Graph101a.R} is a
subset of the analytical work on the corruption data set as described in
the post
\href{https://www.r-bloggers.com/2020/01/graph-theory-101-with-corruption-cases-in-spain/}{\emph{Graph
Theory 101}} (purple QR code), which is the work of
\href{https://codingclubuc3m.rbind.io/talk/2020-01-21/}{Marina Medina}
(blue QR code link to presentation site).

\hypertarget{day-3-text}{%
\subsection{Day 3: Text}\label{day-3-text}}

Text modelling, a `tidytext' approach.

\begin{figure}

\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{session-1}{%
\subsubsection{Session 1}\label{session-1}}

\begin{itemize}
\tightlist
\item
  Data cleaning
\item
  Sentiment
\item
  Topic modelling
\end{itemize}

}

\end{minipage}%
%
\begin{minipage}[t]{0.50\linewidth}

{\centering 

\hypertarget{session-2}{%
\subsubsection{Session 2}\label{session-2}}

\begin{itemize}
\tightlist
\item
  Parts-of-speech tagging
\item
  Text regression
\item
  Use examples: Central bank minutes, reports
\end{itemize}

}

\end{minipage}%

\end{figure}

\hypertarget{kalman-filtering}{%
\chapter{Kalman filtering}\label{kalman-filtering}}

Estimating unobserved components

\hfill\break

\hypertarget{literature}{%
\section{Literature}\label{literature}}

Alternatives to what follows can be found in Harvey (1989), Hamilton
(1994), Kim and Nelson (1999), Durbin and Koopman (2001) or
Triantafyllopoulos (2021). There are many books devoted to the Kalman
filter
\href{https://www.amazon.co.uk/s?k=kalman+filtering\&i=stripbooks}{as a
casual Amazon search} mostly from an engineering perspective. However
econometricians since Harvey and Pierse (1984) have used it in a way
somewhat different from standard engineering applications. We will cover
the filter and then look at a simple example if filtering, then develop
a maximum likelihood estimation approach.

\hypertarget{reminder-of-a-state-space-model}{%
\section{Reminder of a state-space
model}\label{reminder-of-a-state-space-model}}

Consider the trend-cycle model \begin{equation}
  y_t = \chi_t + \tau_t + \varepsilon_t
\end{equation} where the cycle equation is \begin{equation}
  \chi_t = c+\rho_1 \chi_{t-1} + \rho_2 \chi_{t-2}+v_{1t}
\end{equation} and the trend equation is \begin{equation}
  \tau_t = \tau_{t-1} + v_{2t}
\end{equation}

In state space this can be written \begin{align}
y_t &=
\begin{bmatrix} 1 & 0 & 1 \end{bmatrix}
 \begin{bmatrix} \chi_t \\ \chi_{t-1} \\ \tau_t \end{bmatrix} + [1] \varepsilon_t\\
 \begin{bmatrix} \chi_t \\ \chi_{t-1} \\ \tau_t \end{bmatrix} &=
\begin{bmatrix} c \\ 0 \\ 0 \end{bmatrix} +
 \begin{bmatrix} \rho_1 & \rho_2 & 0 \\ 1 & 0 & 0 \\ 0 & 0 & 1 \end{bmatrix}
\begin{bmatrix} \chi_{t-1} \\ \chi_{t-2} \\ \tau_{t-1} \end{bmatrix} +
 \begin{bmatrix} 1 & 0 \\ 0 & 0 \\ 0 & 1 \end{bmatrix}
\begin{bmatrix} v_{1t} \\ v_{2t} \end{bmatrix}
\end{align}

\hypertarget{a-useful-class-of-models}{%
\subsection{A useful class of models}\label{a-useful-class-of-models}}

We need a framework that nests this type of model (and many more).
State-space models are one such framework, amenable to classical (and
Bayesian) estimation. Quite a lot of apparatus required before we can
apply maximum likelihood.

\textbf{Key points}:

\begin{itemize}
\tightlist
\item
  Many quantities routinely used to build models and analyse policy are
  \emph{unobservable}.
\item
  Econometricians face a major problem estimating such models:
  everything unobserved needs estimating simultaneously (states and
  parameters).
\item
  Fortunately there is a method we can use: the \textbf{\emph{Kalman
  filter}} (Kalman (1960)).
\item
  Has the useful spin-off that we can also use it to calculate the value
  of the likelihood function.
\end{itemize}

\hypertarget{what-is-a-filter}{%
\section{What is a filter?}\label{what-is-a-filter}}

Imagine we had a time-varying parameter model where we estimate
\(\beta_t\); this becomes a time series so we have a lot of parameters
to estimate: we outline an estimation method here, which we will then
characterise as the \emph{Kalman Filter}.

Simple observation and transition equations \begin{align}
y_t     &= H_t\beta_t + e_t, &var(e_t) = R \\
\beta_t &= \mu + F \beta_{t-1} + v_t, &var(v_t)=Q
\end{align} where \(\beta_t\) is a vector of stochastic variables,
\(y_t\) a vector of measurements and the data forms an information set
such that \(\psi_T = \{y_T,y_{T-1},...,y_1\}\).

Jazwinski (1970) defines three type of estimation problem

\begin{itemize}
\tightlist
\item
  \textbf{Smoothing} is the problem of estimating \(\beta_k\) for any
  \(k<T\)
\item
  \textbf{Filtering} is the problem of estimating \(\beta_k\) for
  \(k=T\)
\item
  \textbf{Prediction} is the problem of estimating \(\beta_k\) for any
  \(k>T\)
\end{itemize}

\begin{quote}
``The object of filtering is to update our knowledge of the system each
time a new observation \(y_t\) is brought in.'' (Durbin and Koopman
(2001))
\end{quote}

Filtering is specifically this: perhaps we have some estimates already
of \(\beta_t\) for \(t=1...t-1\), then given the new period-\(t\)
observation of \(y_t\) how should we estimate a new value of
\(\beta_t\)? This immediately implies a recursive structure to
estimation problems, consistent with on-line (or real-time) estimation.
The Kalman filter uses the period \(t\) news available from observed
\(y_t\) to update our estimates of \(\beta_t\) using the regression
lemma.

\hypertarget{forecasting}{%
\subsection{Forecasting}\label{forecasting}}

Consider the simple first-order VAR model \begin{equation}
  \beta_t = F\beta_{t-1}+v_{t},\quad v_t\sim N(0,Q)
\end{equation} We can use to make the \emph{conditional} forecast
\begin{equation}
  \beta_{t|t-1} = F\beta_{t-1}
\end{equation} where \(\beta_{t|t-1}=E[\beta_t|\psi_{t-1}]\) and
\(\psi_{t-1}\) is the information set available at time \(t-1\).

If \(\psi_{t-1}\) includes \(\beta_{t-1}\) we can straightforwardly
forecast next period (and the next-but-one period etc) using the model.
This is a standard forecasting exercise given any estimated (or even
calibrated) economic model.

\hypertarget{uncertainty}{%
\subsection{Uncertainty}\label{uncertainty}}

How can we assess the associated forecast uncertainty? The forecast
covariance \(P_{t|t-1} = var(\beta_t|\psi_{t-1})\) is given by
\begin{align}
P_{t|t-1} &= E\left[ (\beta_t - \beta_{t|t-1})(\beta_t-\beta_{t|t-1})'\right]   \\
  &= E\left[ (F\beta_{t-1}+v_t-F\beta_{t-1|t-1}) \left(\beta_{t-1}'F'+v_t'-\beta_{t-1|t-1}'F'\right) \right] \\
&= E\left[ F\left( \beta _{t-1}-\beta _{t-1|t-1}\right) \left( \beta_{t-1}-\beta _{t-1|t-1}\mu_z \right) ' F' \right] + E[v_t v_t']  \notag \\
&= FP_{t-1|t-1}F' + Q
\end{align} where \(P_{t-1|t-1} = var(\beta_{t-1}|\psi_{t-1})\). The
forecast error variance depends on the previous error variance; that
value depends on the information set.

If \(\beta_{t-1}\) forms part of the information set \(\psi_{t-1}\) then
\begin{equation}
 P_{t-1|t-1} = var \left(\beta_{t-1}|\psi_{t-1}\right) = 0
\end{equation} and there is no uncertainty other than from the
disturbance terms and \(P_t=Q\).

If \(\beta_{t-1}\) does not form part of the information set
\(\psi_{t-1}\) but \(\beta _{t-2}\) does then \(P_{t-1|t-1}=Q\) and
\(P_{t|t-1}=FQF'+Q\). This can be continued backwards; the unconditional
(steady-state) covariance of \(\beta_t\) is the limit \(P=FPF'+Q\). We
can easily calculate error bands for \(\beta_t\) using the appropriate
information set.

\hypertarget{prediction-error}{%
\subsection{Prediction error}\label{prediction-error}}

We can turn this around, as it must be the \emph{prediction errors} are
given by \begin{align}
\eta_{t|t-1} &= y_t - E[y_t|\psi_{t-1}]  \\
             &= y_t - E[H_t\beta_t+e_t|\psi_{t-1}] \\
             &= y_t-H_t\beta_{t|t-1}
\end{align} where \(\eta_{t|t-1}\) is uncorrelated with \(\psi_{t-1}\).
So the `news' over that contained in \(y_t\) above \(\psi_{t-1}\) is
captured by \(\eta_{t|t-1}\). It will be that
\(\eta_{t|t-1}\sim N(0,\Sigma_{\eta\eta})\); we need to find an
expression for the covariance.

\hypertarget{current-data-predictions}{%
\subsection{Current-data predictions}\label{current-data-predictions}}

Now we find \(E [\beta_t | \psi_t]\) -- the best prediction of the
unknown coefficient vector given \emph{current} information. Using the
regression lemma we know that \begin{align}
E[\beta_t | \psi_t ] &= E[\beta_t | \psi_{t-1}, \eta_{t|t-1} ]  \\
&= E[\beta_t | \psi_{t-1}] +\Sigma_{\beta\eta} \Sigma_{\eta\eta}^{-1}\eta_{t|t-1}  \\
&= \beta_{t|t-1} + \Sigma_{\beta\eta}\Sigma_{\eta\eta}^{-1} \eta_{t|t-1}
\end{align} because \(\psi_{t-1}\) and \(\eta_{t|t-1}\) are uncorrelated
and \(\eta_{t|t-1}\) is mean zero.

Similarly, we can find \(P_{t|t}\) as the best prediction of the
variance of \(\beta_t\) given \(\psi_t\). Using the regression lemma we
know that \begin{align}
P_{t|t} &= E[(\beta_t-\beta_{t|t})(\beta_t - \beta_{t|t})'|\psi_{t-1}, \eta_{t|t-1}] \\
        &= E[(\beta_t - \beta_{t|t})(\beta_t-\beta_{t|t})'|\psi_{t-1}] - \Sigma_{\beta\eta}\Sigma_{\eta\eta}^{-1}\Sigma_{\eta\beta} \\
        &=P_{t|t-1}-\Sigma_{\beta\eta} \Sigma_{\eta\eta}^{-1} \Sigma_{\eta\beta} 
\end{align}

\hypertarget{estimated-model-covariances}{%
\subsection{Estimated model
covariances}\label{estimated-model-covariances}}

All we need do is plug the relevant expressions into the regression
lemma. So, what is \(\Sigma_{\beta\eta}\)? \begin{align}
\Sigma_{\beta\eta} &= E[(\beta_t-\beta_{t|t-1}) \eta_{t|t-1}'] \\
&= E\left[(\beta_t-\beta_{t|t-1}) (y_t-H_t\beta_{t|t-1})'\right] \\
&= E\left[(\beta_t-\beta_{t|t-1}) (H_t\beta_t+e_t-H_t\beta_{t|t-1})'\right] \\
&= E[(\beta_t-\beta_{t|t-1}) (\beta_t-\beta_{t|t-1})'H_t'] + E[(\beta_t - \beta_{t|t-1}) e_t'] \\
&= P_{t|t-1} H_t' \tag{$\Sigma_{\beta\eta}$} 
\end{align} as \(E[(\beta_t - \beta_{t|t-1})e_t']=0\).

What is \(\Sigma_{\eta\eta}\)? \begin{align}
\Sigma_{\eta\eta} &= E[(y_t-H_t \beta_{t|t-1})(y_t-H_t\beta_{t|t-1})'] \\
                  &= E[(H_t\beta_t+e_t-H_t\beta_{t|t-1})(H_t\beta_t+e_t-H_t\beta_{t|t-1})'] \\
                  &= E[(H_t\beta_t-H_t \beta_{t|t-1})(H_t\beta_t-H_t\beta_{t|t-1})'] + E[e_t e_t'] \\
                  &= E[H_t(\beta_t-\beta_{t|t-1})(\beta_t-\beta_{t|t-1})'H_t'] + R \\
                  &= H_t P_{t|t-1} H_t' + R \\
                  &= f_{t|t-1} \tag{$\Sigma_{\eta\eta}$} \label{svv}
\end{align} where we define \(f_{t|t-1}=E[\eta_{t|t-1}\eta_{t|t-1}']\).
Now we're ready.

\hypertarget{the-kalman-filter}{%
\section{The Kalman filter}\label{the-kalman-filter}}

The equations of the filter are

\begin{itemize}
\tightlist
\item
  the conditional expectation depending on \(\psi_{t-1}\);
\item
  an update that uses \(\eta_{t|t-1}\) to obtain the best \(t\)-period
  prediction now based on \(\psi_t\).
\end{itemize}

These must be of the form \begin{align}
E[\beta_t | \psi_{t-1}] &= \mu + F E [\beta_t | \psi_{t-1}] \\
E[P_t|\psi_{t-1}]       &= F E[P_{t-1}|\psi_{t-1}] F' + Q \\
E[\beta_t | \psi_t]     &= E[\beta_t|\psi_{t-1}] + \Sigma_{\beta\eta} \Sigma_{\eta\eta}^{-1}\eta_{t|t-1} \\
E[P_t|\psi_t]           &= E[P_t|\psi_{t-1}] -\Sigma_{\beta\eta}\Sigma_{\eta\eta}^{-1}\Sigma_{\eta \beta}
\end{align} These are specifically \begin{align}
\beta_{t|t-1} &= \mu +F\beta_{t-1|t-1}                                  \tag{Predicted $\beta$}\\
P_{t|t-1}     &= F P_{t-1|t-1}F' + Q                                    \tag{Predicted $P$}\\
\eta_{t|t-1}  &= y_t-H_t\beta_{t|t-1}                                   \tag{Prediction error}\\
f_{t|t-1}     &= H_t P_{t|t-1}H_t' + R                                  \tag{Pred. err. variance}\\
\beta_{t|t}   &= \beta_{t|t-1}+P_{t|t-1}H_t' f_{t|t-1}^{-1}\eta_{t|t-1} \tag{Updated $\beta$}\\
P_{t|t}       &= P_{t|t-1} - P_{t|t-1}H_t' f_{t|t-1}^{-1}H_tP_{t|t-1}   \tag{Updated $P$}
\end{align} The filter evaluates these recursively, beginning from
\(\beta_0\), \(P_0\).

Treatment of these initial condition reflects knowledge/model

\begin{itemize}
\tightlist
\item
  Stationary models can use the steady-state
\item
  Non-stationary models use something which is often (confusingly)
  called a \emph{diffuse prior} (zero mean, large variance)
\end{itemize}

\hypertarget{kalman-filter-trick}{%
\subsection{Kalman filter trick}\label{kalman-filter-trick}}

For \textbf{\emph{known}} initial conditions -- say
\(\beta_0 \sim N(\mu_0, P_0)\) -- the likelihood of a state-space model
with \(T\) observations of \(m\) variables is \begin{align}
\log L(\theta | y) &= \sum_{t=1}^T \log \left(p \left( \theta | \psi_{t-1}, \theta \right)\right) \\
  &= - \Phi - \frac{1}{2}\sum_{t=1}^T \left( \log(\det(f_{t|t-1})) + \eta_{t|t-1}' f_{t|t-1}^{-1} \eta_{t|t-1} | \theta \right)
\end{align} where \(\Phi = \frac{Tm}{2}\log \left( 2\pi \right)\) and
\(\theta\) are all the non-state parameters to be estimated. We can use
the Kalman filter to obtain \(\eta_{t|t-1}\) and \(f_{t|t-1}\) as they
are the \emph{prediction error} and its \emph{variance}. This is the
\textbf{\emph{prediction error decomposition}} of the log-likelihood.

A maximum likelihood estimate maximizes \(\log L(y|\theta)\) by choice
of \(\theta\).

\part{Quantiles}

\hypertarget{quantile-regression}{%
\chapter{Quantile regression}\label{quantile-regression}}

This shows how to manipulate data from the SPF in R.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(xts)}
\FunctionTok{library}\NormalTok{(lubridate)}
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(quantmod)}
\FunctionTok{library}\NormalTok{(quantreg)}
\end{Highlighting}
\end{Shaded}

\hypertarget{getting-the-data}{%
\section{Getting the data}\label{getting-the-data}}

We download the data and save it locally.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{h }\OtherTok{\textless{}{-}} \StringTok{"https://www.philadelphiafed.org/{-}/media/frbp/assets/surveys{-}and{-}data/survey{-}of{-}professional{-}forecasters/historical{-}data/"}
\NormalTok{f }\OtherTok{\textless{}{-}} \StringTok{"meanlevel.xlsx"}

\FunctionTok{download.file}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(h, f), }\AttributeTok{destfile=}\NormalTok{f, }\AttributeTok{mode=}\StringTok{"wb"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

Retrieve the unemployment data for the average unemployment forecast.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{UNEMP }\OtherTok{\textless{}{-}}\NormalTok{ f }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{read\_excel}\NormalTok{(}\AttributeTok{na=}\StringTok{"\#N/A"}\NormalTok{, }\AttributeTok{sheet=}\StringTok{"UNEMP"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Date=}\FunctionTok{as.Date}\NormalTok{(}\FunctionTok{as.yearqtr}\NormalTok{(}\FunctionTok{paste}\NormalTok{(YEAR, QUARTER), }\AttributeTok{format=}\StringTok{"\%Y \%q"}\NormalTok{))) }

\NormalTok{Usel }\OtherTok{\textless{}{-}}\NormalTok{ UNEMP }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(Date, UNEMP1, UNEMP3, UNEMP4, UNEMP5, UNEMP6) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{UNRATE =} \FunctionTok{lead}\NormalTok{(UNEMP1,}\DecValTok{1}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(Date, UNRATE, }
         \AttributeTok{UNEMP1=}\NormalTok{UNEMP3, }\AttributeTok{UNEMP2=}\NormalTok{UNEMP4, }\AttributeTok{UNEMP3=}\NormalTok{UNEMP5, }\AttributeTok{UNEMP4=}\NormalTok{UNEMP6) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{UNEMP1 =} \FunctionTok{lag}\NormalTok{(UNEMP1,}\DecValTok{1}\NormalTok{), }
         \AttributeTok{UNEMP2 =} \FunctionTok{lag}\NormalTok{(UNEMP2,}\DecValTok{2}\NormalTok{), }
         \AttributeTok{UNEMP3 =} \FunctionTok{lag}\NormalTok{(UNEMP3,}\DecValTok{3}\NormalTok{), }
         \AttributeTok{UNEMP4 =} \FunctionTok{lag}\NormalTok{(UNEMP4,}\DecValTok{4}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(Date, UNRATE), }\AttributeTok{names\_to=}\StringTok{"Which"}\NormalTok{, }\AttributeTok{values\_to=}\StringTok{"Val"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\FunctionTok{year}\NormalTok{(Date) }\SpecialCharTok{\textgreater{}} \DecValTok{2000}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\hypertarget{plots}{%
\section{Plots}\label{plots}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Usel }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Date)) }\SpecialCharTok{+} 
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{UNRATE), }\AttributeTok{colour=}\StringTok{"red"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{y=}\NormalTok{Val, }\AttributeTok{colour=}\NormalTok{Which, }\AttributeTok{shape=}\NormalTok{Which)) }\SpecialCharTok{+}
  \FunctionTok{theme\_light}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\StringTok{"Mean unemployment forecasts"}\NormalTok{, }\AttributeTok{x=}\StringTok{""}\NormalTok{, }\AttributeTok{y=}\StringTok{""}\NormalTok{, }\AttributeTok{caption=}\StringTok{"Source: SPF"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{QR_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\end{figure}

\hypertarget{carter-kohn}{%
\chapter{Carter-Kohn}\label{carter-kohn}}

\hypertarget{using-the-kalman-filter}{%
\section{Using the Kalman Filter}\label{using-the-kalman-filter}}

Establish the usefulness of the Kalman Filter (and not just for state
estimation). Refresh idea of maximum likelihood estimation in the
context of state space models.

\begin{itemize}
\tightlist
\item
  Introduce \emph{smoothing}
\item
  Develop Gibbs sampling by the Carter-Kohn method
\item
  All of these use the Kalman Filter to develop conceptually different
  tools
\end{itemize}

Follow Kim and Nelson (1999); also see Harvey (1989), Hamilton (1994),
Durbin and Koopman (2001)

\hypertarget{maximum-likelihood}{%
\section{Maximum likelihood}\label{maximum-likelihood}}

\hypertarget{classical-maximum-likelihood-estimation}{%
\subsection{Classical Maximum Likelihood
Estimation}\label{classical-maximum-likelihood-estimation}}

The principle of maximum likelihood is that the parameters should be
chosen so that the probability of observing a given sample is maximized.

For time series models the joint density of
\(\psi_T = \{y_T, y_{T-1},\ldots ,y_1 \}\) and parameters \(\theta\) in
conditional form is \begin{equation}
 p(\theta|\psi_T) = \prod\nolimits_{t=1}^T p (y_t|\psi_{t-1},\theta)
\end{equation} emphasizing the serial dependence of observations.

Interpret this as the likelihood for a particular sample. Assuming
(conditional) normality, the likelihood of any particular \(n\)-vector
of observations is \begin{equation}
p(y_t) = (2\pi)^{-\frac{n}{2}}|var(y_t)|^{-\frac{1}{2}}e^{\left\{ -\frac{1}{2}(y_t-\mu )' var(y_t)^{-1}(y_t-\mu)\right\} }
\end{equation} Notice this depends on the observed data \emph{and} the
values of the parameters. It can be multivariate and for any underlying
density. A maximum likelihood (ML) estimate of \(\theta\) maximizes the
likelihood of the parameter given an observed sample.

\hypertarget{poisson-example}{%
\subsection{Poisson example}\label{poisson-example}}

Th Poisson distribution is a nice one to consider as the maximum
likelihood estimate can be calculated easily -- essentially in your
head.\footnote{For example Greene (1997) constructs a Poisson
  distribution example where the chosen observations yield an exact
  estimate of the underlying parameter of the distribution. The example
  is to find the most likely value of \(\theta\) given observations
  \begin{equation}
  5,\ 0,\ 1,\ 1,\ 0,\ 3,\ 2,\ 3,\ 4,\ 1
  \end{equation} ten observations which sum to 20.}

The Poisson distribution is \begin{equation}
 p(y_i,\ \theta )=\frac{e^{-\theta }\theta ^{y_i}}{y_i!}
\end{equation} for \(y>0\), zero otherwise with the property
\(E[Y]=var(Y)=\theta\).

Count variables often modelled as a random Poisson process: numbers of
road traffic accidents, sales, telephone calls, electron emissions.
Greene's example is to find the most likely value of \(\theta\) given
observations. \begin{equation}
5,\ 0,\ 1,\ 1,\ 0,\ 3,\ 2,\ 3,\ 4,\ 1
\end{equation} For independent observations the joint density is
\begin{equation}
p(y,\ \theta) =\prod_{i=1}^{10}p(y_i,\ \theta )
  = \frac{e^{-10\theta}\theta^{\sum_i y_i}}{\prod_i (y_i!)}
  = \frac{e^{-10\theta}\theta^{20}}{207,360}
\end{equation} We can plot this function to see if it has a maximum

\begin{figure}

{\centering \includegraphics[width=0.85\textwidth,height=\textheight]{CK_files/figure-pdf/dens-1.pdf}

}

\end{figure}

We can also find this by calculus. As ever, because the log function is
monotonic it is convenient to take logs \begin{equation}
   \ln L(\theta) = -10\theta + 20\ln\theta -\ln(207,360)
\end{equation} First order conditions are \begin{equation}
  \frac{\partial \ln L(\theta )}{\partial\theta} = -10+\frac{20}{\theta}
\Rightarrow \theta =\frac{20}{10}=2
\end{equation} Check for maximum \begin{equation}
   \frac{\partial^2\ln L(\theta )}{\partial\theta^2} = -\frac{20}{\theta^2} < 0
\end{equation}

\hypertarget{poisson-example-1}{%
\section{Poisson example}\label{poisson-example-1}}

The Poisson density for each observation is \begin{equation}
   p(y_i, \theta) = \frac{e^{-\theta} \theta^{y_i}}{y_i!}
\end{equation} for \(y>0\), zero otherwise, with \(E[Y]=var(Y)=\theta\).
For \(n\) independent observations, joint density is \begin{equation}
P(y, \theta) = \prod_{i=1}^n p(y_i, \theta)
  = \frac{e^{-n\theta}\theta^{\sum_i y_i}}{\prod_i (y_i!)}
\end{equation} Interpret this as a likelihood function, i.e.~a
probability measure for \(\theta\) given some observed \(y\)
\begin{equation}
 L(\theta | y) = P(y,\theta)
\end{equation} As log function is monotonic \begin{equation}
\ln L(\theta | y) = -n\theta + {\textstyle{\sum_i} y_i} \ln\theta  - \ln\left(\textstyle{\prod_i} y_i! \right)
\end{equation} First order conditions are \begin{equation}
  \frac{\partial \ln L(\theta|y)}{\partial\theta}
     = -n + \frac{\sum_i y_i}{\theta}
     \Rightarrow
        \theta =\frac{\sum_i y_i}{n}
\end{equation} Finally, check for maximum \begin{equation}
 \frac{\partial^2\ln L(\theta)}{(\partial\theta)^2} = -\frac{\sum_i y_i}{\theta^2} < 0
\end{equation}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(scales)}

\NormalTok{reps   }\OtherTok{\textless{}{-}} \DecValTok{20}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{n      }\OtherTok{\textless{}{-}} \DecValTok{10}

\NormalTok{a }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{x=}\FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{3}\SpecialCharTok{*}\NormalTok{lambda),}
            \AttributeTok{p=}\NormalTok{(}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{lambda}\SpecialCharTok{*}\NormalTok{x)}\SpecialCharTok{*}\NormalTok{(lambda}\SpecialCharTok{\^{}}\NormalTok{x))}\SpecialCharTok{/}\FunctionTok{prod}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(lambda)))}

\NormalTok{d }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rpois}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{reps,lambda), n, reps)}

\NormalTok{t }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(d), }\AttributeTok{.name\_repair =} \SpecialCharTok{\textasciitilde{}}\FunctionTok{paste0}\NormalTok{(}\StringTok{"Rep"}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\NormalTok{reps)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \FunctionTok{everything}\NormalTok{()) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{(}\AttributeTok{dd =} \FunctionTok{prod}\NormalTok{(value)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{sum  =} \FunctionTok{colSums}\NormalTok{(d),}
         \AttributeTok{ests =}\NormalTok{ sum}\SpecialCharTok{/}\NormalTok{n)}
\end{Highlighting}
\end{Shaded}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(t) }\SpecialCharTok{+} 
  \FunctionTok{geom\_histogram}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{ests), }\AttributeTok{fill=}\StringTok{"blue"}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{33}\NormalTok{, }\AttributeTok{color=}\ConstantTok{NA}\NormalTok{, }\AttributeTok{bins=}\DecValTok{20}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.85\textwidth,height=\textheight]{CK_files/figure-pdf/ests-1.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{theta }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{, }\DecValTok{8}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{y     }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{lambda)}\SpecialCharTok{*}\NormalTok{lambda}\SpecialCharTok{\^{}}\NormalTok{(theta))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(theta))}
\NormalTok{df    }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{theta =}\NormalTok{ theta) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\StringTok{\textasciigrave{}}\AttributeTok{lambda == 1}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ (}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{)}\SpecialCharTok{*}\DecValTok{1}\SpecialCharTok{\^{}}\NormalTok{(theta))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(theta)),}
         \StringTok{\textasciigrave{}}\AttributeTok{lambda == 2}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ (}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{)}\SpecialCharTok{*}\DecValTok{2}\SpecialCharTok{\^{}}\NormalTok{(theta))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(theta)),}
         \StringTok{\textasciigrave{}}\AttributeTok{lambda == 3}\StringTok{\textasciigrave{}} \OtherTok{=}\NormalTok{ (}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{)}\SpecialCharTok{*}\DecValTok{3}\SpecialCharTok{\^{}}\NormalTok{(theta))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(theta)))}

\NormalTok{df }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{theta, }\AttributeTok{names\_to =} \StringTok{"lambda"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{theta, }\AttributeTok{y=}\NormalTok{value, }\AttributeTok{color=}\NormalTok{lambda), }\AttributeTok{size=}\DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{theta, }\AttributeTok{y=}\NormalTok{value, }\AttributeTok{color=}\NormalTok{lambda)) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\StringTok{"Poisson density example"}\NormalTok{, }\AttributeTok{x=}\StringTok{""}\NormalTok{, }\AttributeTok{y=}\StringTok{""}\NormalTok{,}
       \AttributeTok{color=}\FunctionTok{expression}\NormalTok{(lambda)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{),}
        \AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{),}
        \AttributeTok{legend.position =} \FunctionTok{c}\NormalTok{(.}\DecValTok{8}\NormalTok{,.}\DecValTok{8}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{scale\_colour\_discrete}\NormalTok{(}\AttributeTok{labels =} \FunctionTok{parse\_format}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics[width=0.85\textwidth,height=\textheight]{CK_files/figure-pdf/ests-2.pdf}

}

\end{figure}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{,}\DecValTok{4}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\NormalTok{l }\OtherTok{\textless{}{-}} \FunctionTok{seq}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{5}\NormalTok{,}\FloatTok{0.05}\NormalTok{)}
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ (}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n}\SpecialCharTok{*}\NormalTok{l)}\SpecialCharTok{*}\NormalTok{l}\SpecialCharTok{\^{}}\NormalTok{(}\FunctionTok{sum}\NormalTok{(e)))}\SpecialCharTok{/}\NormalTok{(}\FunctionTok{prod}\NormalTok{(}\FunctionTok{factorial}\NormalTok{(e)))}

\FunctionTok{tibble}\NormalTok{(}\AttributeTok{l=}\NormalTok{l, }\AttributeTok{y=}\NormalTok{y) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{l, }\AttributeTok{y=}\NormalTok{y), }\AttributeTok{color=}\StringTok{"red"}\NormalTok{, }\AttributeTok{linewidth=}\DecValTok{1}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\StringTok{"Poisson density example"}\NormalTok{,}
       \AttributeTok{x=}\FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Value of "}\NormalTok{, lambda)),}
       \AttributeTok{y=}\StringTok{"Joint density"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{CK_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\end{figure}

Maintain the value of \(\lambda\) of 2. Now generate \(reps=20\)
replications of \(n=10\) observations and plot the empirical density of
each and the maximum likelihood estimate for each replication.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{t2 }\OtherTok{\textless{}{-}}\NormalTok{ t }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(name) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{r =} \FunctionTok{list}\NormalTok{((}\FunctionTok{exp}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{n}\SpecialCharTok{*}\NormalTok{l)}\SpecialCharTok{*}\NormalTok{l}\SpecialCharTok{\^{}}\NormalTok{sum)}\SpecialCharTok{/}\NormalTok{dd))}

\NormalTok{nms }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"Rep\_"}\NormalTok{, }\FunctionTok{str\_pad}\NormalTok{(}\DecValTok{1}\SpecialCharTok{:}\NormalTok{reps, }\DecValTok{2}\NormalTok{, }\AttributeTok{pad=}\StringTok{"0"}\NormalTok{))}

\NormalTok{t2}\SpecialCharTok{$}\NormalTok{r }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{bind\_cols}\NormalTok{(}\AttributeTok{.name\_repair =} \SpecialCharTok{\textasciitilde{}}\NormalTok{ nms) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{l =}\NormalTok{ l) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols =} \SpecialCharTok{{-}}\NormalTok{l) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{l, }\AttributeTok{y=}\NormalTok{value, }\AttributeTok{color=}\NormalTok{name), }\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_vline}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{xintercept=}\NormalTok{lambda), }\AttributeTok{color=}\StringTok{"red"}\NormalTok{, }\AttributeTok{linetype=}\DecValTok{3}\NormalTok{, }\AttributeTok{linewidth=}\FloatTok{0.75}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{ name, }\AttributeTok{scales =} \StringTok{"free\_y"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title    =} \FunctionTok{paste}\NormalTok{(}\StringTok{"Poisson density, sample size"}\NormalTok{, n),}
       \AttributeTok{subtitle =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Dotted line: true value of "}\NormalTok{, lambda)),}
       \AttributeTok{x        =} \FunctionTok{expression}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Estimated value of "}\NormalTok{, lambda)),}
       \AttributeTok{y        =} \StringTok{"Joint density"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{plot.title =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{),}
        \AttributeTok{plot.subtitle =} \FunctionTok{element\_text}\NormalTok{(}\AttributeTok{hjust =} \FloatTok{0.5}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{CK_files/figure-pdf/unnamed-chunk-3-1.pdf}

}

\end{figure}

\hypertarget{ml-and-regression}{%
\subsection{ML and regression}\label{ml-and-regression}}

Linear regression problem is \begin{equation}
L(\beta|y,X) = \frac{1}{(2\pi \sigma^2)^{n/2}}\exp \left[ - \frac{1}{2\sigma^2} (y-X\beta)'(y-X\beta) \right]
\end{equation} The log-likelihood is \begin{equation}
   \ln L = -\frac{n}{2}\ln (2\pi)-\frac{n}{2}\ln (\sigma^2) - \frac{1}{2\sigma^2}(y-X\beta)'(y-X\beta)
\end{equation} As before, find the extremum by calculus; yields
\emph{likelihood equations} \begin{align}
\frac{\partial \ln L}{\partial \beta} & = - \frac{2}{2\sigma^2} (X'y-X'X\beta) = 0 \\
& \Rightarrow \hat{\beta}_{ml} = (X'X)^{-1}X'y
\end{align} and \begin{align}
\frac{\partial \ln L}{\partial \sigma^2} &=
   - \frac{n}{2\sigma^2} + \frac{1}{2\sigma^4}   
     (y - X\beta)'(y - X\beta) = 0 \\
& \Rightarrow -n + \sigma^{-2} (\epsilon'\epsilon) = 0 \\
& \Rightarrow \hat{\sigma}_{ml}^2 = \frac{\hat{\epsilon}'\hat{\epsilon}}{n}
\end{align} ML estimate of \(\sigma^2\) divided by \(n\) (not \(n-k\))
so biased in small samples but not asymptotically

\hypertarget{kalman-filter-tricks}{%
\section{Kalman filter tricks}\label{kalman-filter-tricks}}

For some initial condition -- say \(\beta_0 \sim N(\mu_0,P_0))\) -- the
conditional log-likelihood for sample \(1\) to \(T\) \begin{align}
\log L(\psi_t|\theta) &= \sum\nolimits_{t=1}^T\log p(y_t|\psi_{t-1},\theta) \\
&\propto -\sum\nolimits_{t=1}^T\left( \log \left\vert f_{t|t-1}\right\vert +\eta_{t|t-1}' f_{t|t-1}^{-1}\eta_{t|t-1} |\ \theta \right)
\end{align} Note we could obtain \(\eta_{t|t-1}\) and \(f_{t|t-1}\) from
the Kalman filter, i.e.~ \begin{equation}
  f_{t|t-1} = (H_tP_{t|t-1}H_t' + Q) = \Sigma_{\eta\eta}
\end{equation} This is the \emph{prediction error decomposition} of the
log-likelihood. For a classical approach we estimate \(\theta\) by
numerically maximizing \(\log L(\psi_T|\theta)\).This gives a point
estimate for the value of \(\theta\) and we typically apply classical
inference using the estimated standard errors. Note to do this we need
to evaluate the best estimate of the state as well as maximize the
likelihood: the Kalman Filter is a key ingredient in both.

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, arc=.35mm, title=\textcolor{quarto-callout-note-color}{\faInfo}\hspace{0.5em}{Maximisation}, colbacktitle=quarto-callout-note-color!10!white, bottomtitle=1mm, opacityback=0, colframe=quarto-callout-note-color-frame, toprule=.15mm, titlerule=0mm, left=2mm, bottomrule=.15mm, colback=white, leftrule=.75mm, coltitle=black]

A suitable numerical maximization routine will (in principle) maximize
the likelihood straightforwardly. Often use
\href{http://www.princeton.edu/~sims/}{Chris Sims'}
\href{http://sims.princeton.edu/yftp/optimize/rfiles/csminwel.R}{\textbf{csminwel}}
in Matlab or R as well-suited to this type of problem.

\end{tcolorbox}

Can show (via Cramer-Rao) that \begin{equation}
\widehat{\theta}\sim N\left(\theta, -\frac{\partial^2 \log L(\psi_T|\theta)} {\partial\theta\partial\theta'} \right)
\end{equation}

\hypertarget{full-sample-estimates-of-beta_t}{%
\section{\texorpdfstring{Full sample estimates of
\(\beta_t\)}{Full sample estimates of \textbackslash beta\_t}}\label{full-sample-estimates-of-beta_t}}

\hypertarget{the-regression-lemma-again}{%
\subsection{The regression lemma
again}\label{the-regression-lemma-again}}

You may recall that for any \begin{equation}
\begin{bmatrix} z \\ y \\ \varepsilon \end{bmatrix}
\sim N\left(\begin{bmatrix} \mu_z \\ \mu_y \\ 0 \end{bmatrix},
\begin{bmatrix}
\Sigma_{zz} & \Sigma_{zy} & \Sigma_{z\varepsilon } \\
\Sigma_{yz} & \Sigma_{yy} & 0 \\
\Sigma_{\varepsilon z} & 0 & \Sigma_{\varepsilon\varepsilon}
\end{bmatrix}\right)
\end{equation} then it must be that \begin{align}
E[z|y,\varepsilon] &= \mu_z + \Sigma_{zy}\Sigma_{yy}^{-1}(y-\mu_y) + \Sigma_{z\varepsilon}\Sigma_{\varepsilon\varepsilon}^{-1}\varepsilon \\
&= E[z|y] + \Sigma_{z\varepsilon}\Sigma_{\varepsilon\varepsilon }^{-1}\varepsilon
\end{align} We use this to derive a recursive update to \emph{smooth}
our estimates. We will also derive an appropriate conditional
expectation which we can use in Gibbs sampling.

\hypertarget{smoothing}{%
\section{Smoothing}\label{smoothing}}

The Kalman filter estimates \(\beta_t\) recursively: it only uses
information available up until time \(t\). This means that the estimate
of \(\beta_{T|T}\) uses all available information, but any previous
estimate doesn't. Indeed there must be some values of \(\eta_{i|t-1}\)
\begin{equation}
   \beta_{t|T} = E(\beta_t | \psi_{t-1}, \eta_{t|t-1}, \eta_{t+1|t-1},...,\eta_{T|t-1})
\end{equation} where the `news' is relative to period \(t\).

We could update \(\beta_{t|t-1}\) using the (uncorrelated) future
innovations \begin{equation}
  \beta_{t|T}=\beta_{t|t}+\sum_{j=t}^T\Sigma_{\beta_t\eta_j}\Sigma_{\eta_j\eta_j}^{-1}\eta_{j|t-1}
\end{equation} and recalling
\(\beta_{t|t}=E(\beta_t|\psi_{t-1},\eta_{t|t-1})\).

This is a \emph{fixed interval smoother}; often used for full sample
estimates of \(\beta_t\). Remember we already have an estimate of
\(\beta_{T|T}\) from the Kalman filter so \emph{smoothers work
backwards}; we sketch a derivation here.

In the last but one period we have a different prediction error
\begin{equation}
   \varsigma_{T|T-1} = \beta_{T|T} - F\beta_{T-1|T-1} - \mu
\end{equation} which is the error in predicting \(\beta_T\) using
\(\psi_{T-1}\).

An `update' has to be of the form \begin{equation}
\beta_{T-1|T}=\beta_{T-1|T-1} + \Sigma_{\beta\varsigma}\Sigma_{\varsigma\varsigma}^{-1}\varsigma_{T|T-1}
\end{equation} where
\(\Sigma_{\varsigma\varsigma} = var\left[ \varsigma_T|\psi_{T-1}\right]\)
and
\(\Sigma_{\beta \varsigma}=cov\left[\beta_{T-1},\varsigma_T|\psi_{T-1}\right]\).

These are \begin{align}
\Sigma_{\varsigma\varsigma} &= var(\beta_T - F\beta_{T-1|T-1}-\mu) \\
  &= var\left(F(\beta_{T-1}-\beta_{T-1|T-1}) + e_t \right) \\
  &= F P_{T-1|T-1}F' + Q
\end{align} and \begin{align}
\Sigma_{\beta\varsigma} &= E\left[ (\beta_{T-1}-\beta_{T-1|T-1}) \left( \beta_T - F\beta_{T-1|T-1}-\mu \right)'
\right] \\
&= E\left[ (\beta_{T-1}-\beta_{T-1|T-1}) (\beta_T-\beta_{T-1|T-1})'\right] F' \\
&= P_{T-1|T-1}F'
\end{align} Plugging these definitions in gives us \begin{equation}
\beta_{T-1|T} = \beta_{T-1|T-1} + P_{T-1|T-1}F' P_{T|T-1}^{-1} (\beta_{T|T}-F\beta_{T-1|T-1}-\mu)
\end{equation} Applying the argument backward in time gives the
recursion \begin{align}
\beta_{t|T} &= \beta_{t|t}+P_{t|t} F'P_{t+1|t}^{-1} (\beta_{t+1|T}-F\beta_{t|t}-\mu) \\
&= \beta_{t|t} - K_{t|T} (\beta_{t+1|T}-F\beta_{t|t}-\mu) \tag{smooth}
\end{align} All these quantities are outputs of the Kalman filter so
smoothing is easy to implement.

The smoothed variance of \(\beta_{t|T}\) found by multiplying out
(smooth). To do this use \(\beta_{t+1|t} = \mu + F\beta_{t|t}\) so
rearranging gives \begin{equation}
  \widetilde{\beta}_{t|T} + K_{t|T}\beta_{t+1|T} = \widetilde{\beta}_{t|t}+K_{t|T}\beta_{t+1|t}
\end{equation} where \(\widetilde{\beta}_{t|t}=\beta_t-\beta_{t|t}\).
Now square both sides and take expectations \begin{equation}
  P_{t|T} + K_{t|T} E\left[\beta_{t+1|T}\beta_{t+1|T}' \right] K_{t|T}' = P_{t|t} + K_{t|T} E\left[ \beta_{t+1|t} \beta_{t+1|t}' \right] K_{t|T}'
\end{equation} Adding and subtracting \(E[\beta_{t+1}\beta_{t+1}']\) we
can show that \begin{equation}
-E\left[\beta_{t+1|T}\beta_{t+1|T}'\right] + E\left[\beta_{t+1|t}\beta_{t+1|t}'\right] = P_{t+1|T}-P_{t+1|t}
\end{equation} to obtain \begin{equation}
  P_{t|T} = P_{t|t} + K_{t|T} (P_{t+1|T}-P_{t+1|t}) K_{t|T}'.
\end{equation}

\hypertarget{kalman-filter-in-econometrics}{%
\section{Kalman filter in
econometrics}\label{kalman-filter-in-econometrics}}

\hypertarget{classical-approach}{%
\subsection{Classical approach}\label{classical-approach}}

The typical procedure is some variation on:

\begin{itemize}
\tightlist
\item
  Formulate state-space model
\item
  Estimate the model by maximum likelihood
\item
  Condition on the parameters to retrieve the (usually smoothed) state
  estimates and standard errors
\item
  Use Cramer-Rao to calculate the standard errors of any other parameter
  estimates
\end{itemize}

For this the Kalman filter is a useful tool, as it allows a great deal
of flexibility in the estimation of a variety of models, as is is an
appropriate tool for models with unobserved components. However, it must
be used with care: it is easy to try to estimate models that are
essentially unidentified.

Further useful tools

\begin{itemize}
\tightlist
\item
  The \emph{Extended Kalman filter} linearises the filter at every step
  and can be used for nonlinear models (such as ones where you need to
  estimate \(B_T\) and \(\theta\) simultaneously)
\item
  Increasingly non-Gaussian non-linear models are estimated using the
  \emph{particle filter}
\end{itemize}

\hypertarget{bayesian-approach}{%
\subsection{Bayesian approach}\label{bayesian-approach}}

Bayesian approach is to generate the entire distribution of the model
parameters.

\begin{itemize}
\tightlist
\item
  Now no longer just look for the point estimate obtained by maximum
  likelihood
\item
  Use Gibbs sampling or some other appropriate method applied to the
  state space model
\item
  In particular we treat the states and the parameters as jointly
  determined by the data
\item
  As the state is estimated we need a way to draw the states conditional
  on the other estimates to do Gibbs sampling
\item
  Seek a conditional updating algorithm that replicates the Gibbs
  sampling approach we have used before
\end{itemize}

We require a procedure such that:

\begin{itemize}
\tightlist
\item
  \textbf{Step 1} Conditional on \(\theta\) and the data, generate the
  sequence \(B_T = (\beta_1, \beta_2, \ldots, \beta_T)\)
\item
  \textbf{Step 2} Conditional on \(B_T\) and the data, generate values
  of \(\theta\)
\item
  \textbf{Step 3} Iterate previous two steps until convergence
\end{itemize}

In this way the joint distribution of the two can be obtained from the
resulting simulation.

\hypertarget{carter-kohn-algorithm}{%
\section{Carter-Kohn algorithm}\label{carter-kohn-algorithm}}

\begin{itemize}
\item
  \textbf{Step 2} above relatively easy but how do we generate a
  sequence of states?

  \begin{itemize}
  \tightlist
  \item
    The state estimates depend on the parameter value through the Kalman
    filter
  \end{itemize}
\item
  Appropriate algorithm designed by Carter and Kohn (1994)
\item
  Takes the form of a modified Kalman smoother
\item
  Known as \emph{multimove Gibbs sampling}
\item
  Similar to above, define
\end{itemize}

\begin{equation}
  B_t = \begin{bmatrix} \beta_1 & \beta_2 & \ldots & \beta_t \end{bmatrix}
\end{equation} so in particular \begin{equation}
B_{T-1} = \begin{bmatrix} \beta_1 & \beta_2 & \ldots & \beta_{T-1} \end{bmatrix}
\end{equation} consistent with out earlier definition of \(\psi_t\).

\begin{itemize}
\tightlist
\item
  Multimove Gibbs sampling generates the whole vector of states
  (\(B_T\)) at once
\item
  We therefore need to generate a realization of \(B_T\) given the
  probability distribution \(p( B_T|\psi_T)\)
\item
  We want to generate an appropriate conditional probability
  distribution \(p(\beta_t|B_{j\neq t}, \psi_T)\) to sample from for our
  Gibbs sampler
\item
  Just as for the Kalman smoother we use the outputs of the Kalman
  filter and a separate backward recursion to obtain the conditional
  distribution
\end{itemize}

\hypertarget{joint-distribution}{%
\section{Joint distribution}\label{joint-distribution}}

Deriving the appropriate distributions is easy if we know what to
condition on. The joint probability density function can be split into a
sequence of conditional distributions: \(p(B_T|\psi_T)\) can be written
recursively \begin{align}
p(B_T|\psi_T) &= p(\beta_T|\psi_T) \times p(B_{T-1}|\beta_T,\psi_T) \\
&= p(\beta_T|\psi_T) \times p(\beta_{T-1}|\beta_T,\psi_T) \times p(B_{T-2}|\beta_{T-1},\beta_T,\psi_T) \\
&= p(\beta_T|\psi_T) \times p(\beta_{T-1}|\beta_T,\psi_T) \times p(B_{T-2}|\beta_{T-1},\psi_T)
\end{align} Final simplification follows as the state vector is a Markov
chain so there is no information in \(\beta_T\) not contained in
\(\beta_{T-1}\) and \(\psi_T\). Further as soon as we know
\(\beta_{T-1}\) there is no information contained in \(\psi_T\) so we
can drop that, so \begin{align}
p(B_T|\psi_T) &= p(\beta_T|\psi_T)\times p(\beta_{T-1}|\beta_T, \psi_T) \times  p(B_{T-2}|\beta_{T-1},\psi_T) \\
&= p(\beta_T|\psi_T)\times p(\beta_{T-1}|\beta_T, \psi_{T-1}) \times p(B_{T-2}|\beta_{T-1},\psi_{T-2}) \\
&= p(\beta_T|\psi_T) \times \prod_{t=1}^{T-1} p(\beta_t|\beta_{t+1}, \psi_t)
\end{align}

\hypertarget{the-carter-kohn-equations}{%
\section{The Carter-Kohn equations}\label{the-carter-kohn-equations}}

The estimated \(\beta\) variables are distributed \begin{align}
\beta_{T|\psi_T} &\sim N(\beta_{T|T}, P_{T|T}) \\
\beta_{t|\psi_t, \beta_{t+1}} &\sim N(\beta_{t|t,\beta_{t+1}},P_{t|t,\beta_{t+1}})
\end{align} where \begin{align}
\beta_{t|t,\beta_{t+1}} &= E\left[\beta_t|\psi_t,\beta_{t+1}\right]
= E\left[\beta_t|\beta_{t|t},\beta_{t+1}\right] \\
P_{t|t,\beta_{t+1}} &= cov\left[\beta_t|\psi_t,\beta_{t+1}\right] = cov\left[\beta_t |{\beta_{t|t},\beta_{t+1}}\right]
\end{align} Carter-Kohn derive appropriate recursions so that, for
example, we update the state estimate conditioning on some known value
of \(\beta_{t+1}\) \begin{equation}
  \beta_{t|t,\beta_{t+1}} = \beta_{t|t}-K_{t|t+1} (\beta_{t+1}-F\beta_{t|t}-\mu)
\end{equation} Define \begin{equation}
   \varsigma_{t+1|t} = \beta_{t+1}-F\beta_{t|t}-\mu
\end{equation} as the `innovation' in predicted \(\beta_{t+1|t}\) where
we have some realized \(\beta_{t+1}\) drawn from its probability
distribution. The Carter-Kohn smoother comprises updates to the
conditional expectations that use this news. \begin{align}
E[\beta_t|\psi_t,\beta_{t+1}] &= E[\beta_t|\psi_t] + \Sigma_{\beta\varsigma} \Sigma_{\varsigma\varsigma}^{-1}\varsigma_{t+1|t} \\
&= \beta_{t|t} + \Sigma_{\beta\varsigma}\Sigma_{\varsigma\varsigma}^{-1}\varsigma_{t+1|t} \\
var[\beta_t|\psi_t,\beta_{t+1}] &= var[\beta_t|\psi_t] -\Sigma_{\beta\varsigma} \Sigma_{\varsigma\varsigma}^{-1} \Sigma_{\varsigma\beta} \\
&= P_{t|t} - \Sigma_{\beta\varsigma} \Sigma_{\varsigma\varsigma}^{-1} \Sigma_{\varsigma\beta} \\
&= P_{t|t,\beta_{t+1}}
\end{align} Both \(\beta_{t|t}\) and \(P_{t|t}\) are outputs of the
Kalman filter.

\hypertarget{deriving-sigma_betavarsigma-and-sigma_varsigmavarsigma}{%
\subsection{\texorpdfstring{Deriving \(\Sigma_{\beta\varsigma}\) and
\(\Sigma_{\varsigma\varsigma}\)}{Deriving \textbackslash Sigma\_\{\textbackslash beta\textbackslash varsigma\} and \textbackslash Sigma\_\{\textbackslash varsigma\textbackslash varsigma\}}}\label{deriving-sigma_betavarsigma-and-sigma_varsigmavarsigma}}

As before we just plug in the definitions so \begin{align}
\Sigma_{\varsigma\varsigma} &= var[\beta_{t+1}-F\beta_{t|t}-\mu] \\
&= var\left[ F\beta_t+\mu +v_{t+1}-F\beta_{t|t}-\mu \right] \\
&= var\left[ F(\beta_t-\beta_{t|t})+v_{t+1}\right] \\
&= F P_{t|t}F' + Q
\end{align} and \begin{align}
\Sigma_{\beta\varsigma} &= E\left[ (\beta_t - \beta_{t|t}) (\beta_{t+1}-F\beta_{t|t}-\mu)'\right] \\
&= E\left[ (\beta_t-\beta_{t|t})\left( F(\beta_t-\beta_{t|t})+v_{t+1}\right)'\right] \\
&= P_{t|t}F'
\end{align}

\hypertarget{kalman-gain-again}{%
\section{`Kalman gain' again}\label{kalman-gain-again}}

So using the definitions of the covariances and the regression lemma we
get \begin{align}
\beta_{t|t,\beta_{t+1}} &= \beta_{t|t} + \Sigma_{s\eta} \Sigma_{\eta\eta}^{-1}\varsigma_t \\
&= \beta_{t|t} + P_{t|t}F' \left( FP_{t|t}F' + Q\right)^{-1} (\beta_{t+1}-F\beta_{t|t}-\mu) \\
&= \beta_{t|t} - K_{t|t}(\beta_{t+1}-F\beta_{t|t}-\mu)
\end{align} where \begin{equation}
   K_{t|t+1} = - P_{t|t}F' (FP_{t|t}F' + Q)^{-1}
\end{equation} Like the Kalman smoother, this uses the filter's estimate
of \(P_{t|t}\) and updates \(\beta_t\) using the error in predicting
\(\beta_{t+1}\) not \(y_t\).

\hypertarget{conditional-mean-and-variance-of-the-state}{%
\subsection{Conditional mean and variance of the
state}\label{conditional-mean-and-variance-of-the-state}}

Updating equations for the state and variance obtained directly from the
regression lemma \begin{align}
\beta_{t|t,\beta_{t+1}} &= \beta_{t|t} - K_{t|t+1}\varsigma_{t+1|t} \\
    P_{t|t,\beta_{t+1}} &= P_{t|t}-P_{t|t}F'(FP_{t|t}F' + Q)^{-1}F P_{t|t}
\end{align} CK equations recursively evaluate these quantities
\emph{backwards} beginning from \(s_T\), \(P_T\) obtained from the
Kalman filter.

Generate appropriate conditional samples using \begin{equation}
  \beta_{t|t,\beta_{t+1}} \sim N\left(\beta_{t|t,\beta_{t+1}}, P_{t|t,\beta_{t+1}} \right)
\end{equation} to give \(B_T|\psi_T\). This is a conditional sample that
depends on a given parameter vector to use in a Gibbs sampling scheme
that draws those parameters in turn from distributions conditioned on
the states.

\hypertarget{state-space-gibbs-sampling-in-practice}{%
\section{State-space Gibbs sampling in
practice}\label{state-space-gibbs-sampling-in-practice}}

Above approach cannot be used explicitly if
\(\Sigma_{\varsigma\varsigma}\) is singular, for example if we have more
states than shocks (which is not uncommon). A simple modification given
in KN can deal with this; we treat only those states that are shocked as
observed.

In general we need conditional distributions for all the other
parameters to be estimated. Need to store the complete sequence of
states and covariances to implement the Gibbs sampler. We will
investigate the exact implementation of Gibbs sampling for state-space
models in the exercises.

\hypertarget{comparing-the-filters-and-smoothers}{%
\section{Comparing the filters and
smoothers}\label{comparing-the-filters-and-smoothers}}

\begin{alignat*}{3}
&\text{Filter} & &\text{Innovation} & & \text{Gain and state covariance}  \\
& && &&\\
&KF &\qquad\ &\eta_t = y_t-H_t\beta_{t|t-1} && K_{t|t} =-P_{t|t-1}H_t' (H_t P_{t|t-1} H_t' + R)^{-1} \\
& &&  && P_{t|t} = P_{t|t-1}-P_{t|t-1} H_t'(H_t P_{t|t-1} H_t' +R)^{-1} H_t P_{t|t-1} \\
&KS && \varsigma_t = \beta_{t+1|T}-F\beta_{t|t}-\mu & \qquad\ & K_{t|T}=-P_{t|t}F' P_{t+1|t}^{-1} \\
&   &&      && P_{t|T} = P_{t|t}+K_{t|T}(P_{t+1|T}-P_{t+1|t}) K_{t|T}' \\
&CK && \varsigma_t = \beta_{t+1}-F\beta_{t|t}-\mu && K_{t|t,\beta_{t+1}} = -P_{t|t}F' P_{t+1|t}^{-1} \\ 
&   &&   && P_{t|t,\beta_{t+1}} = P_{t|t}-P_{t|t}F'(FP_{t|t}F' + Q)^{-1}FP_{t|t}
\end{alignat*}

\part{Networks}

\hypertarget{causal-inference}{%
\chapter{Causal Inference}\label{causal-inference}}

Outline how to solve the Pearl, Glymour, and Jewell (2016) exercises in
R.

\hypertarget{study-question-1.3.2}{%
\section{Study question 1.3.2}\label{study-question-1.3.2}}

Data:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\NormalTok{ed }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{Gender =} \FunctionTok{c}\NormalTok{(}\StringTok{"M"}\NormalTok{,}\StringTok{"M"}\NormalTok{,}\StringTok{"M"}\NormalTok{,}\StringTok{"M"}\NormalTok{,}\StringTok{"F"}\NormalTok{,}\StringTok{"F"}\NormalTok{,}\StringTok{"F"}\NormalTok{,}\StringTok{"F"}\NormalTok{),}
             \AttributeTok{eLevel =} \FunctionTok{c}\NormalTok{(}\StringTok{"U"}\NormalTok{,}\StringTok{"H"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"G"}\NormalTok{,}\StringTok{"U"}\NormalTok{,}\StringTok{"H"}\NormalTok{,}\StringTok{"C"}\NormalTok{,}\StringTok{"G"}\NormalTok{),}
             \AttributeTok{num    =} \FunctionTok{c}\NormalTok{(}\DecValTok{112}\NormalTok{,}\DecValTok{231}\NormalTok{,}\DecValTok{595}\NormalTok{,}\DecValTok{242}\NormalTok{,}\DecValTok{136}\NormalTok{,}\DecValTok{189}\NormalTok{,}\DecValTok{763}\NormalTok{,}\DecValTok{172}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{total =} \FunctionTok{sum}\NormalTok{(num))}
\end{Highlighting}
\end{Shaded}

which we tabulate as

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrr@{}}
\toprule\noalign{}
Gender & eLevel & num & total \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
M & U & 112 & 2440 \\
M & H & 231 & 2440 \\
M & C & 595 & 2440 \\
M & G & 242 & 2440 \\
F & U & 136 & 2440 \\
F & H & 189 & 2440 \\
F & C & 763 & 2440 \\
F & G & 172 & 2440 \\
\end{longtable}

\hypertarget{exercises-and-answers}{%
\section{Exercises and answers}\label{exercises-and-answers}}

\hypertarget{find-pelevel-h}{%
\subsection{\texorpdfstring{Find
\(P(eLevel = H)\)}{Find P(eLevel = H)}}\label{find-pelevel-h}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(eLevel }\SpecialCharTok{==} \StringTok{"H"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_H =} \FunctionTok{sum}\NormalTok{(num)}\SpecialCharTok{/}\NormalTok{total) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrr@{}}
\toprule\noalign{}
Gender & eLevel & num & total & p\_H \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
M & H & 231 & 2440 & 0.1721311 \\
F & H & 189 & 2440 & 0.1721311 \\
\end{longtable}

\hypertarget{find-pelevel-h-vee-gender-f}{%
\subsection{\texorpdfstring{Find
\(P(eLevel = H\ \vee \ Gender = F)\)}{Find P(eLevel = H\textbackslash{} \textbackslash vee \textbackslash{} Gender = F)}}\label{find-pelevel-h-vee-gender-f}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Gender }\SpecialCharTok{==} \StringTok{"F"} \SpecialCharTok{|}\NormalTok{ eLevel }\SpecialCharTok{==} \StringTok{"H"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_HorF =} \FunctionTok{sum}\NormalTok{(num)}\SpecialCharTok{/}\NormalTok{total) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrr@{}}
\toprule\noalign{}
Gender & eLevel & num & total & p\_HorF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
M & H & 231 & 2440 & 0.6110656 \\
F & U & 136 & 2440 & 0.6110656 \\
F & H & 189 & 2440 & 0.6110656 \\
F & C & 763 & 2440 & 0.6110656 \\
F & G & 172 & 2440 & 0.6110656 \\
\end{longtable}

\hypertarget{find-pelevel-h-gender-f}{%
\subsection{\texorpdfstring{Find
\(P(eLevel = H\ |\ Gender = F)\)}{Find P(eLevel = H\textbackslash{} \textbar\textbackslash{} Gender = F)}}\label{find-pelevel-h-gender-f}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(Gender }\SpecialCharTok{==} \StringTok{"F"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{tcond =} \FunctionTok{sum}\NormalTok{(num)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(eLevel }\SpecialCharTok{==} \StringTok{"H"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_HgivenF =} \FunctionTok{sum}\NormalTok{(num)}\SpecialCharTok{/}\NormalTok{tcond) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrrr@{}}
\toprule\noalign{}
Gender & eLevel & num & total & tcond & p\_HgivenF \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
F & H & 189 & 2440 & 1260 & 0.15 \\
\end{longtable}

\hypertarget{find-pgender-f-elevel-h}{%
\subsection{\texorpdfstring{Find
\(P(Gender = F\ | \ eLevel = H)\)}{Find P(Gender = F\textbackslash{} \textbar{} \textbackslash{} eLevel = H)}}\label{find-pgender-f-elevel-h}}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ed }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(eLevel }\SpecialCharTok{==} \StringTok{"H"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{tcond =} \FunctionTok{sum}\NormalTok{(num)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{filter}\NormalTok{(Gender }\SpecialCharTok{==} \StringTok{"F"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{p\_FgivenH =} \FunctionTok{sum}\NormalTok{(num)}\SpecialCharTok{/}\NormalTok{tcond) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{kable}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{longtable}[]{@{}llrrrr@{}}
\toprule\noalign{}
Gender & eLevel & num & total & tcond & p\_FgivenH \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
F & H & 189 & 2440 & 420 & 0.45 \\
\end{longtable}

\hypertarget{mapping-regional-house-price-inflation}{%
\chapter{Mapping regional house price
inflation}\label{mapping-regional-house-price-inflation}}

\hypertarget{how-heterogenous-is-uk-house-price-inflation}{%
\section{How heterogenous is UK house price
inflation?}\label{how-heterogenous-is-uk-house-price-inflation}}

A simple enough question, and one that Bahaj, Foulis, and Pinter
(2020)\index{Bahaj et al.|textbf} thought was best answered with a map
-- actually a referee asked for one. As I know how to draw a map in R
they asked me if I could do it. Well yes, but there are some particular
difficulties.

\begin{itemize}
\tightlist
\item
  The UK (actually Great Britain) is an awkward (but not too awkward)
  shape.
\item
  Population in the UK is heavily concentrated in a small number of
  centres, such as London or Manchester.
\item
  There are three different periods to compare.
\item
  It has to be in grayscale.
\end{itemize}

Before all of this we need some data, with boundaries that correspond to
areas that we have data for. The regional inflation data is available at
the level of the
\href{https://www.gov.uk/government/organisations/land-registry}{Land
Registry}, which almost by local authority but amalgamates a number of
the areas. So a map at Local Authority level would be fine as long as we
can amalgamate some of the regions.

The map data used here is available from the UK's
\href{https://geoportal.statistics.gov.uk/}{ONS
geoportal}\index{ONS!geoportal}, with a lot of administrative data
available including local authority boundaries. The Local Authority data
is specifically available from
\href{https://geoportal.statistics.gov.uk/maps/lad-dec-2015-generalised-clipped-boundaries-gb}{here},
where I use the clipped full extent version. There are a number of
possibilities, but in general high water mark, and enough but not too
much detail is needed.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(readxl)}
\FunctionTok{library}\NormalTok{(sf)}
\end{Highlighting}
\end{Shaded}

The information in the map file is comprehensive, and by Local Authority
as of December 2015.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{fle }\OtherTok{\textless{}{-}} \StringTok{"LAD\_Dec\_2015\_GCB\_GB"}
\NormalTok{shape }\OtherTok{\textless{}{-}} \FunctionTok{read\_sf}\NormalTok{(}\AttributeTok{dsn=}\StringTok{"."}\NormalTok{, }\AttributeTok{layer=}\NormalTok{fle)}
\end{Highlighting}
\end{Shaded}

We can look at the attributes using \texttt{summary}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{summary}\NormalTok{(shape)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
   lad15cd            lad15nm            lad15nmw           GlobalID        
 Length:380         Length:380         Length:380         Length:380        
 Class :character   Class :character   Class :character   Class :character  
 Mode  :character   Mode  :character   Mode  :character   Mode  :character  
          geometry  
 MULTIPOLYGON :380  
 epsg:27700   :  0  
 +proj=tmer...:  0  
\end{verbatim}

This can be plotted straightforwardly using \texttt{ggplot}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{geometry=}\NormalTok{geometry, }\AttributeTok{fill=}\NormalTok{lad15nm), }
          \AttributeTok{color=}\ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{66}\NormalTok{, }\AttributeTok{show.legend=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_void}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Maps_files/figure-pdf/map0a-1.pdf}

}

\end{figure}

Looking at the read-out above, each of the 380 regions have some
metadata associated, which are contained in each of the listed
attributes. It should be obvious that \texttt{objectid} is just a
sequence from 1 to 380. \texttt{lad15nm} turns out to be a list of names
of the regions -- I suspect \texttt{lad} for Local Authority District,
\texttt{15} for 2015 and \texttt{nm} for name -- and it is easy to
specify this as the name to use for the region when using \texttt{tidy}.

Now this can be plotted using \texttt{ggplot}, using \texttt{geometry}
for the \(x\) and \(y\) coordinates. The choice of fill colour is
determined by \texttt{fill} and we can set the colour of the lines by
\texttt{colour} (or \texttt{color}). The two extra arguments are for a
suitable blank style and to impose an appropriate ratio of height to
width.

Immediately, the awkward shape of the British Isles is apparent. (Note
this is a plot of Great Britain, and there is no Northern Ireland.) The
islands to the far north are somewhat unnecessary, although quite
rightly the inhabitants get a bit tired of being left off maps!
Nonetheless I'll do exactly the same by filtering out the polygons
associated with \texttt{Orkney\ Islands} and \texttt{Shetland\ Islands}.

Fewer Scottish Islands makes the graphs a lot clearer with little loss
of information, paticularly given the tiny number of transactions in the
Orkneys and the Shetlands, very far to the north.

In what follows we filter out the islands using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape }\OtherTok{\textless{}{-}} \FunctionTok{read\_sf}\NormalTok{(}\AttributeTok{dsn=}\StringTok{"."}\NormalTok{, }\AttributeTok{layer=}\NormalTok{fle) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{filter}\NormalTok{(}\SpecialCharTok{!}\NormalTok{lad15nm }\SpecialCharTok{\%in\%} \FunctionTok{c}\NormalTok{(}\StringTok{"Shetland Islands"}\NormalTok{,}\StringTok{"Orkney Islands"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Country=}\FunctionTok{str\_sub}\NormalTok{(lad15cd, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{), }\AttributeTok{.after=}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

where we also create an indicator of country using the first letter of
the code string.

So the final country map is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{shape }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(Country) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{fill=}\NormalTok{Country), }\AttributeTok{color=}\StringTok{"grey77"}\NormalTok{, }\AttributeTok{linewidth=}\NormalTok{.}\DecValTok{25}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{66}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_void}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Maps_files/figure-pdf/map0d-1.pdf}

}

\end{figure}

\begin{tcolorbox}[enhanced jigsaw, toptitle=1mm, rightrule=.15mm, opacitybacktitle=0.6, breakable, arc=.35mm, title=\textcolor{quarto-callout-tip-color}{\faLightbulb}\hspace{0.5em}{\texttt{group} and \texttt{summarise} can join geographical areas}, colbacktitle=quarto-callout-tip-color!10!white, bottomtitle=1mm, opacityback=0, colframe=quarto-callout-tip-color-frame, toprule=.15mm, titlerule=0mm, left=2mm, bottomrule=.15mm, colback=white, leftrule=.75mm, coltitle=black]

Note the really nice feature -- if we group by something, in this case
country, we can summarise to amalgamate the geometries!

\end{tcolorbox}

You may have noticed, one thing that that's missing on the LA graphs is
the boundaries. They aren't, they're just invisible. That's because I
set \texttt{colour\ =\ NA}, so I can fix that by choosing a colour and
making the lines very thin so they don't swamp the map, as in the
country one.

One further amendment, the \texttt{fill} is moved inside the
\texttt{aes()} specification and made conditional. \texttt{R} now
chooses unique colours for each of the regions.

Two things now need to be done to get the map colours right to
illustrate regional inflation rates. First we need to amalgamate some of
the Local Authority boundaries to the Land Registry definitions, and
second we need to assign the inflation rate to each area.

\hypertarget{inflation-data-and-regions}{%
\section{Inflation data and regions}\label{inflation-data-and-regions}}

We have a map, and we have that data in a form that is easy to
understand. If we can suitably attach an inflation rate to each area
then we can fill the individual areas with a colour unique to each
individual inflation rates.

Recall that the Land Registry areas aren't quite what we have, and will
need amalgamating. Bahaj, Foulis, and Pinter (2020) supplied me the
areas that needed amalgamating (and the inflation rates) using the
\href{https://en.wikipedia.org/wiki/ONS_coding_system}{ONS codes}. This
is contained in the metadata \texttt{lad15cd} above.

The data is structured in `wide' format with one row for each Land
Registry region. The details aren't very important for us now, but what
it means is I can manipulate it to get

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Price data by Land Registry region, converted to long format}
\NormalTok{hp\_data }\OtherTok{\textless{}{-}} \FunctionTok{read\_excel}\NormalTok{(}\StringTok{"house\_price\_data\_figure\_1.xls"}\NormalTok{)  }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\StringTok{"land\_reg\_region"}\NormalTok{, }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"e\_"}\NormalTok{), }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"av\_"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{names\_to  =} \StringTok{"name"}\NormalTok{, }
               \AttributeTok{values\_to =} \StringTok{"lad15cd"}\NormalTok{, }
               \AttributeTok{cols      =} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{land\_reg\_region, }\SpecialCharTok{{-}}\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"av\_"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{drop\_na}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(land\_reg\_region, lad15cd, }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"av\_"}\NormalTok{)) }

\NormalTok{codes }\OtherTok{\textless{}{-}}\NormalTok{ hp\_data }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(lad15cd, land\_reg\_region) }
\end{Highlighting}
\end{Shaded}

The important thing that the \texttt{pivot\_longer} achieves is that for
every \texttt{land\_reg\_region} I get a list of all the ONS codes that
makes up the Local Authority level. So if I look at
\texttt{buckinghamshire} as an example there are four ONS codes now
associated with it.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{filter}\NormalTok{(codes, land\_reg\_region }\SpecialCharTok{==} \StringTok{"buckinghamshire"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 4 x 2
  lad15cd   land_reg_region
  <chr>     <chr>          
1 E07000004 buckinghamshire
2 E07000005 buckinghamshire
3 E07000006 buckinghamshire
4 E07000007 buckinghamshire
\end{verbatim}

Join these together

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Join polygons defined by Land Registry regions}
\NormalTok{gg }\OtherTok{\textless{}{-}}\NormalTok{ shape }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\FunctionTok{starts\_with}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\StringTok{"lad"}\NormalTok{,}\StringTok{"C"}\NormalTok{))) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{left\_join}\NormalTok{(codes, }\AttributeTok{by=}\StringTok{"lad15cd"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{group\_by}\NormalTok{(land\_reg\_region) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{summarise}\NormalTok{() }
\end{Highlighting}
\end{Shaded}

which produces a match between the Land Registry and the Local Authority
areas, plus the inflation rates.

\hypertarget{inflation-in-grayscale}{%
\subsection{Inflation in grayscale}\label{inflation-in-grayscale}}

All the information required to plot the Land Registry-based regional
inflation rates is now available. As you can see from the
\texttt{buckinghamshire} data above, there are three average rates in
three different periods, so I'll focus on one, 2002-2007 to begin with.

First, augment the geographic data with the inflation data, and call
them something better.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{gg }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{geometry=}\NormalTok{geometry, }\AttributeTok{fill=}\NormalTok{land\_reg\_region), }
          \AttributeTok{color=}\ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{66}\NormalTok{, }\AttributeTok{show.legend =} \ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_void}\NormalTok{()}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Maps_files/figure-pdf/unnamed-chunk-4-1.pdf}

}

\end{figure}

Then specify gray and put the legend at the bottom.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nms }\OtherTok{\textless{}{-}} \FunctionTok{gsub}\NormalTok{(}\StringTok{"av\_hp\_growth"}\NormalTok{, }\StringTok{"HPI"}\NormalTok{, }\FunctionTok{colnames}\NormalTok{(hp\_data))}

\NormalTok{hp\_data }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{rename\_all}\NormalTok{( }\SpecialCharTok{\textasciitilde{}}\NormalTok{ nms) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(land\_reg\_region, }\FunctionTok{starts\_with}\NormalTok{(}\StringTok{"HPI"}\NormalTok{)) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{distinct}\NormalTok{() }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{left\_join}\NormalTok{(gg) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_sf}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{geometry=}\NormalTok{geometry, }\AttributeTok{fill=}\NormalTok{HPI\_02\_07), }
          \AttributeTok{color=}\ConstantTok{NA}\NormalTok{, }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{66}\NormalTok{, }\AttributeTok{show.legend =} \ConstantTok{TRUE}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_void}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{scale\_fill\_gradient}\NormalTok{(}\AttributeTok{low=}\FunctionTok{grey}\NormalTok{(}\FloatTok{0.9}\NormalTok{), }\AttributeTok{high=}\FunctionTok{grey}\NormalTok{(}\FloatTok{0.05}\NormalTok{)) }\SpecialCharTok{+}
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.direction =} \StringTok{"horizontal"}\NormalTok{, }
        \AttributeTok{legend.position  =} \FunctionTok{c}\NormalTok{(}\FloatTok{0.75}\NormalTok{,}\FloatTok{0.05}\NormalTok{),}
        \AttributeTok{legend.title     =} \FunctionTok{element\_blank}\NormalTok{())}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Joining with `by = join_by(land_reg_region)`
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{Maps_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

\part{Time}

\hypertarget{linear-rational-expectations-models}{%
\chapter{Linear rational expectations
models}\label{linear-rational-expectations-models}}

\hypertarget{introduction-1}{%
\section{Introduction}\label{introduction-1}}

How do we solve rational expectations models? What does that even mean?
Here I show how to implement versions of the Blanchard and Kahn
(1980)\index{Blanchard, O.}\index{Kahn, C.} and Klein (2000) solutions
to linear rational expectations models in R. The implementation is
fairly general, and copes with singular models. It is a very transparent
implementation, with all the necessary code, and also shows how to
calculate and plot impulse responses.

\hypertarget{model}{%
\section{Model}\label{model}}

We take a simple New Keynesian model \begin{align}
y_t    &= y_{t+1}^e-\frac{1}{\sigma} (i_t - \pi_{t+1}^e) + e_t^1 \\
\pi_t  &= \beta \pi_{t+1}^e + \kappa y_t + e_t^2 \\
i_t    &= \gamma i_{t-1} + (1-\gamma) \delta \pi_t + \varepsilon_t^3 \\ 
e_t^1  &= \rho_1 e_{t-1}^1 + \varepsilon_t^1 \\ 
e_t^2  &= \rho_2 e_{t-1}^2 + \varepsilon_t^2 
\end{align} The model comprises a dynamic IS curve, a Phillips Curve and
a policy rule with smoothing. There are three shocks, two of which are
persistent. This we need to write in the general algebraic linear
state-space form: \[
E\begin{bmatrix} z_t \\ x_{t+1}^e \end{bmatrix} = A \begin{bmatrix} z_{t-1} \\ x_t \end{bmatrix} + B \varepsilon_t  
\] We map our variables to their algebraic equivalent as (\(z_t\),
\(x_t\)) \(=\) ((\(e^1_t\), \(e^2_t\), \(i_t\)), (\(y_t\), \(\pi_t\))).
Then the model in state-space form but including the matrix \(E\) is \[
\begin{bmatrix} 1 & 0 & 0 & 0 & 0 \\ 
                0 & 1 & 0 & 0 & 0 \\ 
                0 & 0 & 1 & 0 & 0 \\ 
                1 & 0 & -\frac{1}{\sigma} & 1 & \frac{1}{\sigma} \\ 
                0 & 1 & 0 & 0 & \beta
\end{bmatrix}
\begin{bmatrix} e^1_t \\ e^2_t \\ i_t \\ y^e_{t+1} \\ \pi^e_{t+1} \end{bmatrix} 
   = 
   \begin{bmatrix} \rho_1 & 0 & 0 & 0 & 0 \\ 
                0 & \rho_2 & 0 & 0 & 0 \\ 
                0 & 0 & \gamma & 0 & (1-\gamma)\delta \\ 
                0 & 0 & 0 & 1 & 0 \\ 
                0 & 0 & 0 & -\kappa & 1
   \end{bmatrix}
\begin{bmatrix} e^1_{t-1} \\ e^2_{t-1} \\ i_{t-1} \\ y_t \\ \pi_t \end{bmatrix}    
   + 
      \begin{bmatrix} 
                1 & 0 & 0  \\ 
                0 & 1 & 0 \\ 
                0 & 0 & 1 \\ 
                0 & 0 & 0 \\ 
                0 & 0 & 0 
   \end{bmatrix}
   \begin{bmatrix} \varepsilon^1_t \\ \varepsilon^2_t \\ \varepsilon^3_t \end{bmatrix}    
\] Anyone wanting to code up solutions should familiarize themselves
with this before continuing.

\hypertarget{coding-the-model}{%
\subsection{Coding the model}\label{coding-the-model}}

Before we begin coding this in R, load the \texttt{tidyverse} libraries
so we can do impulse responses with our usual tool kit and then we can
forget about it.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\end{Highlighting}
\end{Shaded}

Set the model parameters

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nf    }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{ns    }\OtherTok{\textless{}{-}} \DecValTok{5}
\NormalTok{ne    }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{np    }\OtherTok{\textless{}{-}}\NormalTok{ ns}\SpecialCharTok{{-}}\NormalTok{nf}

\NormalTok{beta  }\OtherTok{\textless{}{-}} \FloatTok{0.99}   \CommentTok{\# Discount factor }
\NormalTok{sigma }\OtherTok{\textless{}{-}} \FloatTok{2.0}    \CommentTok{\# Elas. substitution}
\NormalTok{kappa }\OtherTok{\textless{}{-}} \FloatTok{0.075}  \CommentTok{\# Slope PC}
\NormalTok{delta }\OtherTok{\textless{}{-}} \FloatTok{1.5}    \CommentTok{\# Inflation feedback}
\NormalTok{gamma }\OtherTok{\textless{}{-}} \FloatTok{0.75}   \CommentTok{\# Smoothing}
\NormalTok{rho\_1 }\OtherTok{\textless{}{-}} \FloatTok{0.9}    \CommentTok{\# AR1}
\NormalTok{rho\_2 }\OtherTok{\textless{}{-}} \FloatTok{0.8}    \CommentTok{\# AR1}
\NormalTok{Omega }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.33}\NormalTok{,}\FloatTok{0.33}\NormalTok{,}\FloatTok{0.33}\NormalTok{)) }\CommentTok{\# SE of 3 shocks}
\end{Highlighting}
\end{Shaded}

Now define the model matrices `long hand' and some variable names, which
we put in \texttt{labels}.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"e\^{}1"}\NormalTok{,}\StringTok{"e\^{}2"}\NormalTok{,}\StringTok{"i"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"pi"}\NormalTok{)}

\NormalTok{E }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ns)}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ns)}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{diag}\NormalTok{(}\DecValTok{1}\NormalTok{,ns,ne)}

\CommentTok{\# Now put the equations in matrix form}
\FunctionTok{diag}\NormalTok{(E[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]) }\OtherTok{\textless{}{-}} \DecValTok{1}
\FunctionTok{diag}\NormalTok{(A[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(rho\_1, rho\_2)}

\NormalTok{E[}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{]             }\OtherTok{\textless{}{-}} \DecValTok{1} 
\NormalTok{E[}\DecValTok{4}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma)}
\NormalTok{E[}\DecValTok{5}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{5}\NormalTok{)]       }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, beta)}

\NormalTok{A[}\DecValTok{3}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)]       }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(gamma, (}\DecValTok{1}\SpecialCharTok{{-}}\NormalTok{gamma)}\SpecialCharTok{*}\NormalTok{delta)}
\NormalTok{A[}\DecValTok{4}\NormalTok{,}\DecValTok{4}\NormalTok{]             }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{A[}\DecValTok{5}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)]        }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{kappa, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

where for example, \(E\) and \(A\) are \begin{equation}
  E = \left[\begin{matrix}1 &0 &0 &0 &0 \\0 &1 &0 &0 &0 \\0 &0 &1 &0 &0 \\1 &0 &-0.5 &1 &0.5 \\0 &1 &0 &0 &0.99 \\\end{matrix}\right] 
\end{equation} \begin{equation}  
  A = \left[\begin{matrix}0.9 &0 &0 &0 &0 \\0 &0.8 &0 &0 &0 \\0 &0 &0.75 &0 &0.375 \\0 &0 &0 &1 &0 \\0 &0 &0 &-0.075 &1 \\\end{matrix}\right] 
\end{equation} Calculate the reduced form state-space model
\begin{equation}
\begin{bmatrix} z_t \\ x_{t+1}^e \end{bmatrix} = C \begin{bmatrix} z_{t-1} \\ x_t \end{bmatrix} + D \varepsilon_t  
\end{equation} which is done in R very simply as

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{C }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(E,A)}
\NormalTok{D }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(E,B)}
\end{Highlighting}
\end{Shaded}

Why can't we solve this for impulse responses?

The following function simulates the impulse responses of a model in a
loop within a loop\footnote{Sometimes a loop is the right way to do
  something.} and returns the time series in a suitably organised data
frame.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{impulse\_responses }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(P, Q, Omega, labels, T) \{}
\NormalTok{  s   }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{ncol}\NormalTok{(Q), }\DecValTok{1}\NormalTok{)}
\NormalTok{  z   }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{, }\FunctionTok{nrow}\NormalTok{(Q), T)}
  \FunctionTok{rownames}\NormalTok{(z) }\OtherTok{\textless{}{-}}\NormalTok{ labels}
\NormalTok{  dza }\OtherTok{\textless{}{-}} \ConstantTok{NULL}
  \ControlFlowTok{for}\NormalTok{ (j }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\FunctionTok{ncol}\NormalTok{(Q)) \{}
\NormalTok{    s[j]  }\OtherTok{\textless{}{-}}\NormalTok{ Omega[j,j]}
\NormalTok{    z[,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ Q }\SpecialCharTok{\%*\%}\NormalTok{ s}
    \ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{(T}\DecValTok{{-}1}\NormalTok{)) \{}
\NormalTok{      z[,i}\SpecialCharTok{+}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}}\NormalTok{ P }\SpecialCharTok{\%*\%}\NormalTok{ z[,i]}
\NormalTok{    \}}
\NormalTok{    s[j] }\OtherTok{\textless{}{-}} \DecValTok{0}
\NormalTok{    dz }\OtherTok{\textless{}{-}} \FunctionTok{as\_tibble}\NormalTok{(}\FunctionTok{t}\NormalTok{(z)) }\SpecialCharTok{\%\textgreater{}\%} 
      \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Period =} \DecValTok{1}\SpecialCharTok{:}\NormalTok{T, }\AttributeTok{Shock =} \FunctionTok{paste0}\NormalTok{(}\StringTok{"epsilon\^{}"}\NormalTok{,j))}
\NormalTok{    dza }\OtherTok{\textless{}{-}} \FunctionTok{bind\_rows}\NormalTok{(dza,dz)}
\NormalTok{  \}}
  \FunctionTok{return}\NormalTok{(dza)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

A function to plot the impulses will be useful, so we create one.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{response\_plot }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(series, title) \{}
  \FunctionTok{return}\NormalTok{(}\FunctionTok{pivot\_longer}\NormalTok{(series, }\AttributeTok{cols =} \SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(Period,Shock), }\AttributeTok{names\_to=}\StringTok{"Var"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"Val"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
           \FunctionTok{ggplot}\NormalTok{() }\SpecialCharTok{+}
           \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Period, }\AttributeTok{y=}\NormalTok{Val, }\AttributeTok{group=}\NormalTok{Shock, }\AttributeTok{colour=}\NormalTok{Var), }\AttributeTok{show.legend=}\ConstantTok{FALSE}\NormalTok{) }\SpecialCharTok{+}
           \FunctionTok{facet\_grid}\NormalTok{(Shock}\SpecialCharTok{\textasciitilde{}}\NormalTok{Var, }\AttributeTok{scales=}\StringTok{"free"}\NormalTok{, }\AttributeTok{labeller=}\NormalTok{label\_parsed) }\SpecialCharTok{+}
           \FunctionTok{scale\_x\_continuous}\NormalTok{(}\AttributeTok{expand=}\FunctionTok{c}\NormalTok{(}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{)) }\SpecialCharTok{+}
           \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+}
           \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\NormalTok{title, }\AttributeTok{x=}\StringTok{""}\NormalTok{,}\AttributeTok{y=}\StringTok{""}\NormalTok{))}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Call the impulse response function using the model \(C\) and \(D\).

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{impulse\_responses}\NormalTok{(C, D, Omega, labels, T)}
\end{Highlighting}
\end{Shaded}

and plot

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{response\_plot}\NormalTok{(z, }\StringTok{"Impulse responses: Taylor rule"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{BK_files/figure-pdf/unnamed-chunk-4-1.pdf}

}

\end{figure}

Oh! That's not looking good. Let's try a few more periods.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{150}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{impulse\_responses}\NormalTok{(C, D, Omega, labels, T)}
\FunctionTok{response\_plot}\NormalTok{(z, }\StringTok{"Impulse responses: Taylor rule"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{BK_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

This is clearly exploding. But it's rational -- we're solving forward so
expectations are always fulfilled. This is a key the insight of the
early rational expectations modellers -- rational isn't enough,
non-explosive is necessary too. Fortunately we know how to find this.

\hypertarget{bk80}{%
\section{Blanchard and Kahn (1980)}\label{bk80}}

To solve this model to give a unique \emph{stable} rational expectations
equilibrium, we appeal to the following. Consider the eigenvalue
decomposition \[
  MC=\Lambda M
\] where \(\Lambda\) is a diagonal matrix of \emph{eigenvalues} in
increasing absolute value and \(M\) is a non-singular matrix of
\emph{left eigenvectors}. Note that computer routines (including the one
in R) usually calculate \emph{right eigenvectors} such that
\(CV=V\Lambda\) and that \(M=V^{-1}\), so be aware of this in what
follows.

We can \emph{diagonalise} \(C\) and write it as \(C=M^{-1}\Lambda M\).
So pre-multiplying the reduced form model by \(M\) gives \[ 
M \begin{bmatrix} z_t \\ x_{t+1}^e \end{bmatrix} = \Lambda M \begin{bmatrix} z_{t-1} \\ x_t \end{bmatrix} + M D \varepsilon_t
\] Blanchard and Kahn (1980)\index{Blanchard-Kahn!conditions} (following
Vaughan (1970)) show uniqueness requires as many unstable eigenvalues as
jump variables. To see this, define \[
\begin{bmatrix} \xi_{t-1}^{s} \\  \xi_t^{u} \end{bmatrix}
  =  \begin{bmatrix} M_{11} & M_{12} \\  M_{21} & M_{22} \end{bmatrix}
      \begin{bmatrix} z_{t-1} \\  x_t \end{bmatrix}
\] Write the normalized model as \[
\begin{bmatrix} \xi_t^s \\ \xi_{t+1}^u \end{bmatrix}
 = \begin{bmatrix} \Lambda_s & 0 \\ 0 & \Lambda_u \end{bmatrix} 
\begin{bmatrix} \xi_{t-1}^s \\ \xi_t^u \end{bmatrix} +
\begin{bmatrix} M_1 \\ M_2 \end{bmatrix} D\varepsilon_t
\] where the eigenvalues are split into stable (\(\Lambda_s\)) and
unstable (\(\Lambda_u\)). If we ignore the stochastic bit for a moment
\[
\begin{bmatrix} \xi_t^s \\ \xi_{t+1}^u \end{bmatrix}
 = \begin{bmatrix} \Lambda_s & 0 \\ 0 & \Lambda_u \end{bmatrix} 
\begin{bmatrix} \xi_{t-1}^s \\ \xi_t^u \end{bmatrix}
\]

We seek a non-explosive solution, and this turns out to be easy to find
using the following

\begin{itemize}
\tightlist
\item
  The dynamics of \(\xi_t^u\) are determined by \(\Lambda_u\) and
  nothing else;
\item
  If they don't start at \(0\) they must explode;
\item
  This implies they must start at \(0\) and are always \(0\).
\end{itemize}

Thus the definition of the canonical variables necessarily implies \[
\begin{bmatrix} \xi_{t-1}^s \\  0 \end{bmatrix}
  =  \begin{bmatrix} M_{11} & M_{12} \\  M_{21} & M_{22} \end{bmatrix}
      \begin{bmatrix} z_{t-1} \\  x_t \end{bmatrix}
\]

From this it is clear that the jump variables themselves are only on the
saddle path if \[
   M_{21} z_{t-1} + M_{22} x_t = 0
\]

The rational solution implies that the jump variables are linearly
related to the predetermined ones through \begin{align}
x_t &= -M_{22}^{-1} M_{21}z_{t-1} \\
    &= N z_{t-1}
\end{align} We'll deal with the shocks in a moment.

How do we do this in R? First, find the eigenvalue decomposition of
\(C\) using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{m }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(C, }\AttributeTok{symmetric=}\ConstantTok{FALSE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

which yields

\begin{verbatim}
eigen() decomposition
$values
[1] 1.0715518+0.092734i 1.0715518-0.092734i 0.9000000+0.000000i
[4] 0.8000000+0.000000i 0.6548762+0.000000i

$vectors
                      [,1]                  [,2]         [,3]           [,4]
[1,]  0.0000000+0.0000000i  0.0000000+0.0000000i 0.2854942+0i  0.00000000+0i
[2,]  0.0000000+0.0000000i  0.0000000+0.0000000i 0.0000000+0i  0.09783896+0i
[3,]  0.1599159-0.5089425i  0.1599159+0.5089425i 0.7830500+0i  0.49622464+0i
[4,] -0.6991064+0.0000000i -0.6991064+0.0000000i 0.4552131+0i -0.86012270+0i
[5,]  0.2629802-0.3968579i  0.2629802+0.3968579i 0.3132200+0i  0.06616328+0i
              [,5]
[1,]  0.0000000+0i
[2,]  0.0000000+0i
[3,]  0.6351203+0i
[4,] -0.7554249+0i
[5,] -0.1611069+0i
\end{verbatim}

However this calculates \emph{right} eigenvectors. We will need to
invert it for left ones. Given the number of jump variables in the model
satisfies the Blanchard-Kahn conditions\index{Blanchard-Kahn!conditions}
of as many unstable roots (1.072+0.093i, 1.072-0.093i) as jump variables
(2) we can calculate the reaction function from the eigenvectors

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{iz }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\NormalTok{np}
\NormalTok{ix }\OtherTok{\textless{}{-}}\NormalTok{ (np}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{ns}
\NormalTok{M  }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(m}\SpecialCharTok{$}\NormalTok{vectors[,ns}\SpecialCharTok{:}\DecValTok{1}\NormalTok{])        }\CommentTok{\# Invert \& reverse order for increasing abs value}
\NormalTok{N  }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\FunctionTok{Re}\NormalTok{(}\FunctionTok{solve}\NormalTok{(M[ix,ix], M[ix,iz])) }\CommentTok{\# Drop tiny complex bits (if any)}
\end{Highlighting}
\end{Shaded}

where \texttt{iz} are the indices of the first \texttt{np} variables and
\texttt{ix} those of the remaining \texttt{nf} ones.

\hypertarget{stochastic-part}{%
\subsection{Stochastic part}\label{stochastic-part}}

What about the shocks? Assume the stochastic reaction function is \[
  x_t = N z_{t-1} + G \varepsilon_t 
\] Following Andrew P. Blake (2004), note that \(x_{t+1}^e = N z_t\) as
the expected value of \(\varepsilon_{t+1}=0\), meaning we can write \[
 Nz_t = C_{21}z_{t-1} + C_{22} x_t + D_2 \varepsilon_t
\] or \[
 N\left( C_{11}z_{t-1} + C_{12}x_t + D_1 \varepsilon_t\right) = C_{21}z_{t-1} + C_{22} x_t + D_2 \varepsilon_t
\] Gathering terms we obtain \[
  (C_{22} - N C_{12}) x_t = (NC_{11} - C_{21}) z_{t-1} + (N D_1 - D_2) \varepsilon_t
\] which implies \[
G=(C_{22} - N C_{12})^{-1}(N D_1 - D_2) 
\] Notice it also implies
\(N = (C_{22} - N C_{12})^{-1}(NC_{11} - C_{21})\). It is this fixed
point nature of the solution for \(N\) -- which in turn implies the
quadratic matrix equation \(C_{21} = NC_{11} - C_{22}N + N C_{12}N\) --
that means we need to use the Blanchard and Kahn
(1980)\index{Blanchard-Kahn!method} method in the first place.

All of this means that

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{G }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{((C[ix,ix] }\SpecialCharTok{{-}}\NormalTok{ N }\SpecialCharTok{\%*\%}\NormalTok{ C[iz,ix]), (N }\SpecialCharTok{\%*\%}\NormalTok{ D[iz,]}\SpecialCharTok{{-}}\NormalTok{ D[ix,]))}
\end{Highlighting}
\end{Shaded}

so for our model and parameters \(N\) and \(G\) are

\begin{equation}  
  N = \left[\begin{matrix}4.8568 &-2.7586 \\-1.1894 &1.7929 \\1.9628 &-0.2537 \\\end{matrix}\right] 
\end{equation} \begin{equation}
  G = \left[\begin{matrix}5.3964 &-3.4483 \\-1.5859 &1.9921 \\2.4535 &-0.3382 \\\end{matrix}\right] 
\end{equation}

The `fixed point' check is that the following should be the same as
\(N\)

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{solve}\NormalTok{((C[ix,ix] }\SpecialCharTok{{-}}\NormalTok{ N }\SpecialCharTok{\%*\%}\NormalTok{ C[iz,ix]), (N }\SpecialCharTok{\%*\%}\NormalTok{ C[iz,iz]}\SpecialCharTok{{-}}\NormalTok{ C[ix,iz]))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        [,1]      [,2]       [,3]
[1,] 4.85680 -2.758647 -1.1894200
[2,] 1.79286  1.962790 -0.2536635
\end{verbatim}

which it is.

The solved model is finally \begin{align}
\begin{bmatrix} z_t \\ x_t \end{bmatrix} &= \begin{bmatrix} C_{11}+C_{12}N & 0 \\ N & 0 \end{bmatrix} \begin{bmatrix} z_{t-1} \\ x_{t-1} \end{bmatrix} + \begin{bmatrix} D_1+C_{12}G \\ G \end{bmatrix} \varepsilon_t \\
 &= P \begin{bmatrix} z_{t-1} \\ x_{t-1} \end{bmatrix} + Q \varepsilon_t
\end{align} which can be coded as

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{P  }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\FunctionTok{rbind}\NormalTok{((C[iz,iz] }\SpecialCharTok{+}\NormalTok{ C[iz,ix] }\SpecialCharTok{\%*\%}\NormalTok{ N), N), }\FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,nf))}
\NormalTok{Q  }\OtherTok{\textless{}{-}} \FunctionTok{rbind}\NormalTok{(D[iz,] }\SpecialCharTok{+}\NormalTok{ C[iz,ix] }\SpecialCharTok{\%*\%}\NormalTok{ G, G)}
\end{Highlighting}
\end{Shaded}

\hypertarget{digression-right-eigenvector-version}{%
\subsection{Digression -- right eigenvector
version}\label{digression-right-eigenvector-version}}

It turns out that we could use the output from the standard
eigenvalue/vector routine directly by exploiting the following. This
time, let \(M\) be the matrix of \emph{right eigenvectors} so \[
  C M = M \Lambda \text{  or  } C = M\Lambda M^{-1}
\]\\
and \[
\begin{bmatrix} M_{11} & M_{12} \\ M_{21} & M_{22} \end{bmatrix}
\begin{bmatrix} \xi_{t-1}^s \\ \xi_t^u \end{bmatrix}
 = 
\begin{bmatrix} z_{t-1} \\ x_t \end{bmatrix}
\]

Written this way around, if \(\xi_t^{u}=0\) \(\forall\ t\) then (again
ignoring stochastics)

\[
  M_{11} \xi_{t-1}^s = z_{t-1}, \ M_{21}\xi_t^s = x_t 
\]

\[
   \Rightarrow x_t = M_{21} M_{11}^{-1} z_t
\] so

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{M }\OtherTok{\textless{}{-}}\NormalTok{ m}\SpecialCharTok{$}\NormalTok{vectors[,ns}\SpecialCharTok{:}\DecValTok{1}\NormalTok{]            }\CommentTok{\# Don\textquotesingle{}t invert as already right vectors, but reorder}
\FunctionTok{Re}\NormalTok{(M[ix,iz] }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(M[iz,iz])) }\CommentTok{\# Again, drop tiny complex bits}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
        [,1]      [,2]       [,3]
[1,] 4.85680 -2.758647 -1.1894200
[2,] 1.79286  1.962790 -0.2536635
\end{verbatim}

The result is identical. This method is particularly useful if there are
fewer predetermined variables than jumps as the matrix we need to invert
is of the same dimension as the predetermined variables this way round.

\hypertarget{impulse-responses}{%
\subsection{Impulse responses}\label{impulse-responses}}

We now call the impulse response function using the model solved for
rational expectations.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{T }\OtherTok{\textless{}{-}} \DecValTok{25}
\NormalTok{z }\OtherTok{\textless{}{-}} \FunctionTok{impulse\_responses}\NormalTok{(P, Q, Omega, labels, T)}
\end{Highlighting}
\end{Shaded}

Now plot these responses

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{response\_plot}\NormalTok{(z, }\StringTok{"Impulse responses: Taylor rule"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{BK_files/figure-pdf/unnamed-chunk-13-1.pdf}

}

\end{figure}

Now, that looks better! It is no longer explosive. It also makes
complete economic sense, which you can verify by going through the
dynamics of the different demand, supply and monetary shocks.

\hypertarget{generalized-solution}{%
\section{Generalized solution}\label{generalized-solution}}

Sometimes for a model \(E\) is singular. A more general solution was
proposed by Klein (2000), that doesn't require \(E\) to be non-singular.
This uses a generalized Schur decomposition instead of an eigenvalue one
and is applied to the structural model represented by the matrix pencil
\((A,E)\), and is considered much more numerically stable (see Pappas,
Laub, and Sandell (1980)). The generalized Schur form of \((A,E)\) is
\((QTZ', QSZ')\), so we can write the model as \[
E \begin{bmatrix} z_t \\ x_{t+1}^e \end{bmatrix} \equiv QTZ' \begin{bmatrix} z_t \\ x_{t+1}^e \end{bmatrix} \equiv QT \begin{bmatrix} \xi_t^s \\ \xi_{t+1}^u \end{bmatrix} 
\] and \[
A \begin{bmatrix} z_{t-1} \\ x_t \end{bmatrix} \equiv QSZ' \begin{bmatrix} z_{t-1} \\ x_t \end{bmatrix} \equiv QS\begin{bmatrix} \xi_{t-1}^s \\ \xi_t^u \end{bmatrix} 
\] so the model pre-multiplied by \(Q'\) is \[
T \begin{bmatrix} \xi_{t+1}^s \\ \xi_{t+1}^u \end{bmatrix} = S \begin{bmatrix} \xi_t^s \\ \xi_t^u \end{bmatrix} + Q'B\varepsilon_t
\]

We use the function \texttt{gqz} from the library \texttt{geigen} for
this

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{d }\OtherTok{\textless{}{-}}\NormalTok{ geigen}\SpecialCharTok{::}\FunctionTok{gqz}\NormalTok{(A, E, }\AttributeTok{sort=}\StringTok{"S"}\NormalTok{) }\CommentTok{\# Option "S" puts the stable roots first}
\end{Highlighting}
\end{Shaded}

We can check that this is actually saddle path using \texttt{gevalues()}
to get all the eigenvalues from the generalized Schur decomposition, and
the unstable ones are

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ geigen}\SpecialCharTok{::}\FunctionTok{gevalues}\NormalTok{(d)}
\NormalTok{e[}\FunctionTok{abs}\NormalTok{(e) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.071552+0.092734i 1.071552-0.092734i
\end{verbatim}

The number of \emph{stable} roots is returned in \texttt{d\$sdim} which
is 3.

We then modify our solution function to calculate \texttt{Ns} and
\texttt{Gs} using the matrix \texttt{Z} and a generalized version of the
formula for \(G\) and calculate the reduced form model \texttt{Ps} and
`Q which are \begin{align}
    N_s &= Z_{21} Z_{11}^{-1} \\
    H   &= (E_{11} + E_{12} N_s)^{-1} \\
    W   &= (E_{21} + E_{22} N_s) H\\
    G_s &= (A_{22} - W A_{12})^{-1} (W B_1 - B_2) \\
    P_s &= H (A_{11} + A_{12} N_s) \\
    Q_s &= H (B_1 + A_{12} G_s)
\end{align} Verify this yourself with a bit of matrix algebra!

The R code for this is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{solveGenBK }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(E,A,B,n) \{}
\NormalTok{  d  }\OtherTok{\textless{}{-}}\NormalTok{ geigen}\SpecialCharTok{::}\FunctionTok{gqz}\NormalTok{(A, E, }\AttributeTok{sort=}\StringTok{"S"}\NormalTok{) }
\NormalTok{  np }\OtherTok{\textless{}{-}}\NormalTok{ d}\SpecialCharTok{$}\NormalTok{sdim}
\NormalTok{  ns }\OtherTok{\textless{}{-}} \FunctionTok{nrow}\NormalTok{(E)}
  \FunctionTok{print}\NormalTok{(}\FunctionTok{paste}\NormalTok{(}\StringTok{"Number of unstable roots is"}\NormalTok{, ns}\SpecialCharTok{{-}}\NormalTok{np))}
  \ControlFlowTok{if}\NormalTok{ (n }\SpecialCharTok{==}\NormalTok{ np) \{}
\NormalTok{    iz }\OtherTok{\textless{}{-}} \DecValTok{1}\SpecialCharTok{:}\NormalTok{n}
\NormalTok{    ix }\OtherTok{\textless{}{-}}\NormalTok{ (n}\SpecialCharTok{+}\DecValTok{1}\NormalTok{)}\SpecialCharTok{:}\NormalTok{ns}
\NormalTok{    Ns }\OtherTok{\textless{}{-}}\NormalTok{ d}\SpecialCharTok{$}\NormalTok{Z[ix,iz] }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(d}\SpecialCharTok{$}\NormalTok{Z[iz,iz])}
\NormalTok{    H  }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(E[iz,iz] }\SpecialCharTok{+}\NormalTok{ E[iz,ix] }\SpecialCharTok{\%*\%}\NormalTok{ Ns)}
\NormalTok{    W  }\OtherTok{\textless{}{-}}\NormalTok{ (E[ix,iz] }\SpecialCharTok{+}\NormalTok{ E[ix,ix] }\SpecialCharTok{\%*\%}\NormalTok{ Ns) }\SpecialCharTok{\%*\%}\NormalTok{ H}
\NormalTok{    Gs }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{((A[ix,ix] }\SpecialCharTok{{-}}\NormalTok{ W }\SpecialCharTok{\%*\%}\NormalTok{ A[iz,ix]), (W }\SpecialCharTok{\%*\%}\NormalTok{ B[iz,] }\SpecialCharTok{{-}}\NormalTok{ B[ix,]))}
\NormalTok{    As }\OtherTok{\textless{}{-}}\NormalTok{ H }\SpecialCharTok{\%*\%}\NormalTok{ (A[iz,iz] }\SpecialCharTok{+}\NormalTok{ A[iz,ix] }\SpecialCharTok{\%*\%}\NormalTok{ Ns)}
\NormalTok{    Bs }\OtherTok{\textless{}{-}}\NormalTok{ H }\SpecialCharTok{\%*\%}\NormalTok{ (B[iz,] }\SpecialCharTok{+}\NormalTok{ A[iz,ix] }\SpecialCharTok{\%*\%}\NormalTok{ Gs)}
    \FunctionTok{return}\NormalTok{(}\FunctionTok{list}\NormalTok{(}\AttributeTok{P=}\FunctionTok{cbind}\NormalTok{(}\FunctionTok{rbind}\NormalTok{(As,Ns),}\FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ns}\SpecialCharTok{{-}}\NormalTok{n)), }\AttributeTok{Q=}\FunctionTok{rbind}\NormalTok{(Bs, Gs)))}
\NormalTok{    \} }
  \ControlFlowTok{else}\NormalTok{ \{ }
    \FunctionTok{return}\NormalTok{(}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{) }
\NormalTok{    \}}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Using this on our original model gives

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{S  }\OtherTok{\textless{}{-}} \FunctionTok{solveGenBK}\NormalTok{(E,A,B,np)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Number of unstable roots is 2"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ps }\OtherTok{\textless{}{-}}\NormalTok{ S}\SpecialCharTok{$}\NormalTok{P}
\NormalTok{Qs }\OtherTok{\textless{}{-}}\NormalTok{ S}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

and comparing \texttt{Ps} and \texttt{Qs} with \texttt{P} and \texttt{Q}
obtained using Blanchard-Kahn\index{Blanchard-Kahn!method} we find

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{max}\NormalTok{(}\FunctionTok{abs}\NormalTok{(P}\SpecialCharTok{{-}}\NormalTok{Ps), }\FunctionTok{abs}\NormalTok{(Q}\SpecialCharTok{{-}}\NormalTok{Qs)), }\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 0
\end{verbatim}

They are, as expected, the same -- at least up to 12 decimal places,
which should be enough.

\hypertarget{singular-models-optimal-policy}{%
\section{Singular models: optimal
policy}\label{singular-models-optimal-policy}}

However, this is an easy test. What we need is to use a model that can't
be solved using the BK method.\index{Blanchard-Kahn!method} Under
optimal policy, the interest rate instrument rule is replaced with a
targeting rule, so that \[
  \pi_t = -\mu \Delta y_t - \varepsilon^3_t
\] for some value of \(\mu\) that reflects the optimal trade-off between
output (gap) growth and inflation, and we've included a disturbance
which we can loosely describe as a monetary policy shock. We modify the
model above by dropping the Taylor rule\index{Taylor!rule} in favour of
the targeting rule. This requires a lagged value of \(y\) to be created.
The following does the trick

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{nf }\OtherTok{\textless{}{-}} \DecValTok{2}
\NormalTok{ne }\OtherTok{\textless{}{-}} \DecValTok{3}
\NormalTok{ns }\OtherTok{\textless{}{-}} \DecValTok{6}      \CommentTok{\# One extra state}
\NormalTok{np }\OtherTok{\textless{}{-}}\NormalTok{ ns}\SpecialCharTok{{-}}\NormalTok{nf}
\NormalTok{mu }\OtherTok{\textless{}{-}} \FloatTok{0.75}   \CommentTok{\# Representative trade{-}off}

\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"e\^{}1"}\NormalTok{,}\StringTok{"e\^{}2"}\NormalTok{,}\StringTok{"ylag"}\NormalTok{,}\StringTok{"i"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"pi"}\NormalTok{) }\CommentTok{\# New variable order}

\NormalTok{E }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ns)}
\NormalTok{A }\OtherTok{\textless{}{-}}\NormalTok{ E}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ne)}
\NormalTok{B[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{1}

\FunctionTok{diag}\NormalTok{(E[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]) }\OtherTok{\textless{}{-}} \DecValTok{1}
\FunctionTok{diag}\NormalTok{(A[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(rho\_1, rho\_2)}
\NormalTok{A[}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{]           }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{E[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{]           }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{A[}\DecValTok{4}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\NormalTok{mu)}

\NormalTok{E[}\DecValTok{5}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)] }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma)}
\NormalTok{A[}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{]           }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{E[}\DecValTok{6}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, beta)}
\NormalTok{A[}\DecValTok{6}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{kappa, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The new \(E\) and \(A\) system matrices are then \[  
E = \left[\begin{matrix}1 &0 &0 &0 &0 &0 \\0 &1 &0 &0 &0 &0 \\0 &0 &1 &0 &0 &0 \\0 &0 &1 &0 &0 &0 \\1 &0 &0 &-0.5 &1 &0.5 \\0 &1 &0 &0 &0 &0.99 \\\end{matrix}\right] 
\] \[  
A = \left[\begin{matrix}0.9 &0 &0 &0 &0 &0 \\0 &0.8 &0 &0 &0 &0 \\0 &0 &0 &0 &1 &0 \\0 &0 &1 &0 &0 &-1.333 \\0 &0 &0 &0 &1 &0 \\0 &0 &0 &0 &-0.075 &1 \\\end{matrix}\right] 
\] Now we have a singular model. The matrix \(E\) is clearly singular as
rows 3 and 4 are identical. But we have a problem using the code above.
To use it we need the matrices \(H\) and \((A_{22} - W A_{21})\) to be
non-singular. What to do?

There are two ways out. Klein (2000) gives a solution that depends on
the decomposed matrix pencil, which is what is typically implemented,
but you don't actually need it although it is easiest. Instead, all you
need to do is reorder the equations.

The real problem is that with a targeting rule that doesn't include the
interest rate, and the interest rate is now only determined by the IS
curve. But we can swap the location of any two rows of the model
arbitrarily. If we swap the positions of the equations for the IS curve
and the targeting rule (rows 4 and 5) using the following

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{E[}\DecValTok{4}\SpecialCharTok{:}\DecValTok{5}\NormalTok{,] }\OtherTok{\textless{}{-}}\NormalTok{ E[}\DecValTok{5}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,]}
\NormalTok{A[}\DecValTok{4}\SpecialCharTok{:}\DecValTok{5}\NormalTok{,] }\OtherTok{\textless{}{-}}\NormalTok{ A[}\DecValTok{5}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,]}
\NormalTok{B[}\DecValTok{4}\SpecialCharTok{:}\DecValTok{5}\NormalTok{,] }\OtherTok{\textless{}{-}}\NormalTok{ B[}\DecValTok{5}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,]}
\end{Highlighting}
\end{Shaded}

then the model is unchanged but now we have \[  
E_{11} = \left[\begin{matrix}1 &0 &0 &0 \\0 &1 &0 &0 \\0 &0 &1 &0 \\1 &0 &0 &-0.5 \\\end{matrix}\right] 
\] so \(E_{11} + E_{12}N\) is likely non-singular (it is). Also, note
after the re-ordering \(A_{22}\) is \[  
A_{22} = \left[\begin{matrix}0 &-1.33 \\-0.07 &1 \\\end{matrix}\right] 
\] which is guaranteed non-singular for zero \(W\). We can now proceed
as before. First, check for saddle path stability

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ geigen}\SpecialCharTok{::}\FunctionTok{gevalues}\NormalTok{(geigen}\SpecialCharTok{::}\FunctionTok{gqz}\NormalTok{(A, E, }\AttributeTok{sort=}\StringTok{"S"}\NormalTok{))}
\NormalTok{e[}\FunctionTok{abs}\NormalTok{(e) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 1.378195      Inf
\end{verbatim}

which confirms that it has a unique saddle path stable solution. This is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{So }\OtherTok{\textless{}{-}} \FunctionTok{solveGenBK}\NormalTok{(E,A,B,np)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Number of unstable roots is 2"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Po }\OtherTok{\textless{}{-}}\NormalTok{ So}\SpecialCharTok{$}\NormalTok{P}
\NormalTok{Qo }\OtherTok{\textless{}{-}}\NormalTok{ So}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

The solved model is then

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Po}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]      [,2]          [,3] [,4] [,5] [,6]
[1,]  0.9  0.000000  0.000000e+00    0    0    0
[2,]  0.0  0.800000  6.986592e-17    0    0    0
[3,]  0.0 -1.863455  7.329156e-01    0    0    0
[4,]  1.8 -1.241330 -2.446879e-01    0    0    0
[5,]  0.0 -1.863455  7.329156e-01    0    0    0
[6,]  0.0  1.397591  2.003133e-01    0    0    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qo}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]      [,2]          [,3]
[1,]    1  0.000000  0.000000e+00
[2,]    0  1.000000 -6.986592e-17
[3,]    0 -2.329318 -7.329156e-01
[4,]    2 -1.551663  2.446879e-01
[5,]    0 -2.329318 -7.329156e-01
[6,]    0  1.746989 -2.003133e-01
\end{verbatim}

\hypertarget{optimal-impulse-responses}{%
\subsection{Optimal impulse responses}\label{optimal-impulse-responses}}

We can now simulate the model under optimal policy and plot using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{zo }\OtherTok{\textless{}{-}} \FunctionTok{impulse\_responses}\NormalTok{(Po, Qo, Omega, labels, T) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{ylag) }\CommentTok{\# Drop duplicate series}
\FunctionTok{response\_plot}\NormalTok{(zo, }\StringTok{"Impulse responses: Optimal policy"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{BK_files/figure-pdf/unnamed-chunk-24-1.pdf}

}

\end{figure}

\hypertarget{dummy-jumps}{%
\section{Dummy jumps}\label{dummy-jumps}}

But this isn't the only way to get this to work. Effectively what we
just did was create an extra predetermined variable and reorder the
system to give us non-singularity. What if instead of including an
unused \(i_{t-1}\) on the right hand side, we instead include an unused
\(i^e_{t+1}\) on the left hand side? So we swap to having one more jump
variable, one less predetermined one?

Compare the following to the previous model. When we pick out the
interest rate we do so on the right hand side of the matrix equation,
not the left as before.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ns }\OtherTok{\textless{}{-}} \DecValTok{6}      \CommentTok{\# One extra state}
\NormalTok{nf }\OtherTok{\textless{}{-}} \DecValTok{3}      \CommentTok{\# And one extra jump}
\NormalTok{np }\OtherTok{\textless{}{-}}\NormalTok{ ns}\SpecialCharTok{{-}}\NormalTok{nf}
\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"e\^{}1"}\NormalTok{,}\StringTok{"e\^{}2"}\NormalTok{,}\StringTok{"ylag"}\NormalTok{,}\StringTok{"i"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"pi"}\NormalTok{) }\CommentTok{\# New variable order}

\NormalTok{E }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ns)}
\NormalTok{A }\OtherTok{\textless{}{-}}\NormalTok{ E}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ne)}
\NormalTok{B[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{1}

\FunctionTok{diag}\NormalTok{(E[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{3}\NormalTok{]) }\OtherTok{\textless{}{-}} \DecValTok{1}
\FunctionTok{diag}\NormalTok{(A[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(rho\_1, rho\_2)}
\NormalTok{A[}\DecValTok{3}\NormalTok{,}\DecValTok{5}\NormalTok{]           }\OtherTok{\textless{}{-}} \DecValTok{1}

\NormalTok{E[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{]           }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{A[}\DecValTok{4}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{3}\NormalTok{, }\DecValTok{6}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\NormalTok{mu)}

\NormalTok{E[}\DecValTok{5}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)]  }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{, }\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma) }\CommentTok{\# One less coefficient}
\NormalTok{A[}\DecValTok{5}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\SpecialCharTok{/}\NormalTok{sigma, }\DecValTok{1}\NormalTok{)    }\CommentTok{\# One more {-} nothing else changes}

\NormalTok{E[}\DecValTok{6}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{6}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, beta)}
\NormalTok{A[}\DecValTok{6}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{5}\NormalTok{, }\DecValTok{6}\NormalTok{)]     }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{kappa, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

This is still a singular model, as we can see from \[  
E = \left[\begin{matrix}1 &0 &0 &0 &0 &0 \\0 &1 &0 &0 &0 &0 \\0 &0 &1 &0 &0 &0 \\0 &0 &1 &0 &0 &0 \\1 &0 &0 &0 &1 &0.5 \\0 &1 &0 &0 &0 &0.99 \\\end{matrix}\right] 
\] with column 4 all zeros. Is \emph{this} model saddle path stable?

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}}\NormalTok{ geigen}\SpecialCharTok{::}\FunctionTok{gevalues}\NormalTok{(geigen}\SpecialCharTok{::}\FunctionTok{gqz}\NormalTok{(A, E, }\AttributeTok{sort=}\StringTok{"S"}\NormalTok{) )}
\NormalTok{e[}\FunctionTok{abs}\NormalTok{(e) }\SpecialCharTok{\textgreater{}} \DecValTok{1}\NormalTok{]}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1]     -Inf 1.378195      Inf
\end{verbatim}

Again, it is with an extra unstable root for the extra jump variable. We
could simplify the solution. As that top left 3 by 3 block, \(E_{11}\),
is the identity matrix and \(E_{12}\) is all zeros this \texttt{Ei} is
always an identity matrix. However, here we simply re-use
\texttt{solveGenBG}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{So2 }\OtherTok{\textless{}{-}} \FunctionTok{solveGenBK}\NormalTok{(E,A,B,np)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Number of unstable roots is 3"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Po2 }\OtherTok{\textless{}{-}}\NormalTok{ So2}\SpecialCharTok{$}\NormalTok{P}
\NormalTok{Qo2 }\OtherTok{\textless{}{-}}\NormalTok{ So2}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

Now the solved model is

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Po2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]      [,2]       [,3] [,4] [,5] [,6]
[1,]  0.9  0.000000  0.0000000    0    0    0
[2,]  0.0  0.800000  0.0000000    0    0    0
[3,]  0.0 -1.863455  0.7329156    0    0    0
[4,]  1.8 -1.241330 -0.2446879    0    0    0
[5,]  0.0 -1.863455  0.7329156    0    0    0
[6,]  0.0  1.397591  0.2003133    0    0    0
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Qo2}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]      [,2]       [,3]
[1,]    1  0.000000  0.0000000
[2,]    0  1.000000  0.0000000
[3,]    0 -2.329318 -0.7329156
[4,]    2 -1.551663  0.2446879
[5,]    0 -2.329318 -0.7329156
[6,]    0  1.746989 -0.2003133
\end{verbatim}

which is actually identical to our previous solution. This is because I
have preserved the order of the solved-out variables, and shows that the
swap from a predetermined to a jump variable is completely arbitrary.

\hypertarget{substituting-out}{%
\section{Substituting out}\label{substituting-out}}

But even this doesn't exhaust the possible re-parametrisations of the
model. We can reduce the number of jump variables to 1 and find the same
solution. There exist formal methods for reducing models (see King and
Watson (2002)) but there is an obvious way to proceed here. From the
targeting rule, it must be that \[
  y^e_{t+1} = y_t - \frac{1}{\mu}\pi^e_{t+1}
\] as the expected shock is zero. This means the IS curve can be
rewritten \[
y_t = y_t - \frac{1}{\mu}\pi^e_{t+1} - \frac{1}{\sigma} \left (i_t - \pi_{t+1}^e \right ) + e_t^1
\] implying \[
i_t =  \left (1 - \frac{\sigma}{\mu} \right )\pi_{t+1}^e + \sigma e_t^1
\] This is the required interest rate consistent with the targeting rule
holding. Now the only jump variable is the inflation rate as we have
eliminated the expected output gap. \begin{align}
y_t    &= y_{t-1} -\frac{1}{\mu} \pi_t  + \frac{1}{\mu} \varepsilon^3_t \\
\pi_t  &= \beta \pi_{t+1}^e + \kappa y_t + e_t^2 \\
i_t    &= \left (1 - \frac{\sigma}{\mu} \right ) \pi_{t+1}^e + \sigma e_t^1 \\
e_t^1  &= \rho_1 e_{t-1}^1 + \varepsilon_t^1 \\ 
e_t^2  &= \rho_2 e_{t-1}^2 + \varepsilon_t^2 
\end{align}

We can code this

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{ns }\OtherTok{\textless{}{-}} \DecValTok{5}      \CommentTok{\# Back to 5 states}
\NormalTok{nf }\OtherTok{\textless{}{-}} \DecValTok{1}      \CommentTok{\# Now only one jump}
\NormalTok{np }\OtherTok{\textless{}{-}}\NormalTok{ ns}\SpecialCharTok{{-}}\NormalTok{nf}

\NormalTok{labels }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"e\^{}1"}\NormalTok{,}\StringTok{"e\^{}2"}\NormalTok{,}\StringTok{"i"}\NormalTok{,}\StringTok{"y"}\NormalTok{,}\StringTok{"pi"}\NormalTok{) }\CommentTok{\# Lose a y}

\NormalTok{E }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ns)}
\NormalTok{A }\OtherTok{\textless{}{-}}\NormalTok{ E}
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\DecValTok{0}\NormalTok{,ns,ne)}
\NormalTok{B[}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{] }\OtherTok{\textless{}{-}} \DecValTok{1}
\NormalTok{B[}\DecValTok{4}\NormalTok{,}\DecValTok{3}\NormalTok{] }\OtherTok{\textless{}{-}} \SpecialCharTok{{-}}\DecValTok{1}

\FunctionTok{diag}\NormalTok{(E[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{4}\NormalTok{]) }\OtherTok{\textless{}{-}} \DecValTok{1}
\FunctionTok{diag}\NormalTok{(A[}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{,}\DecValTok{1}\SpecialCharTok{:}\DecValTok{2}\NormalTok{]) }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(rho\_1, rho\_2)}

\NormalTok{E[}\DecValTok{3}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\DecValTok{3}\NormalTok{, }\DecValTok{5}\NormalTok{)]  }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{sigma, }\DecValTok{1}\NormalTok{, sigma}\SpecialCharTok{/}\NormalTok{mu}\DecValTok{{-}1}\NormalTok{)}

\NormalTok{A[}\DecValTok{4}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{5}\NormalTok{)]      }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, }\SpecialCharTok{{-}}\DecValTok{1}\SpecialCharTok{/}\NormalTok{mu)}

\NormalTok{E[}\DecValTok{5}\NormalTok{,}\FunctionTok{c}\NormalTok{(}\DecValTok{2}\NormalTok{, }\DecValTok{4}\NormalTok{, }\DecValTok{5}\NormalTok{)]  }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, kappa, beta)}
\NormalTok{A[}\DecValTok{5}\NormalTok{,}\DecValTok{5}\NormalTok{]           }\OtherTok{\textless{}{-}} \DecValTok{1}
\end{Highlighting}
\end{Shaded}

and solve it using

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ss }\OtherTok{\textless{}{-}} \FunctionTok{solveGenBK}\NormalTok{(E,A,B,np)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] "Number of unstable roots is 1"
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ps }\OtherTok{\textless{}{-}}\NormalTok{ Ss}\SpecialCharTok{$}\NormalTok{P}
\NormalTok{Qs }\OtherTok{\textless{}{-}}\NormalTok{ Ss}\SpecialCharTok{$}\NormalTok{Q}
\end{Highlighting}
\end{Shaded}

Compare the realized of \texttt{Ps}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Ps}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]      [,2] [,3]       [,4] [,5]
[1,]  0.9  0.000000    0  0.0000000    0
[2,]  0.0  0.800000    0  0.0000000    0
[3,]  1.8 -1.241330    0 -0.2446879    0
[4,]  0.0 -1.863455    0  0.7329156    0
[5,]  0.0  1.397591    0  0.2003133    0
\end{verbatim}

with \texttt{Po} above, say. This is the most `efficient' way of
programming the model, in that we have only five states, and indeed the
repeated behavioural equations we had before have disappeared in the
reduced form solution. Just to confirm this, simulating and plotting
this version gives

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{response\_plot}\NormalTok{(}\FunctionTok{impulse\_responses}\NormalTok{(Ps,Qs,Omega,labels,T), }\StringTok{"Optimal, substituted out"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{BK_files/figure-pdf/unnamed-chunk-32-1.pdf}

}

\end{figure}

which are identical results to those above. But of course \(E\) is now
invertible so we could solve this using the simplest
Blanchard-Kahn\index{Blanchard-Kahn!method} variant. Try it!

\hypertarget{bvar-with-dummies}{%
\chapter{BVAR with dummies}\label{bvar-with-dummies}}

\hypertarget{estimating-bvars-using-us-data}{%
\section{Estimating BVARs using US
data}\label{estimating-bvars-using-us-data}}

We will the Fed Funds rate, annual GDP growth and annual CPI inflation
data from FRED\index{FRED}, retrieved 2023-07-01. These are:

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-2-1.pdf}

}

\end{figure}

We will build a variety and two and three variable BVARs. More details
on the data are given below.

\hypertarget{bvars-with-dummy-variable-priors}{%
\section{BVARs with dummy variable
priors}\label{bvars-with-dummy-variable-priors}}

Rather than combine a prior distribution with a likelihood and draw from
the resulting joint posterior distribution there is another convenient
way of parameterizing the problem. We can instead add some `dummy
variables' that have the same properties of the prior so we have a
single modified likelihood that incorporates the prior information. This
approach was most obviously adopted by Banbura, Giannone, and Reichlin
(2010). Further discussion of this can be found in Giannone, Lenza, and
Primiceri (2015). In general this is a version of the Theil and
Goldberger (1961) \textbf{\emph{mixed estimator}} given a Bayesian
interpretation.

\hypertarget{var-model}{%
\subsection{VAR model}\label{var-model}}

Simple bi-variate two-lag VAR model:

\begin{align}
  \left[\begin{matrix}g_t \cr \pi_t\end{matrix}\right] &=
  \left[\begin{matrix}c_1 \cr c_2\end{matrix}\right] +
  \left[\begin{matrix}b_{11} & b_{12} \cr
    b_{21} & b_{22}\end{matrix}\right]
\left[\begin{matrix}g_{t-1} \cr \pi_{t-1} \end{matrix}\right] +
   \left[\begin{matrix}d_{11} & d_{12} \cr
    d_{21} & d_{22}\end{matrix}\right]
\left[\begin{matrix}g_{t-2} \cr \pi_{t-2} \end{matrix}\right] +
  \left[\begin{matrix}\nu_{g,t} \cr \nu_{\pi,t}\end{matrix}\right] \\
  \left[\begin{matrix}\nu_{g,t} \cr \nu_{\pi,t}\end{matrix}\right] &\sim N(0, \Sigma)
\end{align}

\hypertarget{bvar-hyperparameters}{%
\section{BVAR hyperparameters}\label{bvar-hyperparameters}}

We will (similarly to the straightforward Minnesota prior) need some
control parameters:

\begin{itemize}
\tightlist
\item
  \(\tau\) controls the overall tightness of the prior for the AR
  coefficients
\item
  \(d\) controls the prior on higher lags;
\item
  \(\lambda\) controls the prior on constants;
\item
  \(\gamma\) controls the prior on the sum of coefficients;
\item
  \(\delta\) controls the cointegration prior;
\end{itemize}

where

\begin{itemize}
\tightlist
\item
  \(\sigma_i\) standard deviation of error terms from individual OLS
  regressions;
\item
  \(\mu_i\) sample means of the data.
\end{itemize}

\hypertarget{first-lag}{%
\subsubsection{First lag}\label{first-lag}}

Now consider the following artificial data for the \textbf{first lag}.
We construct some dummy observations of the dependent and explanatory
variables that look like: \begin{equation}
  Y_{D,1} = \left[\begin{matrix}\frac{1}{\tau}\sigma_1 & 0 \cr
    0 & \frac{1}{\tau}\sigma_2\end{matrix}\right]
\end{equation}

and

\begin{equation}
  X_{D,1} = \left [ \begin{matrix}0 & \frac{1}{\tau}\sigma_1 & 0 & 0 & 0\cr
    0 & 0 & \frac{1}{\tau}\sigma_2 & 0 & 0\end{matrix}\right]
\end{equation}

Intuition:

\begin{equation}
  \left[\begin{matrix} \frac{\sigma_1}{\tau} & 0 \cr
    0 & \frac{\sigma_2}{\tau}\end{matrix}\right] =
  \left[\begin{matrix} 0 & \frac{\sigma_1}{\tau} & 0 & 0 & 0\cr
   0 & 0 & \frac{\sigma_2}{\tau} & 0 & 0\end{matrix} \right]
\left[\begin{matrix}c_1 & c_2 \cr
  b_{11} & b_{21} \cr
  b_{12} & b_{22} \cr
  d_{11} & d_{21} \cr
  d_{12} & d_{22}\end{matrix}\right]
+
  \left[\begin{matrix}\xi_{11} & \xi_{12} \cr \xi_{21} & \xi_{22} \end{matrix}\right]
\end{equation}

Multiplying out we get:

\begin{equation}
  \left[\begin{matrix}\frac{\sigma_1}{\tau} & 0 \cr
    0 & \frac{\sigma_2}{\tau}\end{matrix}\right]
=
  \left[\begin{matrix}\frac{\sigma_1}{\tau}b_{11} & \frac{\sigma_1}{\tau}b_{21}\cr
  \frac{\sigma_2}{\tau}b_{12} &  \frac{\sigma_2}{\tau}b_{22}\end{matrix} \right]
+
  \left[\begin{matrix}\xi_{11} & \xi_{12} \cr \xi_{21} & \xi_{22} \end{matrix}\right]
\end{equation}

Concentrating on the first row, notice:

\begin{equation}
  \frac{\sigma_1}{\tau} = \frac{\sigma_1}{\tau}b_{11} + \xi_{11}
\end{equation}

implying:

\begin{equation}
  b_{11} = 1 - \frac{\tau}{\sigma_1}\xi_{11}
\end{equation}

so we can write:

\begin{equation}
  b_{11} \sim N\left(1, \frac{\tau^2var(\xi_{11})}{\sigma^2_1}\right)
\end{equation}

as \(E[b_{11}] = 1 - \frac{\tau}{\sigma_1}E[\xi_{11}] = 1\) and the
variance is easily derived. Similarly: \begin{equation}
  b_{12} = - \frac{\tau}{\sigma_1}\xi_{12}
\end{equation} which is clearly zero in expectation.

\hypertarget{further-priors}{%
\subsection{Further priors}\label{further-priors}}

\hypertarget{higher-lags}{%
\subsubsection{Higher lags}\label{higher-lags}}

Rather than derive the implications we state the rest of the dummy
priors. Consider the following artificial data for the \textbf{second}
lag:

\begin{align*}
  Y_{D,2} &= \left[\begin{matrix}0 & 0 \cr 0 & 0\end{matrix}\right] \\
  X_{D,2} &= \left[\begin{matrix}0 & 0 & 0 & \frac{\sigma_1 2^d}{\tau} & 0 \cr
    0 & 0 & 0 & 0 & \frac{\sigma_2 2^d}{\tau} \end{matrix}\right]
\end{align*}

We can multiply these out and check the properties, in particular we can
verify in the same way as for the first lag that:

\begin{equation}
  b_{ji} \sim N\left(0, \frac{1}{4}\frac{\tau^2var(\xi_{ji})} {2^d\sigma^2_j}\right)
\end{equation}

for \(j=1,...N\), \(i=1,...l\).

\hypertarget{constant}{%
\subsubsection{Constant}\label{constant}}

Consider the following artificial data for the \textbf{constant}:

\begin{align*}
  Y_{D,3} &= \left[\begin{matrix}0 & 0 \end{matrix}\right] \\
  X_{D,3} &= \left[\begin{matrix}\lambda & 0 & 0 & 0 & 0 \end{matrix}\right]
\end{align*}

so \(\lambda c_1 = \varepsilon_1\) and \(\lambda c_2 = \varepsilon_2\).
As \(\lambda \rightarrow \infty\) the prior is implemented more tightly.

\hypertarget{covariances}{%
\subsubsection{Covariances}\label{covariances}}

Dummy observations to implement the prior on the error covariance matrix
are: \begin{align*}
  Y_{D,4} &= \left[\begin{matrix}\sigma_1 & 0 \cr 0 & \sigma_2\end{matrix}\right] \\
  X_{D,4} &= \left[\begin{matrix}0 & 0 & 0 & 0 & 0 \cr
    0 & 0 & 0 & 0 & 0 \end{matrix}\right]
\end{align*}

with the magnitude of the diagonal elements of \(\Sigma\) controlled by
the scale of the diagonal elements of \(Y_{D,4}\), as larger diagonal
elements implement the prior belief that the variance of \(\nu_1\) and
\(\nu_2\) is larger.

Banbura, Giannone, and Reichlin (2010) stop here, but there are
additional priors that could be added.

\hypertarget{sum-of-coefficients}{%
\subsubsection{Sum of coefficients}\label{sum-of-coefficients}}

We could add a prior that reflects the belief that the \textbf{sum of
coefficients} on `own' lags add up to 1. This is an additional `unit
root'-style prior. Consider:

\begin{align*}
  Y_{D,5} &= \left[\begin{matrix} \gamma\mu_1 & 0\cr 0 & \gamma\mu_2\end{matrix}\right] \\
  X_{D,5} &= \left [ \begin{matrix} 0 & \gamma\mu_1 & 0 & \gamma\mu_1 & 0\cr
    0 & 0 & \gamma\mu_2 & 0 & \gamma\mu_2\end{matrix}\right]
\end{align*}

where \(\mu_1\) is the sample mean of \(y_t\) and \(\mu_2\) is the
sample mean of \(x_t\). Note that these dummy observations imply prior
means of the form \(b_{ii} + d_{ii} = 1\) where \(i = 1, 2\) and
\(\gamma\) controls the tightness of the prior. As
\(\gamma \rightarrow \infty\) the prior is implemented more tightly.
Forecast growth rates eventually converge to their sample averages.

\hypertarget{trends}{%
\subsubsection{Trends}\label{trends}}

We can also specify \textbf{common stochastic trend} dummies:

\begin{align*}
  Y_{D,6} &= \left[\begin{matrix}\delta\mu_1 & \delta\mu_2 \end{matrix}\right] \\
  X_{D,6} &= \left [\begin{matrix}\delta & \delta\mu_1 & \delta\mu_2 & \delta\mu_1 & \delta\mu_2 \end{matrix}\right]
\end{align*}

where this imposes that the coefficients are consistent with limiting
the amount of drift between the predictions at their average values.

\hypertarget{implementation}{%
\subsection{Implementation}\label{implementation}}

The data and the artificial data are now stacked:

\begin{equation}
  Y^* = \left[\begin{matrix} g_3 & \pi_3 \cr
    \vdots & \vdots \cr
    g_T & \pi_T \cr
    \frac{1}{\tau}\sigma_1 & 0 \cr
    0 & \frac{1}{\tau}\sigma_2\cr
    0 & 0 \cr
    0 & 0 \cr
    0 & 0 \cr
    \sigma_1 & 0 \cr
    0 & \sigma_2 \cr
    \gamma\mu_1 & 0 \cr
    0 & \gamma\mu_2 \cr
    \delta\mu_1 & \delta\mu_2 \end{matrix}\right], \quad
X^* = \left [ \begin{matrix}1 & g_2 & \pi_2 & g_1 & \pi_1 \cr
  \vdots & \vdots & \vdots & \vdots & \vdots \cr
  1 & g_{T-1} & \pi_{T-1} & g_{T-2} & \pi_{T-2} \cr
  0 & \frac{1}{\tau}\sigma_1 & 0 & 0 & 0\cr
  0 & 0 & \frac{1}{\tau}\sigma_2 & 0 & 0\cr
  0 & 0 & 0 & \frac{\sigma_1 2^d}{\tau} & 0 \cr
  0 & 0 & 0 & 0 & \frac{\sigma_2 2^d}{\tau} \cr
  \lambda & 0 & 0 & 0 & 0 \cr
  0 & 0 & 0 & 0 & 0 \cr
  0 & 0 & 0 & 0 & 0 \cr
  0 & \gamma\mu_1 & 0 & \gamma\mu_1 & 0 \cr
  0 & 0 & \gamma\mu_2 & 0 & \gamma\mu_2 \cr
  \delta & \delta\mu_1 & \delta\mu_2 & \delta\mu_1 & \delta\mu_2 \end{matrix}\right]
\end{equation}

Estimation via Gibbs sampling now proceeds in a very straightforward
way. There is no need to draw for the prior separately.

\hypertarget{examples}{%
\section{Examples}\label{examples}}

First we use quarterly US Growth (FRED series
\href{https://fred.stlouisfed.org/series/A191RO1Q156NBEA}{A191RO1Q156NBEA})
and CPI (FRED series
\href{https://fred.stlouisfed.org/series/CPALTT01USQ661S}{CPALTT01USQ661S})
expressed as the annual inflation rate from 1961-01-01 to 2023-01-01 in
a bi-variate BVAR. The last ten observations are:

\begin{longtable}[]{@{}lrr@{}}
\toprule\noalign{}
Date & Growth & Inflation \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2020-10-01 & -1.5 & 1.224176 \\
2021-01-01 & 1.2 & 1.905310 \\
2021-04-01 & 12.5 & 4.776278 \\
2021-07-01 & 5.0 & 5.264633 \\
2021-10-01 & 5.7 & 6.765892 \\
2022-01-01 & 3.7 & 8.023109 \\
2022-04-01 & 1.8 & 8.556077 \\
2022-07-01 & 1.9 & 8.284860 \\
2022-10-01 & 0.9 & 7.110821 \\
2023-01-01 & 1.8 & 5.769521 \\
\end{longtable}

We specify a VAR with two lags, and use it to forecast 12 periods ahead.
The BVAR are specified using the names above, with only \texttt{tau}
particularly binding in this case. We set the total number of iterations
in each case to 20000 and discard the first half. The parameter
\texttt{nb} is used to set how much back data should appear in a fan
chart.

\begin{Shaded}
\begin{Highlighting}[]
\DocumentationTok{\#\#\#\#\#\#\#\#\#}
\CommentTok{\# Options}
\DocumentationTok{\#\#\#\#\#\#\#\#\#}
\NormalTok{nf }\OtherTok{\textless{}{-}} \DecValTok{12} \CommentTok{\# Max forecast horizon}
\NormalTok{nb }\OtherTok{\textless{}{-}} \DecValTok{21} \CommentTok{\# No. back periods plotted in graphs}
\NormalTok{l  }\OtherTok{\textless{}{-}} \DecValTok{2}  \CommentTok{\# Number of lags in VAR}

\CommentTok{\# specify parameters of the Minnesota{-}type prior}
\NormalTok{tau    }\OtherTok{\textless{}{-}}\NormalTok{ .}\DecValTok{1}   \CommentTok{\# controls prior on own 1st lags (1 makes wibbly)}
\NormalTok{d      }\OtherTok{\textless{}{-}} \DecValTok{1}    \CommentTok{\# decay for higher lags}
\NormalTok{lambda }\OtherTok{\textless{}{-}} \DecValTok{1}    \CommentTok{\# prior for the constant}
\NormalTok{gamma  }\OtherTok{\textless{}{-}} \DecValTok{1}    \CommentTok{\# sum of coefficients unit roots}
\NormalTok{delta  }\OtherTok{\textless{}{-}} \DecValTok{1}    \CommentTok{\# cointegration prior}

\CommentTok{\# Gibbs control}
\NormalTok{reps }\OtherTok{\textless{}{-}} \DecValTok{20000} \CommentTok{\# total numbers of Gibbs iterations}
\NormalTok{burn }\OtherTok{\textless{}{-}} \DecValTok{10000} \CommentTok{\# number of burn{-}in iterations}
\end{Highlighting}
\end{Shaded}

In what follows we vary \texttt{tau} and the lag length to illustrate
their effects. To do this we create the augmented data and then run the
Gibbs sampler, using:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Create augmented data}
\NormalTok{Yplus }\OtherTok{\textless{}{-}} \FunctionTok{augmentData}\NormalTok{(Y, l, tau, d, lambda, gamma, delta)}

\CommentTok{\# Run Gibbs sampler}
\NormalTok{out   }\OtherTok{\textless{}{-}} \FunctionTok{Gibbs\_estimate}\NormalTok{(Yplus[[}\DecValTok{1}\NormalTok{]], Yplus[[}\DecValTok{2}\NormalTok{]], reps, burn, }\DecValTok{1}\NormalTok{, nf)}
\end{Highlighting}
\end{Shaded}

where \texttt{Y} contains the data in a dataframe/tibble with the date
in the first column as in the data example above. The code strips out
the date and then uses the remaining \(N\) columns in the BVAR. See the
Code Appendix for the details of the functions.

The output contains any \textbf{\emph{forecast}} draws from the Gibbs
sampler in the third list element from the \texttt{Gibbs\_estimate()}
function. The first two elements are coefficient draws. Two further
functions plots the fan charts using the Gibbs draws:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# String to put in subtitle}
\NormalTok{controls }\OtherTok{\textless{}{-}} \FunctionTok{paste0}\NormalTok{(}\StringTok{"Lag length "}\NormalTok{, l, }\StringTok{": tau="}\NormalTok{, tau, }\StringTok{", d="}\NormalTok{, d,}
                   \StringTok{", lambda="}\NormalTok{, lambda, }\StringTok{", gamma="}\NormalTok{, gamma, }\StringTok{", delta="}\NormalTok{, delta)}

\CommentTok{\# Plots}
\FunctionTok{fan\_chart}\NormalTok{(Y, out[[}\DecValTok{3}\NormalTok{]], controls, nb)}
\NormalTok{p           }\OtherTok{\textless{}{-}} \FunctionTok{coeff\_plot}\NormalTok{(Y, l, out[[}\DecValTok{1}\NormalTok{]], out[[}\DecValTok{2}\NormalTok{]], }\DecValTok{333}\NormalTok{, controls)}
\NormalTok{pnum        }\OtherTok{\textless{}{-}}\NormalTok{ pnum}\SpecialCharTok{+}\DecValTok{1}
\NormalTok{pce[[pnum]] }\OtherTok{\textless{}{-}}\NormalTok{ p[[}\DecValTok{1}\NormalTok{]]}
\end{Highlighting}
\end{Shaded}

where the string \texttt{controls} is put in the chart subtitle and the
coefficient densities. It can be anything but is a good place to remind
yourself of how you specified the model. Notice we save the coefficient
plots for later use.

\hypertarget{example-1-bvar2-with-tau0.1}{%
\subsection{\texorpdfstring{Example 1: BVAR(2) with
\(\tau=0.1\)}{Example 1: BVAR(2) with \textbackslash tau=0.1}}\label{example-1-bvar2-with-tau0.1}}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/estim-1.pdf}

}

\end{figure}

\hypertarget{example-2-bvar2-with-tau1}{%
\subsection{\texorpdfstring{Example 2: BVAR(2) with
\(\tau=1\)}{Example 2: BVAR(2) with \textbackslash tau=1}}\label{example-2-bvar2-with-tau1}}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/estim-1.pdf}

}

\end{figure}

\hypertarget{example-3-bvar6-with-tau0.1}{%
\subsection{\texorpdfstring{Example 3: BVAR(6) with
\(\tau=0.1\)}{Example 3: BVAR(6) with \textbackslash tau=0.1}}\label{example-3-bvar6-with-tau0.1}}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/estim-1.pdf}

}

\end{figure}

\hypertarget{example-4-bvar6-with-tau1}{%
\subsection{\texorpdfstring{Example 4: BVAR(6) with
\(\tau=1\)}{Example 4: BVAR(6) with \textbackslash tau=1}}\label{example-4-bvar6-with-tau1}}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/estim-1.pdf}

}

\end{figure}

\hypertarget{coefficient-estimates}{%
\subsection{Coefficient estimates}\label{coefficient-estimates}}

All of these have underlying parameters. Their estimated posterior
densities are:

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-9-2.pdf}

}

\end{figure}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-9-3.pdf}

}

\end{figure}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-9-4.pdf}

}

\end{figure}

\hypertarget{tri-variate-bvar}{%
\section{Tri-variate BVAR}\label{tri-variate-bvar}}

Now we add the FedFunds rate (FRED series
\href{https://fred.stlouisfed.org/series/FEDFUNDS}{FEDFUNDS}), so the
last ten periods of the data set is now:

\begin{longtable}[]{@{}lrrr@{}}
\toprule\noalign{}
Date & Growth & Inflation & FedFunds \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
2020-10-01 & -1.5 & 1.224176 & 0.09 \\
2021-01-01 & 1.2 & 1.905310 & 0.09 \\
2021-04-01 & 12.5 & 4.776278 & 0.07 \\
2021-07-01 & 5.0 & 5.264633 & 0.10 \\
2021-10-01 & 5.7 & 6.765892 & 0.08 \\
2022-01-01 & 3.7 & 8.023109 & 0.08 \\
2022-04-01 & 1.8 & 8.556077 & 0.33 \\
2022-07-01 & 1.9 & 8.284860 & 1.68 \\
2022-10-01 & 0.9 & 7.110821 & 3.08 \\
2023-01-01 & 1.8 & 5.769521 & 4.33 \\
\end{longtable}

Two more examples follow.

\hypertarget{example-5-bvar4-with-tau.1-3-variables}{%
\subsection{\texorpdfstring{Example 5: BVAR(4) with \(\tau=.1\), 3
variables}{Example 5: BVAR(4) with \textbackslash tau=.1, 3 variables}}\label{example-5-bvar4-with-tau.1-3-variables}}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/estim-1.pdf}

}

\end{figure}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\end{figure}

\hypertarget{example-6-bvar6-with-tau1-3-variables}{%
\subsection{\texorpdfstring{Example 6: BVAR(6) with \(\tau=1\), 3
variables}{Example 6: BVAR(6) with \textbackslash tau=1, 3 variables}}\label{example-6-bvar6-with-tau1-3-variables}}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/estim-1.pdf}

}

\end{figure}

\begin{figure}

{\centering \includegraphics{BVAR_files/figure-pdf/unnamed-chunk-14-1.pdf}

}

\end{figure}

\hypertarget{code-appendix}{%
\section{Code appendix}\label{code-appendix}}

You can download the program and functions used for the estimates above
from the links below. Put them in the same directory and they should
recreate exactly (within sampling error) the same graphs as above.
Ensure you have all the libraries available that are loaded at the top
of \texttt{BVARdum.R}.

Main program:

Functions:

\part{End matter}

\hypertarget{summary}{%
\chapter{Summary}\label{summary}}

In summary, this book has no content whatsoever\ldots{}

\hypertarget{references}{%
\chapter*{References}\label{references}}
\addcontentsline{toc}{chapter}{References}

\markboth{References}{References}

\hypertarget{refs}{}
\begin{CSLReferences}{1}{0}
\leavevmode\vadjust pre{\hypertarget{ref-BFP}{}}%
Bahaj, Saleem, Angus Foulis, and Gabor Pinter. 2020. {``Home Values and
Firm Behavior.''} \emph{American Economic Review} 110 (7): 2225--70.
\url{https://doi.org/10.1257/aer.20180649}.

\leavevmode\vadjust pre{\hypertarget{ref-Banbura}{}}%
Banbura, M., D. Giannone, and L. Reichlin. 2010. {``Large {B}ayesian
Vector Auto Regressions.''} \emph{Journal of Applied Econometrics} 25
(1): 71--92.

\leavevmode\vadjust pre{\hypertarget{ref-BlakeCE}{}}%
Blake, Andrew P. 2004. {``Analytic Derivatives in Linear Rational
Expectations Models.''} \emph{Computational Economics} 24 (1): 77--96.

\leavevmode\vadjust pre{\hypertarget{ref-Mumtaz_BOOK}{}}%
Blake, Andrew P, and Haroon Mumtaz. 2017. \emph{Applied Bayesian
Econometrics for Central Bankers}. Revised. Technical Books. Centre for
Central Banking Studies, Bank of England.
\url{https://www.bankofengland.co.uk/-/media/boe/files/ccbs/resources/applied-bayesian-econometrics-for-central-bankers-updated-2017.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-BK80}{}}%
Blanchard, O., and C. Kahn. 1980. {``The Solution of Linear Difference
Models Under Rational Expectations.''} \emph{Econometrica} 48 (5):
1305--11.

\leavevmode\vadjust pre{\hypertarget{ref-HOMLR}{}}%
Boehmke, Brad, and Brandon M. Greenwell. 2019. \emph{Hands-on Machine
Learning with {R}}. The {R} Series. Boca Raton: Chapman \& Hall/CRC.
\url{https://bradleyboehmke.github.io/HOML/}.

\leavevmode\vadjust pre{\hypertarget{ref-CARTER01091994}{}}%
Carter, C. K., and R. Kohn. 1994. {``{On {G}ibbs sampling for state
space models}.''} \emph{Biometrika} 81 (3): 541--53.
\url{https://doi.org/10.1093/biomet/81.3.541}.

\leavevmode\vadjust pre{\hypertarget{ref-Mixtape}{}}%
Cunningham, Scott. 2021. \emph{Causal Inference: The Mixtape}. New Haven
\& London: Yale University Press. \url{https://mixtape.scunning.com/}.

\leavevmode\vadjust pre{\hypertarget{ref-Durbin}{}}%
Durbin, J., and S. J. Koopman. 2001. \emph{Time Series Analysis by State
Space Methods}. Oxford: Oxford University Press.

\leavevmode\vadjust pre{\hypertarget{ref-GHV}{}}%
Gelman, Andrew, Jennifer Hill, and Aki Vehtari. 2019. \emph{Regression
and Other Stories}. Cambridge: Cambridge University Press.
\url{http://www.stat.columbia.edu/~gelman/regression}.

\leavevmode\vadjust pre{\hypertarget{ref-PriorsVAR}{}}%
Giannone, Domenico, Michele Lenza, and Giorgio E. Primiceri. 2015.
{``{Prior Selection for Vector Autoregressions}.''} \emph{The Review of
Economics and Statistics} 97 (2): 436--51.

\leavevmode\vadjust pre{\hypertarget{ref-Green1997}{}}%
Greene, William H. 1997. \emph{Econometric Analysis}. Third. McGraw
Hill.

\leavevmode\vadjust pre{\hypertarget{ref-Hamilton1994}{}}%
Hamilton, J. D. 1994. \emph{Time Series Analysis}. Princeton, NJ:
Princeton University Press.

\leavevmode\vadjust pre{\hypertarget{ref-Hammond2006}{}}%
Hammond, Gill. 2006. {``The Centre for Central Banking Studies.''}
\emph{Quarterly Bulletin} Q2: 191--95.
\url{https://www.bankofengland.co.uk/-/media/boe/files/quarterly-bulletin/2006/the-centre-for-central-banking-studies.pdf}.

\leavevmode\vadjust pre{\hypertarget{ref-Harvey89}{}}%
Harvey, Andrew C. 1989. \emph{Forecasting, Structural Time Series Models
and the Kalman Filter}. Cambridge: Cambridge University Press.

\leavevmode\vadjust pre{\hypertarget{ref-HarveyPierse}{}}%
Harvey, Andrew C., and Richard G. Pierse. 1984. {``Estimating Missing
Observations in Economic Time Series.''} \emph{Journal of the American
Statistical Association} 79 (385): 125--31.

\leavevmode\vadjust pre{\hypertarget{ref-ESL}{}}%
Hastie, Trevor, Robert Tibshirani, and Jerome Friedman. 2009. \emph{The
Elements of Statistical Learning: Data Mining, Inference, and
Prediction}. 2nd ed. New York, NY: Springer.
\url{https://web.stanford.edu/~hastie/ElemStatLearn/}.

\leavevmode\vadjust pre{\hypertarget{ref-SuperText}{}}%
Hvitfeldt, Emil, and Julia Silge. 2021. \emph{Supervised Machine
Learning for Text Analysis in {R}}. Chapman \& Hall: CRC Press.
\url{https://smltar.com/}.

\leavevmode\vadjust pre{\hypertarget{ref-ITSL}{}}%
James, Gareth, Daniela Witten, Trevor Hastie, and Robert Tibshirani.
2021. \emph{An Introduction to Statistical Learning: With Applications
in {R}}. 2nd ed. Springer Texts in Statistics. New York, NY: Springer.
\url{https://www.statlearning.com/}.

\leavevmode\vadjust pre{\hypertarget{ref-Jazwinski}{}}%
Jazwinski, Andrew H. 1970. \emph{Stochastic Processes and Filtering
Theory}. Mineola, N.Y.: Dover Publications Inc.

\leavevmode\vadjust pre{\hypertarget{ref-Kalman}{}}%
Kalman, R. E. 1960. {``A New Approach to Linear Filtering and Prediction
Problems.''} \emph{Transactions of the ASME Journal of Basic
Engineering} 82 (Series D): 35--45.

\leavevmode\vadjust pre{\hypertarget{ref-KimNelson}{}}%
Kim, Chang-Jin, and Charles R. Nelson. 1999. \emph{State-Space Models
with Regime Switching: Classical and Gibbs-Sampling Approaches with
Applications}. MIT Press.

\leavevmode\vadjust pre{\hypertarget{ref-KW2002}{}}%
King, Robert G., and Mark W. Watson. 2002. {``System Reduction and
Solution Algorithms for Singular Linear Difference Systems Under
Rational Expectations.''} \emph{Computational Economics} 20 (1--2):
57--86.

\leavevmode\vadjust pre{\hypertarget{ref-Klein}{}}%
Klein, Paul. 2000. {``Using the Generalized {S}chur Form to Solve a
Multivariate Linear Rational Expectations Model.''} \emph{Journal of
Economic Dynamics and Control} 24 (10): 1405--23.

\leavevmode\vadjust pre{\hypertarget{ref-Geocomputation}{}}%
Lovelace, Robin, Jakub Nowosad, and Jannes Muenchow. 2019.
\emph{Geocomputation with {R}}. 1st ed. The {R} Series. Boca Raton:
Chapman \& Hall/CRC. \url{https://geocompr.robinlovelace.net/}.

\leavevmode\vadjust pre{\hypertarget{ref-McElreath}{}}%
McElreath, Richard. 2020. \emph{Statistical Rethinking: A Bayesian
Course with Examples in {R} and Stan}. 2nd ed. Abingdon, Oxfordshire:
CRC Press. \url{https://github.com/rmcelreath/rethinking}.

\leavevmode\vadjust pre{\hypertarget{ref-Pappas}{}}%
Pappas, T., A. J. Laub, and N. R. Sandell. 1980. {``On the Numerical
Solution of the Discrete-Time Algebraic Riccati Equation.''} \emph{IEEE
Transaction on Automatic Control} AC-25.4: 631--41.

\leavevmode\vadjust pre{\hypertarget{ref-Primer}{}}%
Pearl, Judea, Madelyn Glymour, and Nicholas P. Jewell. 2016.
\emph{Causal Inference in Statistics: A Primer}. Chichester: John Wiley
\& Sons. \url{http://bayes.cs.ucla.edu/PRIMER/}.

\leavevmode\vadjust pre{\hypertarget{ref-Silge}{}}%
Silge, Julia, and David Robinson. 2017. \emph{Text Mining with {R}: A
{T}idy Approach}. O'Reilly. \url{https://www.tidytextmining.com/}.

\leavevmode\vadjust pre{\hypertarget{ref-Taddy}{}}%
Taddy, Matt. 2019. \emph{Business Data Science: Combining Machine
Learning and Economics to Optimize, Automate, and Accelerate Business
Decisions}. New York, NY: McGraw-Hill Education.
\url{https://github.com/TaddyLab/BDS}.

\leavevmode\vadjust pre{\hypertarget{ref-Theil}{}}%
Theil, Henri, and Arthur S. Goldberger. 1961. {``On Pure and Mixed
Statistical Estimation in Economics.''} \emph{International Economic
Review} 2: 317--32.

\leavevmode\vadjust pre{\hypertarget{ref-BISSM}{}}%
Triantafyllopoulos, Kostas. 2021. \emph{Bayesian Inference of State
Space Models: Kalman Filtering and Beyond}. Springer Texts in
Statistics. Cham, Switzerland: Springer.

\leavevmode\vadjust pre{\hypertarget{ref-Vaughan}{}}%
Vaughan, D. R. 1970. {``A Non Recursive Algorithm Solution for the
Discrete Riccati Equation.''} \emph{IEEE Transactions on Automatic
Control} AC-15.5: 597--99.

\leavevmode\vadjust pre{\hypertarget{ref-Leland}{}}%
Wilkinson, Leland. 2013. \emph{The Grammar of Graphics}. 2nd ed. New
York, NY: Springer-Verlag.

\leavevmode\vadjust pre{\hypertarget{ref-Approval}{}}%
Yong, Laurel Harbridge, Jon A. Krosnick, and Jeffrey M. Wooldridge.
2016. {``Presidential Approval and Gas Prices: Sociotropic or Pocketbook
Influence?''} In \emph{Political Psychology}, edited by Jon A. Krosnick,
I-Chant A. Chiang, and Tobias H. Stark, 246--75. Taylor; Francis Inc.

\end{CSLReferences}

\cleardoublepage
\phantomsection
\addcontentsline{toc}{part}{Appendices}
\appendix

\hypertarget{basic-ggplot2}{%
\chapter{\texorpdfstring{Basic
\texttt{ggplot2}}{Basic ggplot2}}\label{basic-ggplot2}}

\hypertarget{plotting-in-the-tidyverse}{%
\section{\texorpdfstring{Plotting in the
\texttt{tidyverse}}{Plotting in the tidyverse}}\label{plotting-in-the-tidyverse}}

\texttt{ggplot2} forms a key part of the
\href{https://www.tidyverse.org/}{\texttt{tidyverse}}\index{tidyverse}
-- for many \href{https://en.wikipedia.org/wiki/ggplot2}{the only part}.
It builds on the \emph{\textbf{g}rammar of \textbf{g}raphics} proposed
by the late Leland Wilkinson, Wilkinson (2013). In essence it provides
rules for how graphics should be treated, simple rules that drive you
mad until you get it.

The process for building a graph is something like the following.

\begin{itemize}
\tightlist
\item
  Initiate a plot using \texttt{ggplot}.
\item
  Specify \textbf{aesthetics} which indicate \emph{what} you want to
  plot from some data set.
\item
  Call a \texttt{geom} (or an alternative) to say \emph{how} you want to
  plot it.
\item
  Add \textbf{modifiers} to change how it \emph{looks}.
\end{itemize}

The order of operations is essentially always this, although quite how
the ordering is apllied differs subtly, which we will show here.

\hypertarget{example}{%
\section{Example}\label{example}}

To illustrate, we take the \texttt{wooldridge} data set
\texttt{approval} from Yong, Krosnick, and Wooldridge (2016), do a
little wrangling and (eventually) produce some quite nice plots. Start
with the libraries and retrieve data the data.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}
\FunctionTok{library}\NormalTok{(wooldridge)}
\FunctionTok{data}\NormalTok{(}\StringTok{"approval"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The first few columns and rows of this looks like:

\begin{verbatim}
   id month year   sp500   cpi cpifood approve
1 302     2 2001 1239.94 184.4   171.8   59.24
2 303     3 2001 1160.33 185.3   172.2   57.01
3 304     4 2001 1249.46 185.6   172.4   60.31
4 305     5 2001 1255.82 185.5   172.9   55.82
5 306     6 2001 1224.42 185.9   173.4   54.93
6 307     7 2001 1211.23 186.2   174.0   56.36
\end{verbatim}

and all the available variables are

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{names}\NormalTok{(approval)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
 [1] "id"         "month"      "year"       "sp500"      "cpi"       
 [6] "cpifood"    "approve"    "gasprice"   "unemploy"   "katrina"   
[11] "rgasprice"  "lrgasprice" "X11.Sep"    "iraqinvade" "lsp500"    
[16] "lcpifood"  
\end{verbatim}

Typically we want to investigate trends and correlations and graphing
pairs or more of series is a good way to begin.

\hypertarget{scatter-plot}{%
\subsection{Scatter plot}\label{scatter-plot}}

A first scatter plot, using \texttt{geom\_point} of food against gas
(petrol) prices

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(approval, }\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{lcpifood, }\AttributeTok{y=}\NormalTok{lrgasprice)) }\SpecialCharTok{+}    \CommentTok{\# Initiate, set aesthetics}
  \FunctionTok{geom\_point}\NormalTok{()                                       }\CommentTok{\# Display as points}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/p1-1.pdf}

}

\end{figure}

OK, I guess, but a bit dull -- so add some colour. This time,
\texttt{aes} is specified in the \texttt{geom} -- either is fine, but
there are some advantages either way which we will see shortly.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(approval) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{lcpifood, }\AttributeTok{y=}\NormalTok{lrgasprice, }\AttributeTok{color=}\NormalTok{month))  }\CommentTok{\# Colours by month}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/p2-1.pdf}

}

\end{figure}

Better, but how about\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(approval) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{lcpifood, }\AttributeTok{y=}\NormalTok{lrgasprice, }\AttributeTok{color=}\NormalTok{approve), }\AttributeTok{size=}\DecValTok{2}\NormalTok{, }\AttributeTok{shape=}\DecValTok{17}\NormalTok{) }\SpecialCharTok{+} \CommentTok{\# Colours by popularity!}
  \FunctionTok{scale\_color\_gradient}\NormalTok{(}\AttributeTok{low=}\StringTok{"red"}\NormalTok{, }\AttributeTok{high=}\StringTok{"green"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/p2a-1.pdf}

}

\end{figure}

where the colours are a gradient we specify. But months can only be one
of twelve categories, so a categorical variable (a \emph{factor}) is
needed to get different actual colours, otherwise for a continuous
variable I get shades of one colour or a continuous change we need to
specify.

Lets do this -- and add a different aesthetic, size, for year.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(approval) }\SpecialCharTok{+}
  \FunctionTok{geom\_point}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{lcpifood, }\AttributeTok{y=}\NormalTok{lrgasprice, }\AttributeTok{color=}\FunctionTok{as.factor}\NormalTok{(month), }\AttributeTok{size=}\FunctionTok{as.factor}\NormalTok{(year)))}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
Warning: Using size for a discrete variable is not advised.
\end{verbatim}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/p3-1.pdf}

}

\end{figure}

Note there is now a lot going n, and maybe too much. \texttt{ggplot}
thinks so!

\hypertarget{time-series-plots}{%
\subsection{Time series plots}\label{time-series-plots}}

Our time index is a bit odd as the data set has year and month
separately. Create a proper date series using:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{approval }\SpecialCharTok{\%\textless{}\textgreater{}\%} 
  \FunctionTok{unite}\NormalTok{(date, year, month, }\AttributeTok{sep=}\StringTok{"/"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{date =} \FunctionTok{as.Date}\NormalTok{(}\FunctionTok{paste0}\NormalTok{(date,}\StringTok{"/01"}\NormalTok{), }\StringTok{"\%Y/\%m/\%d"}\NormalTok{))}
\end{Highlighting}
\end{Shaded}

I've used the \texttt{\%\textless{}\textgreater{}\%} pipe operator to
send and get back \texttt{approval} so this is now

\begin{verbatim}
   id       date   sp500   cpi cpifood approve gasprice unemploy katrina
1 302 2001-02-01 1239.94 184.4   171.8   59.24    148.4      4.6       0
2 303 2001-03-01 1160.33 185.3   172.2   57.01    144.7      4.5       0
3 304 2001-04-01 1249.46 185.6   172.4   60.31    156.4      4.2       0
4 305 2001-05-01 1255.82 185.5   172.9   55.82    172.9      4.1       0
5 306 2001-06-01 1224.42 185.9   173.4   54.93    164.0      4.7       0
6 307 2001-07-01 1211.23 186.2   174.0   56.36    148.2      4.7       0
  rgasprice lrgasprice X11.Sep iraqinvade   lsp500 lcpifood
1  80.47723   4.387974       0          0 7.122818 5.146331
2  78.08958   4.357857       0          0 7.056460 5.148656
3  84.26724   4.433993       0          0 7.130467 5.149817
4  93.20755   4.534829       0          0 7.135544 5.152713
5  88.21947   4.479828       0          0 7.110222 5.155601
6  79.59184   4.376912       0          0 7.099391 5.159055
\end{verbatim}

Then I can plot a couple of series using two calls to
\texttt{geom\_line}

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{ggplot}\NormalTok{(approval) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{date, }\AttributeTok{y=}\NormalTok{unemploy), }\AttributeTok{colour=}\StringTok{"red"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{date, }\AttributeTok{y=}\NormalTok{cpi), }\AttributeTok{colour=}\StringTok{"blue"}\NormalTok{) }
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-5-1.pdf}

}

\end{figure}

But this is pretty inefficient, as I would need a call to
\texttt{geom\_line} for every series I wanted to plot and even then
scales are unsuitable. Plus the labels are not right.

This is where things really get interesting. I \texttt{pivot\_longer}
all the variables into a single column.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{df }\OtherTok{\textless{}{-}} \FunctionTok{pivot\_longer}\NormalTok{(approval, }\AttributeTok{cols=}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(date, id), }\AttributeTok{names\_to=} \StringTok{"Var"}\NormalTok{, }\AttributeTok{values\_to =} \StringTok{"Val"}\NormalTok{)}
\FunctionTok{head}\NormalTok{(df)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
# A tibble: 6 x 4
     id date       Var         Val
  <int> <date>     <chr>     <dbl>
1   302 2001-02-01 sp500    1240. 
2   302 2001-02-01 cpi       184. 
3   302 2001-02-01 cpifood   172. 
4   302 2001-02-01 approve    59.2
5   302 2001-02-01 gasprice  148. 
6   302 2001-02-01 unemploy    4.6
\end{verbatim}

Great! Now I can plot \texttt{Val} using one call to
\texttt{geom\_line}. This time, put the graph object into \texttt{p} and
then explicitly plot it.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p  }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(df) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{date, }\AttributeTok{y=}\NormalTok{Val))}
\FunctionTok{plot}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-7-1.pdf}

}

\end{figure}

Oops! I need to tell \texttt{ggplot2} to separate out the variables
which are stored in \texttt{Var}. For this, use \texttt{group}:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p  }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(df) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{date, }\AttributeTok{y=}\NormalTok{Val, }\AttributeTok{group=}\NormalTok{Var))}
\FunctionTok{plot}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-8-1.pdf}

}

\end{figure}

But this could better be done by using an aesthetic like colour which
implies group

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p  }\OtherTok{\textless{}{-}} \FunctionTok{ggplot}\NormalTok{(df) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{date, }\AttributeTok{y=}\NormalTok{Val, }\AttributeTok{colour=}\NormalTok{Var))}
\FunctionTok{plot}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-9-1.pdf}

}

\end{figure}

OK, but can I plot them so we can see what's going on, like in a grid?
This is where \texttt{facet} comes in.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p  }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{+}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{Var, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-10-1.pdf}

}

\end{figure}

A bit more formatting\ldots{}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{p  }\OtherTok{\textless{}{-}}\NormalTok{ p }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\StringTok{"Facet plots"}\NormalTok{, }\AttributeTok{x=}\StringTok{""}\NormalTok{, }\AttributeTok{y=}\StringTok{""}\NormalTok{)}
\FunctionTok{plot}\NormalTok{(p)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-11-1.pdf}

}

\end{figure}

Finally all in one go, dropping the dummies, don't store as an object.
Also no legend, as series labelled in the facets. And I call a rather
handy little function \texttt{geom\_smooth} which fits (by default) a
Loess smoothing line.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{approval }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{select}\NormalTok{(}\SpecialCharTok{{-}}\NormalTok{iraqinvade, }\SpecialCharTok{{-}}\NormalTok{katrina, }\SpecialCharTok{{-}}\NormalTok{X11.Sep) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{pivot\_longer}\NormalTok{(}\AttributeTok{cols=}\SpecialCharTok{{-}}\FunctionTok{c}\NormalTok{(date, id), }\AttributeTok{names\_to=}\StringTok{"Var"}\NormalTok{, }\AttributeTok{values\_to=}\StringTok{"Val"}\NormalTok{) }\SpecialCharTok{\%\textgreater{}\%}
  \FunctionTok{ggplot}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{date, }\AttributeTok{y=}\NormalTok{Val, }\AttributeTok{group=}\NormalTok{Var, }\AttributeTok{colour=}\NormalTok{Var)) }\SpecialCharTok{+}
  \FunctionTok{geom\_line}\NormalTok{() }\SpecialCharTok{+}
  \FunctionTok{geom\_smooth}\NormalTok{() }\SpecialCharTok{+} \CommentTok{\# Smoother}
  \FunctionTok{facet\_wrap}\NormalTok{(}\SpecialCharTok{\textasciitilde{}}\NormalTok{Var, }\AttributeTok{scales =} \StringTok{"free"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{title=}\StringTok{"Facet plots"}\NormalTok{, }\AttributeTok{x=}\StringTok{""}\NormalTok{, }\AttributeTok{y=}\StringTok{""}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{Appendix1_files/figure-pdf/unnamed-chunk-12-1.pdf}

}

\end{figure}

Cool, huh?

\hypertarget{linear-algebra}{%
\chapter{Linear algebra}\label{linear-algebra}}

\hypertarget{modelling-in-economics-is-linear-algebra}{%
\section{\texorpdfstring{Modelling in economics \textbf{is} linear
algebra}{Modelling in economics is linear algebra}}\label{modelling-in-economics-is-linear-algebra}}

That's a bit extreme, but you mostly need to do linear algebra to
program up many of the estimators we need, or to solve a rational
expectations models.

\hypertarget{beginning-to-program}{%
\section{Beginning to program}\label{beginning-to-program}}

A few non-linear algebra things we will need are summarized in the
following table.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2698}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1746}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3333}}@{}}
\caption{Useful things}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
R
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
R
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Example
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Assign a value & \texttt{\textless{}-} & \texttt{a\ \textless{}-\ 4} &
Also legal is \texttt{a\ =\ 4}. But I hate it. \\
Create a list of values & \texttt{c(.)} &
\texttt{v\ \textless{}-\ c(1,\ -2,\ 22)} & Defining `on the fly' \\
Sequence & \texttt{seq(i,\ k,\ l)} & \(5\), \(7\), \ldots{} ,\(21\) &
Create a sequence \\
& \texttt{i:k} & \(i\), \(i\pm 1\), \ldots{} ,\(k\) & Short cut for unit
in/de-crements \\
Loop commands & \texttt{for\ (var\ in\ seq)\ expr} &
\texttt{for\ (i\ in\ 5:1)\ print(i)} & Loops. We need loops. \\
Draw a random number & \texttt{rnorm(k,a,b)} &
\texttt{rnorm(60,\ 0,\ 5)} & Example draws 60 values \textasciitilde{}
\(N(0,5)\) \\
Create a matrix & \texttt{matrix(v,i,j)} & \texttt{matrix(5,\ 2,\ 2)} &
Create a \(2\times 2\) matrix of 5s \\
\end{longtable}

\hypertarget{functions}{%
\subsection{Functions}\label{functions}}

Everything in R is a function (although it doesn't look like it).
Defining a function is simple:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{name\_of\_function }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(function\_arguments)\{}
  \CommentTok{\# Body of function where stuff is done  }
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

Here's one that actually does something:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{addaddadd }\OtherTok{\textless{}{-}} \ControlFlowTok{function}\NormalTok{(x,y)\{}
\NormalTok{  z }\OtherTok{\textless{}{-}} \DecValTok{3}\SpecialCharTok{*}\NormalTok{(x}\SpecialCharTok{+}\NormalTok{y)}
  \FunctionTok{return}\NormalTok{(z)}
\NormalTok{\}}
\end{Highlighting}
\end{Shaded}

and if we run it:

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{addaddadd}\NormalTok{(}\DecValTok{4}\NormalTok{,}\DecValTok{6}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] 30
\end{verbatim}

\hypertarget{linear-algebra-1}{%
\section{Linear algebra}\label{linear-algebra-1}}

Assume the following: \(A\) and \(B\) are real matrices of dimension
\(n\times n\), \(b\) and \(c\) are real \(n-\)vectors, \(X\) is a real
\(T\times k\) matrix, and \(S\) is a symmetric real matrix.

\begin{longtable}[]{@{}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2698}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.2222}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.1746}}
  >{\raggedright\arraybackslash}p{(\columnwidth - 6\tabcolsep) * \real{0.3333}}@{}}
\caption{Maths commands essential to linear algebra}\tabularnewline
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Maths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
R
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endfirsthead
\toprule\noalign{}
\begin{minipage}[b]{\linewidth}\raggedright
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Maths
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
R
\end{minipage} & \begin{minipage}[b]{\linewidth}\raggedright
Notes
\end{minipage} \\
\midrule\noalign{}
\endhead
\bottomrule\noalign{}
\endlastfoot
Hadamard product & \(A\bigodot B\) & \texttt{A\ *\ B} &
Element-by-element, \(A\), \(B\) same size \\
Matrix/vector product & \(A\times B\), \(A \times b\) &
\texttt{A\ \%*\%\ B}, \texttt{A\ \%*\%\ b} & Normal product rule \\
Inner product & \(X'X\) & \texttt{t(X)\ \%*\%\ X} & Also uses transpose
operator, \texttt{t()} \\
& & \texttt{crossprod(X)} & More efficient, but less mathy \\
& \(A'B\) & \texttt{t(A)\ \%*\%\ B} & \\
& & \texttt{crossprod(A,B)} & \\
Outer product & \(A\times B'\) & \texttt{tcrossprod(A,B)} & \\
Inverse & \(A^{-1}\) & \texttt{solve(A)} & Matrix inverse is a special
case of\ldots{} \\
Solve for \(d\) & \(Ad = b \Rightarrow d = A^{-1}b\) &
\texttt{d\ \textless{}-\ solve(A,\ b)} & \ldots linear solution! \\
Cholesky decomp & \(S = R'R\) & \texttt{R\ \textless{}-\ chol(S)} &
\(S\) is a symmetric, positive definite matrix \\
Cholesky inverse & \(S^{-1}\) & \texttt{chol2inv(R)} & Fast! \\
Determinant & \(\vert A \vert\) & \texttt{det(A)} & \\
Diagonal & & & \\
\(\quad\) of a matrix & & \texttt{diag(A)} & Retrieve the elements
\(a_{ii}\), \(i=1,..,n\) \\
\(\quad\) in a matrix & & \texttt{A\ \textless{}-\ diag(b)} & Set the
diagonal of \(A\) to \(b\), zero elsewhere \\
\(\quad\) Identity matrix & \(I_n\) & \texttt{diag(n)} & \\
Eigenvalues/vectors & & \texttt{E\ \textless{}-\ eigen(A)} & Returns a
\emph{list}: \texttt{E\$values}, \texttt{E\$vectors} \\
\end{longtable}

\hypertarget{starting-to-do-linear-algebra}{%
\section{Starting to do linear
algebra}\label{starting-to-do-linear-algebra}}

\hypertarget{problem}{%
\subsection{Problem}\label{problem}}

Consider the following simultaneous system of equations:

\begin{align*}
x_1 + 2x_2 &= 6 \\
x_1 - 3x_2 +2 x_3 &= 0 \\
-2 x_1 + 3 x_3 &= 2
\end{align*}

Find the values of \(x\) that solve this using R.

\textbf{Hint} -- write the problem in matrix form

\begin{equation*}
 Ax = b
\end{equation*}

where

\begin{equation*}
A = \left [ \begin{array}{rrr}
             1 &  2 & 0 \\
             1 & -3 & 2 \\
            -2 &  0 & 3
            \end{array} \right ], \qquad 
  b = \left[ \begin{matrix}6 \\ 0 \\ 2\end{matrix} \right ]
\end{equation*}

and then use \texttt{solve}.

\hypertarget{solution}{%
\subsection{Solution}\label{solution}}

R code to create these matrices is:

\begin{Shaded}
\begin{Highlighting}[]
\CommentTok{\# Matrices are populated by column by default}
\NormalTok{A }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{,}\DecValTok{1}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{2}\NormalTok{,}\DecValTok{2}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{3}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{,}\DecValTok{3}\NormalTok{),}\DecValTok{3}\NormalTok{,}\DecValTok{3}\NormalTok{)}
\NormalTok{b }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{6}\NormalTok{,}\DecValTok{0}\NormalTok{,}\DecValTok{2}\NormalTok{),}\DecValTok{3}\NormalTok{,}\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

The solution is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{x }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(A,b)}
\end{Highlighting}
\end{Shaded}

where \texttt{x} is:

\begin{verbatim}
     [,1]
[1,]    2
[2,]    2
[3,]    2
\end{verbatim}

\hypertarget{eigenvalue-decomposition}{%
\section{Eigenvalue decomposition}\label{eigenvalue-decomposition}}

Any square matrix can be decomposed into a non-singular matrix \(V\) of
eigenvectors and a diagonal matrix of eigenvalues \(\Lambda\) such that:
\begin{equation}
  A V = V \Lambda \Rightarrow A = V\Lambda V^{-1}
\end{equation} Call \texttt{eigen} to decompose our previously defined
matrix \(A\)

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{e }\OtherTok{\textless{}{-}} \FunctionTok{eigen}\NormalTok{(A)}
\NormalTok{L }\OtherTok{\textless{}{-}}\NormalTok{ e}\SpecialCharTok{$}\NormalTok{values    }\CommentTok{\# Returns a list, assign vectors/values}
\NormalTok{V }\OtherTok{\textless{}{-}}\NormalTok{ e}\SpecialCharTok{$}\NormalTok{vectors}
\end{Highlighting}
\end{Shaded}

Note \(A\) is \textbf{not} symmetric so it may have complex roots, which
is does

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{L}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
[1] -3.682744+0.000000i  2.341372+0.873683i  2.341372-0.873683i
\end{verbatim}

If we calculate \(A = V\Lambda V^{-1}\) we get

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{s }\OtherTok{\textless{}{-}}\NormalTok{ V }\SpecialCharTok{\%*\%} \FunctionTok{diag}\NormalTok{(L) }\SpecialCharTok{\%*\%} \FunctionTok{solve}\NormalTok{(V)}
\NormalTok{s}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      [,1]             [,2]             [,3]
[1,]  1+0i  2.000000e+00+0i -2.220446e-16+0i
[2,]  1+0i -3.000000e+00+0i  2.000000e+00+0i
[3,] -2+0i -1.054712e-15+0i  3.000000e+00+0i
\end{verbatim}

and when we drop the zero imaginary parts

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{Re}\NormalTok{(s)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]          [,2]          [,3]
[1,]    1  2.000000e+00 -2.220446e-16
[2,]    1 -3.000000e+00  2.000000e+00
[3,]   -2 -1.054712e-15  3.000000e+00
\end{verbatim}

Round to eliminate numerical error, to get

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{round}\NormalTok{(}\FunctionTok{Re}\NormalTok{(s), }\AttributeTok{digits=}\DecValTok{12}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2] [,3]
[1,]    1    2    0
[2,]    1   -3    2
[3,]   -2    0    3
\end{verbatim}

\hypertarget{precision}{%
\section{Precision}\label{precision}}

Why do we round? Take a real matrix \(A_{mn}\) with \(n \le m\) and
pre-multiply by its own transpose, i.e.~\(S = A'A\). \(AA\) is
symmetric, positive semi-definite. If \(rank(A) = n\), then
\(rank(S) = n\) and positive definite, and its inverse exists.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{A  }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\DecValTok{1}\NormalTok{, .}\DecValTok{2}\NormalTok{, }\DecValTok{0}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DecValTok{2}\NormalTok{, }\DecValTok{2}\NormalTok{)}
\NormalTok{S }\OtherTok{\textless{}{-}} \FunctionTok{t}\NormalTok{(A) }\SpecialCharTok{\%*\%}\NormalTok{ A}
\NormalTok{S}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1] [,2]
[1,] 1.04  0.2
[2,] 0.20  1.0
\end{verbatim}

Let's invert \(S\) three different ways.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i1 }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(S) }
\NormalTok{i2 }\OtherTok{\textless{}{-}} \FunctionTok{chol2inv}\NormalTok{(}\FunctionTok{chol}\NormalTok{(S))}
\NormalTok{i3 }\OtherTok{\textless{}{-}} \FunctionTok{qr.solve}\NormalTok{(S) }
\end{Highlighting}
\end{Shaded}

Pre-multiplying \(S\) by its inverse gives

\begin{equation}
   I_k = \left[\begin{matrix}1 &0 \\0 &1 \\\end{matrix}\right]
\end{equation}

Looking at the results of doing this for each method gives

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i1 }\SpecialCharTok{\%*\%}\NormalTok{ S}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
             [,1] [,2]
[1,] 1.000000e+00    0
[2,] 2.775558e-17    1
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i2 }\SpecialCharTok{\%*\%}\NormalTok{ S}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]         [,2]
[1,]    1 5.551115e-17
[2,]    0 1.000000e+00
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{i3 }\SpecialCharTok{\%*\%}\NormalTok{ S}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
     [,1]          [,2]
[1,]    1 -2.775558e-17
[2,]    0  1.000000e+00
\end{verbatim}

which are all slightly different but by tiny -- and insignificant --
amounts. Don't be fooled by this, they are all numerically the same.

\hypertarget{programming-the-regression-problem}{%
\section{Programming the regression
problem}\label{programming-the-regression-problem}}

Let's look at the familiar regression problem for some generated data.
\begin{equation}
  y = XB + \epsilon
\end{equation} where \(\epsilon \sim N(0,.2)\), \(X\) is a
\((k+1)\times n\) matrix of regressors including a constant and \(B\) a
\(k+1\) vector of coefficients. Let's generate some random data of an
arbitrary sized problem:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{180}\NormalTok{, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), }\DecValTok{60}\NormalTok{, }\DecValTok{3}\NormalTok{)}
\FunctionTok{head}\NormalTok{(X, }\DecValTok{6}\NormalTok{) }\CommentTok{\# Print first six rows}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
         [,1]        [,2]     [,3]
[1,] 1.906710  4.86573396 2.390330
[2,] 3.268898  4.05527385 1.705367
[3,] 1.622163  2.10549632 2.176462
[4,] 1.304953  0.40456346 3.078402
[5,] 3.106988  2.54012774 1.180277
[6,] 4.346681 -0.09252894 2.508839
\end{verbatim}

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(}\DecValTok{1}\NormalTok{, X) }\CommentTok{\# Add a constant}
\FunctionTok{tail}\NormalTok{(X,}\DecValTok{6}\NormalTok{) }\CommentTok{\# Print last six rows}
\end{Highlighting}
\end{Shaded}

\begin{verbatim}
      [,1]       [,2]      [,3]      [,4]
[55,]    1 -1.0234818 1.3021403 1.4330546
[56,]    1  1.2814302 0.7535604 1.0542110
[57,]    1  2.3069226 1.4478565 0.3346868
[58,]    1 -0.2652897 3.0628273 2.0804648
[59,]    1  2.1082132 1.5461640 1.8327673
[60,]    1  2.4949328 4.4734549 2.5290737
\end{verbatim}

Now create a dependent variable that is a linear combination of these
variables plus some noise. Create the linear relationship first so we
know what it is:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{c}\NormalTok{(}\FloatTok{0.5}\NormalTok{,}\DecValTok{1}\NormalTok{,}\SpecialCharTok{{-}}\DecValTok{1}\NormalTok{,.}\DecValTok{2}\NormalTok{), }\DecValTok{4}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

and then the dependent variable:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2}\SpecialCharTok{*}\FunctionTok{rnorm}\NormalTok{(}\DecValTok{60}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

We could now do a regression -- i.e.~calculate

\begin{equation}
  \hat B = (X'X)^{-1}X'y
\end{equation}

which can be written:

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Bhat }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X)}\SpecialCharTok{\%*\%}\NormalTok{X)}\SpecialCharTok{\%*\%}\FunctionTok{t}\NormalTok{(X)}\SpecialCharTok{\%*\%}\NormalTok{y}
\end{Highlighting}
\end{Shaded}

which gives

\begin{verbatim}
           [,1]
[1,]  0.5013554
[2,]  1.0131585
[3,] -1.0033866
[4,]  0.1707199
\end{verbatim}

But I wouldn't do it like this (we'll see why in a minute). A better way
would be

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Bhat2 }\OtherTok{\textless{}{-}} \FunctionTok{chol2inv}\NormalTok{(}\FunctionTok{chol}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X))) }\SpecialCharTok{\%*\%} \FunctionTok{crossprod}\NormalTok{(X,y)}
\end{Highlighting}
\end{Shaded}

or even

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{Bhat3 }\OtherTok{\textless{}{-}} \FunctionTok{qr.solve}\NormalTok{(X,y)}
\end{Highlighting}
\end{Shaded}

which both evaluate to the same \(\hat B\) values. Each is better in
different circumstances.

\hypertarget{test-timings}{%
\subsection{Test timings}\label{test-timings}}

Why does it matter how you do things? It should be obvious that it
might, but it turns out some fairly trivial things can make a lot of
difference. We set some parameters so we can create a bigger problem.

\begin{Shaded}
\begin{Highlighting}[]
\NormalTok{n }\OtherTok{\textless{}{-}} \DecValTok{400}
\NormalTok{k }\OtherTok{\textless{}{-}} \DecValTok{12}
\end{Highlighting}
\end{Shaded}

We will use seven different methods to calculate an estimate of \(B\).
These are two variations on the three calculations below (where the
brackets matter!): \begin{align}
\hat B_1 &= ((X'X)^{-1}) X'y \\
\hat B_2 &= ((X'X)^{-1}) (X'y) \\
\hat B_3 &= ((X'X)^{-1} (X'y))
\end{align} where we do each of these either `by hand' or using
\texttt{crossprod}, with a final solution using \texttt{qr.solve}.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tictoc)}

\NormalTok{reps }\OtherTok{\textless{}{-}} \DecValTok{10000}
\NormalTok{t    }\OtherTok{\textless{}{-}} \FunctionTok{list}\NormalTok{()}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n) }
\NormalTok{  Bhat }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X) }\SpecialCharTok{\%*\%} \FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ y }
\NormalTok{  \}}
\NormalTok{t[[}\DecValTok{1}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n) }
\NormalTok{  Bhata }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{t}\NormalTok{(X)}\SpecialCharTok{\%*\%}\NormalTok{X) }\SpecialCharTok{\%*\%}\NormalTok{ (}\FunctionTok{t}\NormalTok{(X)}\SpecialCharTok{\%*\%}\NormalTok{y) }
\NormalTok{\}}
\NormalTok{t[[}\DecValTok{2}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n) }
\NormalTok{  Bhatb }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{((}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ X), (}\FunctionTok{t}\NormalTok{(X) }\SpecialCharTok{\%*\%}\NormalTok{ y)) }
\NormalTok{  \}}
\NormalTok{t[[}\DecValTok{3}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n) }
\NormalTok{  Bhat2 }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X)) }\SpecialCharTok{\%*\%} \FunctionTok{crossprod}\NormalTok{(X,y) }
\NormalTok{  \}}
\NormalTok{t[[}\DecValTok{4}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n) }
\NormalTok{  Bhat2a }\OtherTok{\textless{}{-}} \FunctionTok{solve}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X), }\FunctionTok{crossprod}\NormalTok{(X,y)) }
\NormalTok{  \}}
\NormalTok{t[[}\DecValTok{5}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n)}
\NormalTok{  Bhat2b }\OtherTok{\textless{}{-}} \FunctionTok{chol2inv}\NormalTok{(}\FunctionTok{chol}\NormalTok{(}\FunctionTok{crossprod}\NormalTok{(X))) }\SpecialCharTok{\%*\%} \FunctionTok{crossprod}\NormalTok{(X,y) }
\NormalTok{  \}}
\NormalTok{t[[}\DecValTok{6}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}

\FunctionTok{set.seed}\NormalTok{(}\DecValTok{123}\NormalTok{)}
\FunctionTok{tic}\NormalTok{()}
\ControlFlowTok{for}\NormalTok{ (i }\ControlFlowTok{in} \DecValTok{1}\SpecialCharTok{:}\NormalTok{reps) \{ }
\NormalTok{  B }\OtherTok{\textless{}{-}} \FunctionTok{matrix}\NormalTok{(}\FunctionTok{runif}\NormalTok{(k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{), k}\SpecialCharTok{+}\DecValTok{1}\NormalTok{, }\DecValTok{1}\NormalTok{)}
\NormalTok{  X }\OtherTok{\textless{}{-}} \FunctionTok{cbind}\NormalTok{(1L, }\FunctionTok{matrix}\NormalTok{(}\FunctionTok{rnorm}\NormalTok{(n}\SpecialCharTok{*}\NormalTok{k, }\DecValTok{2}\NormalTok{, }\DecValTok{1}\NormalTok{), n, k))}
\NormalTok{  y }\OtherTok{\textless{}{-}}\NormalTok{ X }\SpecialCharTok{\%*\%}\NormalTok{ B }\SpecialCharTok{+} \FloatTok{0.2} \SpecialCharTok{*} \FunctionTok{rnorm}\NormalTok{(n) }
\NormalTok{  Bhat3 }\OtherTok{\textless{}{-}} \FunctionTok{qr.solve}\NormalTok{(X,y) }
\NormalTok{  \}}
\NormalTok{t[[}\DecValTok{7}\NormalTok{]] }\OtherTok{\textless{}{-}} \FunctionTok{toc}\NormalTok{(}\AttributeTok{quiet =} \ConstantTok{TRUE}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

How do we display the timings we saved in \texttt{t}? We could do a
simple (but dull) table, or something a bit nicer.

\begin{Shaded}
\begin{Highlighting}[]
\FunctionTok{library}\NormalTok{(tidyverse)}

\NormalTok{FF }\OtherTok{\textless{}{-}} \FunctionTok{c}\NormalTok{(}\StringTok{"solve(t(X)\%*\%X) \%*\% t(X) \%*\% y"}\NormalTok{,}
        \StringTok{"solve(t(X)\%*\%X) \%*\% (t(X)\%*\%y)"}\NormalTok{,}
        \StringTok{"solve(t(X)\%*\%X, (t(X)\%*\%y))"}\NormalTok{,}
        \StringTok{"solve(crossprod(X)) \%*\% crossprod(X,y)"}\NormalTok{,}
        \StringTok{"solve(crossprod(X), crossprod(X,y))"}\NormalTok{,}
        \StringTok{"chol2inv(chol(crossprod(X))) \%*\% crossprod(X,y)"}\NormalTok{,}
        \StringTok{"qr.solve(X,y)"}\NormalTok{)}

\NormalTok{tms }\OtherTok{\textless{}{-}} \FunctionTok{as.numeric}\NormalTok{(}\FunctionTok{gsub}\NormalTok{(}\StringTok{" sec elapsed"}\NormalTok{, }\StringTok{""}\NormalTok{, }\FunctionTok{unlist}\NormalTok{(t)[}\FunctionTok{seq}\NormalTok{(}\DecValTok{3}\NormalTok{,}\DecValTok{21}\NormalTok{,}\DecValTok{3}\NormalTok{)]))}
\NormalTok{v   }\OtherTok{\textless{}{-}} \FunctionTok{tibble}\NormalTok{(}\AttributeTok{Method  =} \DecValTok{1}\SpecialCharTok{:}\DecValTok{7}\NormalTok{, }
              \AttributeTok{Times   =}\NormalTok{ tms,}
              \AttributeTok{Formula =}\NormalTok{ FF) }\SpecialCharTok{\%\textgreater{}\%} 
  \FunctionTok{mutate}\NormalTok{(}\AttributeTok{Col =} \FunctionTok{case\_when}\NormalTok{(Times }\SpecialCharTok{==} \FunctionTok{min}\NormalTok{(Times) }\SpecialCharTok{\textasciitilde{}} \StringTok{"red"}\NormalTok{,}
                         \ConstantTok{TRUE} \SpecialCharTok{\textasciitilde{}} \StringTok{"blue"}
\NormalTok{  ))}

\FunctionTok{ggplot}\NormalTok{(v) }\SpecialCharTok{+} 
  \FunctionTok{geom\_col}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Method, }\AttributeTok{y=}\NormalTok{Times, }\AttributeTok{fill=}\FunctionTok{as.factor}\NormalTok{(Method)), }\AttributeTok{alpha=}\NormalTok{.}\DecValTok{6}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{geom\_text}\NormalTok{(}\FunctionTok{aes}\NormalTok{(}\AttributeTok{x=}\NormalTok{Method, }\AttributeTok{y=}\NormalTok{.}\DecValTok{1}\NormalTok{, }\AttributeTok{label=}\NormalTok{Formula, }\AttributeTok{color=}\NormalTok{Col), }\AttributeTok{size=}\FloatTok{5.5}\NormalTok{, }\AttributeTok{hjust=}\DecValTok{0}\NormalTok{) }\SpecialCharTok{+}
  \FunctionTok{theme\_minimal}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{scale\_color\_identity}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{legend.position =} \StringTok{"none"}\NormalTok{) }\SpecialCharTok{+} 
  \FunctionTok{theme}\NormalTok{(}\AttributeTok{axis.text.y =} \FunctionTok{element\_blank}\NormalTok{()) }\SpecialCharTok{+} 
  \FunctionTok{coord\_flip}\NormalTok{() }\SpecialCharTok{+} 
  \FunctionTok{labs}\NormalTok{(}\AttributeTok{y=}\FunctionTok{paste}\NormalTok{(}\StringTok{"Seconds taken to do"}\NormalTok{,reps,}\StringTok{"replications"}\NormalTok{), }\AttributeTok{x=}\StringTok{""}\NormalTok{, }
       \AttributeTok{title=}\StringTok{"Timings of different numerical regression methods"}\NormalTok{)}
\end{Highlighting}
\end{Shaded}

\begin{figure}[H]

{\centering \includegraphics{LinAlg_files/figure-pdf/unnamed-chunk-17-1.pdf}

}

\end{figure}


\backmatter

\printindex

\end{document}
